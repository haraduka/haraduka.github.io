<!-- This file is automatically generated. Do not modify -->
<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title> Kento Kawaharazuka </title>
    <link rel="shortcut icon" href="static/favicon.ico">
    <link rel="canonical" href="https://haraduka.github.io">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1XJ0NHR591"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-1XJ0NHR591');
    </script>

    <meta property="twitter:card" content="summary" />
    <meta property="twitter:title" content="Kento Kawaharazuka" />
    <meta property="twitter:image" content="https://haraduka.github.io/static/kawaharazuka.png" />

    <meta property="og:title" content="Kento Kawaharazuka" />
    <meta property="og:url" content="https://haraduka.github.io" />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://haraduka.github.io/static/kawaharazuka.png" />

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
  </head>

  <body>
    <div class="container py-3">

      <nav class="navbar navbar-expand-lg navbar-light fixed-top" style="background-color: #f8f9fa; border-bottom: 1px solid #ddd;">
        <div class="container">
          <a class="navbar-brand mx-auto align-items-center" href="https://haraduka.github.io" style="font-size: 24px; display: flex;">Kento Kawaharazuka</a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse justify-content-end" id="navbarSupportedContent">
            <ul class="navbar-nav" style="font-size: 24px;">
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="robots.html">Robots</a>
              </li>
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="projects.html">Projects</a>
              </li>
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="videos.html">Videos</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <script>
        let lastScrollTop = 0;
        const navbar = document.querySelector('.navbar');

        window.addEventListener('scroll', () => {
          let currentScroll = window.pageYOffset || document.documentElement.scrollTop;

          if (currentScroll > lastScrollTop) {
            // 下方向にスクロール中
            navbar.classList.add('navbar-hide');
            navbar.classList.remove('navbar-show');
          } else {
            // 上方向にスクロール中
            navbar.classList.add('navbar-show');
            navbar.classList.remove('navbar-hide');
          }

          lastScrollTop = currentScroll;
        });
      </script>

      <main>
        <div class="row py-3">
          <div class="col-md-4 text-center">
            <div style="max-width: 400px">
              <img src="static/kawaharazuka.png" class="img-fluid mx-auto d-block" alt="Image" style="max-width: 100%; height: auto;">
            </div>
          </div>

          <div class="col-md-8 py-3">
            <h2> Kento Kawaharazuka </h2>
            <h3> Lecturer (Junior Associate Professor) </h3>
            Next Generation Artificial Intelligence Research Center (AI Center), <br>
            + Department of Mechano-Informatics, <br>
            Graduate School of Information Science and Technology, <br>
            The University of Tokyo, Japan <br>
            <div class="d-inline-flex mt-4 ms-md-auto">
              <a href="https://scholar.google.co.jp/citations?user=E75YHyUAAAAJ&hl=en" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" height="36" width="36"fill="currentColor" viewBox="0 0 512 512">
                  <path d="M390.9 298.5c0 0 0 .1 .1 .1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7c4.4-7.6 9.4-14.7 15-21.3c27.4-32.6 68.5-53.3 114.4-53.3c33.6 0 64.6 11.1 89.6 29.9c9.1 6.9 17.4 14.7 24.8 23.5c5.6 6.6 10.6 13.8 15 21.3c2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/>
                </svg>
              </a>
              <a href="https://twitter.com/KKawaharazuka" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-twitter-x" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
                </svg>
              </a>
              <a href="https://www.youtube.com/channel/UC3iq44Y7vsriPyFiU02Bcyw" target='_blank' class='me-3'>
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-youtube" viewBox="0 0 16 16">
                  <path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.007 2.007 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.007 2.007 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31.4 31.4 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.007 2.007 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A99.788 99.788 0 0 1 7.858 2h.193zM6.4 5.209v4.818l4.157-2.408z"/>
                </svg>
              </a>
              <a href="https://github.com/haraduka" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
                  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
                </svg>
              </a>
              <a href="mailto:kawaharazuka@jsk.imi.i.u-tokyo.ac.jp" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24">
                  <path fill="currentColor" d="M20 18h-2V9.25L12 13L6 9.25V18H4V6h1.2l6.8 4.25L18.8 6H20m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"/></svg>
                </svg>
              </a>
              <a href="https://www.linkedin.com/in/kento-kawaharazuka-099372285/" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
                  <path fill="currentColor" d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"/></svg>
                </svg>
              </a>
            </div>
          </div>
        </div>
        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Biography </h2>
        </div>
        Kento Kawaharazuka is a lecturer (junior associate professor) in UTokyo AI Center and JSK Robotics Laboratory at the University of Tokyo.
        His research interests are mainly in humanoids, including biomimetics, tendon-driven robots, and machine learning.
        He designs tendon-driven humanoids and develops learning control systems to move them.
        <h3> Career </h3>
        <ul>
          <li> Lecturer (Junior Associate Professor) in UTokyo AI Center and Mechano-Informatics, 2025.2- (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> Visiting Researcher, 2024.6-2024.8 (Robotics and Systems Laboratory, ETH Zurich) </li>
          <li> Project Assistant Professor in Mechano-Informatics, 2022.4-2025.1 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> Ph.D. in Mechano-Informatics, 2019.4-2022.3 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> M.S. in Mechano-Informatics, 2017.4-2019.3 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> B.S. in Mechano-Informatics, 2013.4-2017.3 (Faculty of Engineering, The University of Tokyo) </li>
        </ul>

        <div class="row py-3">
          <div class="col-lg-8 offset-lg-2 text-center">
            <img src="static/robots.jpeg" class="img-fluid mx-auto d-block" alt="Image" style="max-width: 100%; height: auto;">
          </div>
        </div>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> News </h2>
        </div>
        <ul>
          <li><b> 2025.02.01 - Kento Kawaharazuka has promoted to Lecturer (Junior Associate Professor) in UTokyo AI Center and Department of Mechano-Informatics!</b></li>
          <li><b> 2025.01.28 - Two papers including one first-authored paper was accepted at ICRA2025!</b></li>
          <li><b> 2025.01.24 - Our front hair styling robot was selected as a Best Student Paper Award Finalist at SII2025!</b></li>
          <li><b> 2025.01.08 - 共同執筆した書籍「Data-Centric AI入門」が技術評論社から出版されました.</b></li>
          <li><b> 2024.12.07 - I gave an inivited talk at VANJ Conference 2024!</b></li>
          <li><b> 2024.12.06 - I gave an inivited talk at Tokyo AI (TAI)!</b></li>
          <li><b> 2024.11.24 - CubiXMusashi won the Mike Stillman Award at Humanoids2024!</b></li>
          <li><b> 2024.11.23 - I gave a plenary talk at Humanoids2024.</b></li>
          <li><b> 2024.11.20 - I gave an invited talk at KIT, Karlsruhe.</b></li>
          <li><b> 2024.11.08 - One paper was accepted to SII2025</b></li>
          <li><b> 2024.09.09 - Eight papers including three first-authored papers were accepted to Humanoids2024.</b></li>
          <li><b> 2024.09.04 - 日本ロボット学会2024にて主著2件を含む10件の発表があります.</b></li>
          <li><b> 2024.08.01 - I gave a talk at Professor Sven Behnke's Lab at University of Bonn.</b></li>
          <li><b> 2024.07.31 - I gave an invited talk at DLR, Oberpfaffenhofen.</b></li>
          <li><b> 2024.07.30 - I gave a talk at Professor Gordon Cheng's Lab at TUM, Munich.</b></li>
          <li><b> 2024.07.29 - I gave an invited talk at Max Planck Institute, Tubingen.</b></li>
          <li><b> 2024.07.05 - I gave a talk at CREATE lab at EPFL, Lausanne.</b></li>
          <li><b> 2024.06.30 - Six papers including two first-authored papers were accepted to IROS2024.</b></li>
          <li><b> 2024.06.28 - I gave an invited talk at CRL Seminar at ETH Zurich.</b></li>
          <li><b> 2024.06.25 - 創発的研究支援事業に採択されました.</b></li>
          <li><b> 2024.06.20 - I gave an invited talk at postdoc seminar at IIT, Genova.</b></li>
          <li><b> 2024.06.17 - I gave an invited talk at symposium on robotics in biomedical applications at KTH, Stockholm.</b></li>
          <li><b> 2024.06.03 - I will be conducting research as a visiting researcher at ETH for two and a half months.</b></li>
        </ul>
        <div onclick="obj=document.getElementById('open').style; obj.display=(obj.display=='none')?'block':'none';">
          <a style="cursor:pointer;">▼ click here to expand</a>
        </div>
        <div id="open" style="display:none;clear:both;">
          <ul>
          <li><b> 2024.05.30 - ロボティクス・メカトロニクス講演会2024にて主著1件を含む10件の発表があります.</b></li>
          <li><b> 2024.05.28 - 人工知能学会2024にて1件の発表があります.</b></li>
          <li><b> 2024.05.17 - I gave an organizer talk at ICRA2024 workshop on <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Cooking Robotics: Perception and Motion Planning</a>.</b></li>
          <li><b> 2024.05.16 - RT-X project won the Best Conference Paper Award at ICRA2024!</b></li>
          <li><b> 2024.04.15 - I gave an invited talk at RoboSoft2024 workshop on <a href="https://printed-musculoskeletal-robots.ethz.ch/" target='_blank'>From Layers to Limbs! Exploring the Interface of 3D Printing and Bio-Inspired Musculoskeletal Robotics</a>.</b></li>
          <li><b> 2024.03.05 - Our paper "Continuous Object State Recognition for Cooking Robots" was accepted to RA-L!</b></li>
          <li><b> 2024.03.05 - Our paper "SAQIEL: Ultra-Light and Safe Manipulator" was accepted to RA-L!</b></li>
          <li><b> 2024.02.09 - Our new survey paper "Real-World Robot Applications of Foundation Models: A Review" is now on arXiv!</b></li>
          <li><b> 2024.02.09 - "卵料理の実世界調理実行"と"液体滲出軟骨機構の構成法"に関する研究が計測自動制御学会2023にて優秀講演賞に選ばれました.</b></li>
          <li><b> 2024.02.04 - I have been staying at Robotic Systems Lab at ETH in Switzerland for the past two weeks. I appreciate the insightful discussions!</b></li>
          <li><b> 2024.02.02 - We organize <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Cooking Robotics Workshop</a> at ICRA2024!</b></li>
          <li><b> 2024.01.30 - We have extended the deadline of Advanced Robotics Special Issue on Real-World Robot Applications of Foundation Models to 29th February.</b></li>
          <li><b> 2024.01.29 - Five papers including two first-authored papers were accepted to ICRA2024.</b></li>
          <li><b> 2024.01.19 - Two papers  were accepted to RoboSoft2024.</b></li>
          <li><b> 2023.12.15 - We visited RoMeLa at UCLA and GITAI.</b></li>
          <li><b> 2023.12.12 - We presented five papers at Humanoids2023.</b></li>
          <li><b> 2023.10.29 - 第19回身体性認知科学と実世界応用に関する若手研究会(ECSRA)にて招待講演を行います.</b></li>
          <li><b> 2023.10.24 - 日本ロボット学会誌Vol.41, No.8に"情報化身体の学習理論に基づく成長ロボットの革新と創成"に関する解説記事が掲載されました.</b></li>
          <li><b> 2023.10.18 - 第5回LLM勉強会(LLM-jp)にて招待講演を行います.</b></li>
          <li><b> 2023.10.06 - We visited Stanford University.</b></li>
          <li><b> 2023.10.05 - I gave an invited talk at IROS2023 workshop on <a href="https://sites.google.com/view/learning-meets-models-iros2023/speakers?authuser=0" target='_blank'>Learning Meets Model-based Methods for Manipulation and Grasping</a>.</b></li>
          <li><b> 2023.09.30 - Five papers including two first-authored papers were accepted to Humanoids2023.</b></li>
          <li><b> 2023.09.12 - 日本ロボット学会2023にて主著1件を含む12件の発表があります.</b></li>
          <li><b> 2023.08.31 - NLP若手の会(YANS2023)の招待セッションで発表します.</b></li>
          <li><b> 2023.06.29 - "動的柔軟布操作"の研究がロボティクス・メカトロニクス講演会2022にてベストデモンストレーション賞に選ばれました.</b></li>
          <li><b> 2023.06.29 - ロボティクス・メカトロニクス講演会2023にて主著2件を含む13件の発表があります.</b></li>
          <li><b> 2023.06.28 - ロボティクス・メカトロニクス講演会2023シンポジウム「"いいかげん"を科学して未来を創るソフトロボット学4」にて招待講演を行います.</b></li>
          <li><b> 2023.06.22 - Five papers including one first-authored paper were accepted to IROS2023.</b></li>
          <li><b> 2023.06.06 - 人工知能学会2023にて主著1件を含む2件の発表があります.</b></li>
          <li><b> 2023.06.02 - One paper was accepted to ROMAN2023.</b></li>
          <li><b> 2023.05.30 - Four papers were accepted to IAS18.</b></li>
          <li><b> 2023.05.17 - 日本ロボット学会2023にてOS4「基盤モデルの実ロボット応用」を主催します.</b></li>
          <li><b> 2023.04.10 - One paper was accepted to AMAM2023.</b></li>
          <li><b> 2023.04.05 - 新学期から3人のB4が自分のグループに加わりました.</b></li>
          <li><b> 2023.04.01 - JST ACT-X「AI活用で挑む学問の革新と創成」の加速フェーズに採択されました.</b></li>
          <li><b> 2023.01.19 - Two first-authored papers (including one RAM paper) were accepted to ICRA2023.</b></li>
          <li><b> 2022.12.16 - ロボティクスシンポジア2023に主著1件を含む6件の発表が採択されました.</b></li>
          <li><b> 2022.12.14 - 計測自動制御学会2022にて主著1件を含む5件の発表があります.</b></li>
          <li><b> 2022.11.30 - "Hardware and Software Design of Musashi-W" was selected as Best Interactive Paper Award Finalist at Humanoids2022.</b></li>
          <li><b> 2022.11.21 - 日本ロボット学会誌Vol.40, No.9に"パラメトリックバイアスを含む深層予測モデル学習"に関する解説記事が掲載されました.</b></li>
          <li><b> 2022.10.26 - "Self-Supervised Learning of Visual Servoing" was selected as SICE International Young Authors Award at IROS2022.</b></li>
          <li><b> 2022.10.26 - "Parallel-Wire Driven Monopedal Robot RAMIEL" was selected as SICE International Young Authors Award at IROS2022.</b></li>
          <li><b> 2022.09.09 - 日本ロボット学会2022 "若手研究者が描く2050年のAIロボットビジョン"OFにて招待講演を行います.</b></li>
          <li><b> 2022.09.05 - 日本ロボット学会2022にて主著2件を含む14件の発表があります.</b></li>
          <li><b> 2022.09.26 - Five papers including three first-authored papers were accepted to Humanoids2022.</b></li>
          <li><b> 2022.06.30 - Seven papers including four first-authored papers (including one RA-L paper) were accepted to IROS2022.</b></li>
          <li><b> 2022.06.17 - "Human-mimetic Binaural Ear Design" was accepted to Robomech Journal.</b></li>
          <li><b> 2022.06.15 - 人工知能学会2022にて主著1件の発表があります.</b></li>
          <li><b> 2022.06.03 - 日本機械学会2022にて主著2件を含む10件の発表があります.</b></li>
          <li><b> 2022.06.01 - "Roboust Continous Motion Against Muscle Rupture" was accepted to Robotics and Autonomous Systems.</b></li>
          <li><b> 2022.05.27 - We won the first prize of state-based category at DodgeDrone Challenge at ICRA2022.</b></li>
          <li><b> 2022.05.23 - "Dynamic Cloth Manipulation" was accepted to Frontiers in Neurorobotics.</b></li>
          <li><b> 2022.04.05 - 新学期から2人のB4と1人のM1が自分のグループに加わりました.</b></li>
          <li><b> 2022.04.01 - I received Ph.D. and became a project assistant professor at JSK Roboics Laboratory.</b></li>
          <li><b> 2022.03.24 - 博士論文が研究科長賞に選ばれました.</b></li>
          <li><b> 2022.02.01 - Two papers including one first-authored paper (including one RA-L paper) were accepted to ICRA2022.</b></li>
          <li><b> 2022.01.21 - "確率的深層予測モデル学習"に関する研究がSI2021において優秀講演賞に選ばれました.</b></li>
          <li><b> 2021.12.15 - 計測自動制御学会2021にて主著2件を含む3件の発表があります.</b></li>
          <li><b> 2021.09.09 - 日本ロボット学会2021にて"深層予測モデル学習"についてキーノート講演を行います.</b></li>
          <li><b> 2021.09.06 - 日本ロボット学会2021にて主著1件の発表があります.</b></li>
          <li><b> 2021.07.22 - "Design of MusashiOLegs" was selected as Best Oral Paper Award at Humanoids2020.</b></li>
          <li><b> 2021.07.01 - Five papers including four first-authored papers (including three RA-L papers) were accepted to IROS2021.</b></li>
          <li><b> 2021.06.06 - 日本機械学会2021にて主著2件を含む7件の発表があります.</b></li>
          <li><b> 2021.05.01 - Three papers including two first-authored papers were accepted to Humanoids2020.</b></li>
          <li><b> 2021.03.01 - Four papers including two first-authored papers (including one RA-L and one RAM papers) were accepted to ICRA2021.</b></li>
          <li><b> 2021.02.10 - One first-authored paper was accepted to RoboSoft2021.</b></li>
          <li><b> 2021.01.27 - "道具形状最適化"に関する研究が計測自動制御学会2020にて優秀講演賞に選ばれました.</b></li>
          <li><b> 2020.12.16 - 計測自動制御学会2020にて主著3件を含む4件の発表があります.</b></li>
          <li><b> 2020.11.24 - "成長ロボット"に関する課題がJST ACT-X「AI活用で挑む学問の革新と創成」領域に採択されました.</b></li>
          <li><b> 2020.10.10 - 日本ロボット学会2020にて主著1件を含む2件の発表があります.</b></li>
          <li><b> 2020.10.09 - "柔軟物体操作"と"Musculoskeletal AutoEncoder"に関する研究が日本ロボット学会2019にて研究奨励賞に選ばれました.</b></li>
          <li><b> 2020.07.03 - Six papers including five first-authored papers (including two RA-L papers) were accepted to IROS2020.</b></li>
          <li><b> 2020.05.27 - 日本機械学会2020にて2件の発表があります.</b></li>
          <li><b> 2020.05.13 - "Autonomous Driving by Musculoskeletal Humanoids" was accepted to Robotics and Autonomous Magazine.</b></li>
          <li><b> 2020.04.20 - "Human Mimetic Forearm and Hand Design" was accepted to Journal of Robotics and Mechatronics.</b></li>
          <li><b> 2020.01.22 - Three papers including two first-authored papers (including one RA-L paper) were accepted to ICRA2020.</b></li>
          <li><b> 2019.10.09 - 日本ロボット学会2019にて主著2件を含む5件の発表があります.</b></li>
          <li><b> 2019.08.26 - Three papers including one first-authored paper were accepted to Humanoids2019.</b></li>
          <li><b> 2019.06.21 - Seven papers including four first-authored paper (including one RA-L paper)were accepted to IROS2019.</b></li>
          <li><b> 2019.06.05 - 日本機械学会2019にて主著2件を含む8件の発表があります.</b></li>
          <li><b> 2019.04.13 - One first-authored paper was accepted to AMAM2019.</b></li>
          <li><b> 2019.01.22 - One first-authored paper was accepted to ICRA2019.</b></li>
          <li><b> 2018.10.02 - "Five-Fingered Hand Design" was selected as IROS ICROS Best Application Paper Award 2018 Finalists at IROS2018.</b></li>
          <li><b> 2018.09.21 - Three papers including two first-authored papers were accepted to Humanoids2018.</b></li>
          <li><b> 2018.09.05 - 日本ロボット学会2018にて主著2件を含む4件の発表があります.</b></li>
          <li><b> 2018.06.29 - Two papers including one first-authored paper were accepted to IROS2018.</b></li>
          <li><b> 2018.06.02 - 日本機械学会2018にて主著1件を含む4件の発表があります.</b></li>
          <li><b> 2018.03.06 - One first-authored paper (RA-L paper) was accepted to IROS2018.</b></li>
          <li><b> 2017.09.24 - "Human Mimetic Forearm Design" was selected as IEEE RAS Japan Joint Chapter Young Award at IROS2017.</b></li>
          <li><b> 2017.09.11 - 日本ロボット学会2017にて主著1件の発表があります.</b></li>
          <li><b> 2017.06.29 - Three papers including two first-authored paper (including one RA-L paper) were accepted to IROS2017.</b></li>
          <li><b> 2017.05.10 - 日本機械学会2017にて主著1件を含む2件の発表があります.</b></li>
          </ul>
        </div>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Publications </h2>
        </div>
<h3> International Journal Papers </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, T. Matsushima, A. Gambardella, J. Guo, C. Paxton, A. Zeng<br>Real-World Robot Applications of Foundation Models: A Review, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1232-1254, 2024, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.1080/01691864.2024.2408593 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2402.05741 target='_blank'>[Arxiv Link]</a></li>
<li>N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>Real-world cooking robot system from recipes based on food state recognition using foundation models and PDDL, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1318-1334, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2407136 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.02874 target='_blank'>[Arxiv Link]</a> <a href=https://kanazawanaoaki.github.io/cook-from-recipe-pddl/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=3bQRTAKV0wM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada, M. Inaba<br>Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1307-1317, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2393409 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.11380 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/omnidirectional-vlm/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=T2Uezkpu5u4 target='_blank'>[Video]</a></li>
<li>S. Wakabayashi, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Behavioral Learning of Dish Rinsing and Scrubbing based on Interruptive Direct Teaching Considering Assistance Rate, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 15, pp. 1052-1065, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2379393 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09360 target='_blank'>[Arxiv Link]</a> <a href=https://shmpwk.github.io/projects/dish_wash/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=db4OcVsz3YY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, 2024, (<b>presented at ICRA2025</b>)<br> <a href=https://doi.org/10.1109/MRA.2024.3415111 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.06427 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic Environmental State Recognition with Pre-Trained Vision-Language Models and Black-Box Optimization, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1255-1264, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2366995 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.17519 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/vlm-bbo/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=aOoQcEdVb6M target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, Y. Obinata, K. Okada, M. Inaba<br>Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 5, pp. 4059-4066, 2024, (<b>presented at Humanoids2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2024.3375257 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.08239 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/continuous-state-recognition/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=480caUHXrE0 target='_blank'>[Video]</a></li>
<li>T. Suzuki, M. Bando, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>SAQIEL: Ultra-Light and Safe Manipulator with Passive 3D Wire Alignment Mechanism, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 4, pp. 3720-3727, 2024, (<b>presented at IROS2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2024.3371219 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.01803 target='_blank'>[Arxiv Link]</a> <a href=https://tenrobo18.github.io/saqiel-ral2023-webpage/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=QEluGqmj-k8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Yoshimura, T. Suzuki, K. Okada, M. Inaba<br>Design Optimization of Wire Arrangement With Variable Relay Points in Numerical Simulation for Tendon-Driven Robots, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 2, pp. 1388-1395, 2024, (<b>presented at IROS2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2023.3342667 target='_blank'>[Paper Link]</a> <a href=http://arxiv.org/abs/2401.02730 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/muscle-arrange-optimization/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=Uq9Ympi7KMw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Deep Predictive Model Learning with Parametric Bias: Handling Modeling Difficulties and Temporal Model Changes, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, vol. 31, no. 4, pp. 81-99, 2023, (<b>presented at ICRA2023</b>)<br> <a href=https://doi.org/10.1109/MRA.2022.3217744 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.15726 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada, M. Inaba<br>Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 7, no. 3, pp. 7881-7887, 2022, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2022)</font></b>, (<b>presented at IROS2022</b>)<br> <a href=https://doi.org/10.1109/LRA.2022.3186074 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11798 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=ulWgQTVDGQA target='_blank'>[Video]</a></li>
<li>Y. Omura, <b><u>K. Kawaharazuka</u></b>, Y. Nagamatsu, Y. Koga, M. Nishiura, Y. Toshimitsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Human-mimetic binaural ear design and sound source direction estimation for task realization of musculoskeletal humanoids, <i>Robomech Journal</i>, vol. 9, no. 17, pp. 1-15, 2022<br> <a href=https://doi.org/10.1186/s40648-022-00231-x target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.06427 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=d8YB1UJfDCM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, K. Okada, M. Inaba<br>Dynamic Cloth Manipulation Considering Variable Stiffness and Material Change Using Deep Predictive Model With Parametric Bias, <i>Frontiers in Neurorobotics</i>, vol. 16, pp. 1-16, 2022<br> <a href=https://doi.org/10.3389/fnbot.2022.890695 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.15635 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=wDJmIL0ZkbE target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Toshimitsu, Y. Omura, Y. Koga, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Robust Continuous Motion Strategy Against Muscle Rupture using Online Learning of Redundant Intersensory Networks for Musculoskeletal Humanoids, <i>Robotics and Autonomous Systems (<b>RAS</b>)</i>, vol. 152, pp. 1-14, 2022<br> <a href=https://doi.org/10.1016/j.robot.2022.104067 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.14951 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=deRDl2zI_0c target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, Y. Toshimitsu, K. Okada, M. Inaba<br>Adaptive Body Schema Learning System Considering Additional Muscles for Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 7, no. 2, pp. 3459-3466, 2022, (<b>presented at ICRA2022</b>)<br> <a href=https://doi.org/10.1109/LRA.2022.3147457 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06322 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=cc0223BgKlA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Adaptive Robotic Tool-Tip Control Learning Considering Online Changes in Grasping State, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 3, pp. 5992-5999, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3088807 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08052 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=cpimgpBHgxY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Kawamura, K. Okada, M. Inaba<br>Imitation Learning with Additional Constraints on Motion Style using Parametric Bias, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 3, pp. 5897-5904, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3087423 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08057 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=dunhjxYzvUA target='_blank'>[Video]</a></li>
<li>Y. Koga, <b><u>K. Kawaharazuka</u></b>, Y, Toshimitsu, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Self-Body Image Acquisition and Posture Generation with Redundancy using Musculoskeletal Humanoid Shoulder Complex for Object Manipulation, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 4, pp. 6686-6692, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3095318 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Koga, Y. Omura, Y. Toshimitsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Automatic Grouping of Redundant Sensors and Actuators Using Functional and Spatial Connections: Application to Muscle Grouping for Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 2, pp. 1981-1988, 2021, (<b>presented at ICRA2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3060715 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.00678 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=TWJqvRVSVFk target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Koga, Y. Omura, T. Makabe, K. Shinjo, M. Onitsuka, Y. Nagamatsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Toward Autonomous Driving by Musculoskeletal Humanoids: Study of Developed Hardware and Learning-Based Software, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, vol. 27, no. 3, pp. 84-96, 2020, (<b>presented at ICRA2021</b>)<br> <a href=https://doi.org/10.1109/MRA.2020.2987805 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.05573 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=qQqv2pFMhmo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Object Recognition, Dynamic Contact Simulation, Detection, and Control of the Flexible Musculoskeletal Hand Using a Recurrent Neural Network With Parametric Bias, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 3, pp. 4580-4587, 2020, (<b>presented at IROS2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.3002199 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08050 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=c4mhS5BvkPw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Hiraoka, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Estimation and Control of Motor Core Temperature with Online Learning of Thermal Model Parameters: Application to Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 3, pp. 4273-4280, 2020, (<b>presented at IROS2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.2990889 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08055 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Musculoskeletal AutoEncoder: A Unified Online Acquisition Method of Intersensory Networks for State Estimation, Control, and Simulation of Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 2, pp. 2411-2418, 2020, (<b>presented at ICRA2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.2972841 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.17134 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=E510TsXRTf8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, S. Nakashima, Y. Asano, K. Okada, M. Inaba<br>Human Mimetic Forearm and Hand Design with a Radioulnar Joint and Flexible Machined Spring Finger for Human Skillful Motions, <i>Journal of Robotics and Mechatronics (<b>JRM</b>)</i>, vol. 32, no. 2, pp. 445-458, 2020, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.20965/jrm.2020.p0445 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09934 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=h1sEw56zCwo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Long-time Self-body Image Acquisition and its Application to the Control of Musculoskeletal Structures, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 4, no. 3, pp. 2965-2972, 2019, (<b>presented at IROS2019</b>)<br> <a href=https://doi.org/10.1109/LRA.2019.2923968 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05293 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=P5Z4XRYXYzA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>Online Learning of Joint-Muscle Mapping using Vision in Tendon-driven Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 3, no. 2, pp. 772-779, 2018, (<b>presented at ICRA2018</b>)<br> <a href=https://doi.org/10.1109/LRA.2018.2789849 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05295 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=8_A6--bzAeQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Kawamura, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Antagonist Inhibition Control in Redundant Tendon-driven Structures Based on Human Reciprocal Innervation for Wide Range Limb Motion of Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 2, no. 4, pp. 2119-2126, 2017, (<b>presented at IROS2017</b>)<br> <a href=https://doi.org/10.1109/LRA.2017.2720854 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.00705 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=nFMRb1SCs1Q target='_blank'>[Video]</a></li>
</ol>
<h3> International Conference Proceedings (Peer Reviewed) </h3>
<ol>
<li>S. Kim, N. Kanazawa, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Front Hair Styling Robot System Using Path Planning for Root-Centric Strand Adjustment, in <i>2025 IEEE/SICE International Symposium on System Integration (<b>SII2025</b>)</i>, 2025, <b><font color='red'>Best Student Paper Finalist</font></b><br> <a href=https://arxiv.org/abs/2501.10991 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=AUBmOXsnqbg target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Inoue, T. Suzuki, S. Yuzai, S. Sawaguchi, K. Okada, M. Inaba<br>MEVIUS: A Quadruped Robot Easily Constructed through E-Commerce with Sheet Metal Welding and Machining, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 631-636, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769853 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.14721 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/mevius-hardware/ target='_blank'>[Project Page]</a> <a href=https://github.com/haraduka/mevius target='_blank'>[Source Code]</a> <a href=https://www.youtube.com/watch?v=XXJ4EK3Y4zQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 934-940, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769848 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.22707 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=4LzAM_bGBAI target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, Y. Ribayashi, Y. Sahara, K. Okada<br>CubiXMusashi: Fusion of Wire-Driven CubiX and Musculoskeletal Humanoid Musashi toward Unlimited Performance, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 274-279, 2024, <b><font color='red'>Mike Stillman Award</font></b><br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769840 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.23682 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/cubixmusashi/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=IvzP98-r_mo target='_blank'>[Video]</a></li>
<li>Y. Iwata, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Integrative Wrapping System for a Dual-Arm Humanoid Robot, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 84-90, 2024, <b><font color='red'>Kanako Miura Award</font></b><br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769922 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.08389 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Obinata, H. Jia, <b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada<br>Remote Life Support Robot Interface System for Global Task Planning and Local Action Expansion Using Foundation Models, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 738-743, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769852 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.10038 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=bM0w69k0LM8 target='_blank'>[Video]</a></li>
<li>S. Sawaguchi, T. Suzuki, A. Miki, <b><u>K. Kawaharazuka</u></b>, S. Yuzaki, S. Yoshimura, Y. Ribayashi, K. Okada, M. Inaba<br>Vlimb: A Wire-Driven Wearable Robot for Bodily Extension, Balancing Powerfulness and Reachability, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 851-857, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769893 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.09565 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=JIRoCHnsVrw target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, Y. Sahara, S. Sawaguchi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Fundamental Three-Dimensional Configuration of Wire-Wound Muscle-Tendon Complex Drive, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 980-987, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769901 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.03838 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=EDeAqg7aAb4 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Robot Design Optimization with Rotational and Prismatic Joints Using Black-Box Multi-Objective Optimization, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 4571-4577, 2024<br> <a href=https://doi.org/10.1109/IROS58592.2024.10802642 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.20038 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/prismatic-joint-opt/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=XTihjUsbkNw target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, K. Okada, M. Inaba<br>CubiX: Portable Wire-Driven Parallel Robot Connecting to and Utilizing the Environment, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 1296-1301, 2024, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2024)</font></b>, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2024)</font></b><br> <a href=https://doi.org/10.1109/IROS58592.2024.10802299 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.05933 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/cubix-hardware/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=R5ZrzMPEFZs target='_blank'>[Video]</a></li>
<li>S. Yoshimura, A. Miki, K. Miyama, Y. Sahara, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Patterned Structure Muscle : Arbitrary Shaped Wire-Driven Artificial Muscle Utilizing Anisotropic Flexible Structure for Musculoskeletal Robots, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 13930-13937, 2024, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2024)</font></b>, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2024)</font></b><br> <a href=https://doi.org/10.1109/IROS58592.2024.10801899 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.07682 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Sahara, A. Miki, Y. Ribayashi, S. Yoshimura, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Construction of Musculoskeletal Simulation for Shoulder Complex with Ligaments and Its Validation via Model Predictive Control, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 327-333, 2024<br> <a href=https://doi.org/10.1109/IROS58592.2024.10802465 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.05931 target='_blank'>[Arxiv Link]</a> <a href=https://sahara-yuta.github.io/projects/shoulder-complex-simulation target='_blank'>[Project Page]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Robotic Constrained Imitation Learning for the Peg Transfer Task in Fundamentals of Laparoscopic Surgery, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 606-612, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610059 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.03440 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/fls-imitation/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cg7bFTj_hPo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Adaptive Whole-body Robotic Tool-use Learning on Low-rigidity Plastic-made Humanoids Using Vision and Tactile Sensors, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 583-589, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610913 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.04826 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/wholebody-tooluse/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=auCYNiMiXXE target='_blank'>[Video]</a></li>
<li>A. Tang, T. Hiraoka, N. Hiraoka, F. Shi, <b><u>K. Kawaharazuka</u></b>, K. Kojima, K. Okada, M. Inaba<br>HumanMimic: Learning Natural Locomotion and Transitions for Humanoid Robot via Wasserstein Adversarial Imitation, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 13107-13114, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610449 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.14225 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=sdM11yHpzi8 target='_blank'>[Video]</a></li>
<li>K. Shirai, C. C. Beltran-Hernandez, M. Hamaya, A. Hashimoto, S. Tanaka, <b><u>K. Kawaharazuka</u></b>, K. Tanaka, Y. Ushiku, S. Mori<br>Vision-Language Interpreter for Robot Task Planning, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 2051-2058, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10611112 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2311.00967 target='_blank'>[Arxiv Link]</a> <a href=https://kskshr.github.io/vilain/ target='_blank'>[Project Page]</a> <a href=https://github.com/omron-sinicx/vilain target='_blank'>[Source Code]</a></li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 6892-6903, 2024, <b><font color='red'>Best Conference Paper Award</font></b>, <b><font color='red'>Finalists of Best Paper Award in Robot Manipulation</font></b><br> <a href=https://doi.org/10.1109/ICRA57147.2024.10611477 target='_blank'>[Paper Link]</a> <a href=https://robotics-transformer-x.github.io/paper.pdf target='_blank'>[Arxiv Link]</a> <a href=https://robotics-transformer-x.github.io/ target='_blank'>[Project Page]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Body Design and Gait Generation of Chair-Type Asymmetrical Tripedal Low-rigidity Robot, in <i>2024 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2024</b>)</i>, pp. 593-600, 2024<br> <a href=https://doi.org/10.1109/RoboSoft60065.2024.10522029 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05932 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/chair-type-tripedal-robot/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=-f8LDlhmdBg target='_blank'>[Video]</a></li>
<li>A. Miki, Y. Sahara, K. Miyama, Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, S. Hasegawa, K. Okada, M. Inaba<br>Designing Fluid-Exuding Cartilage for Biomimetic Robots Mimicking Human Joint Lubrication Function, in <i>2024 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2024</b>)</i>, pp. 452-459, 2024<br> <a href=https://doi.org/10.1109/RoboSoft60065.2024.10521920 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.06740 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 458-465, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375211 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2303.05674 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, Y. Obinata, K. Okada, M. Inaba<br>Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via Large-Scale Vision-Language Model, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 452-457, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375239 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2312.07451 target='_blank'>[Arxiv Link]</a></li>
<li>S. Yoshimura, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Optimization of Muscle Arrangement Extraction from Human Waist Structure for Biomimetic Humanoid Implementation, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 583-590, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375213 target='_blank'>[Paper Link]</a></li>
<li>Y. Ribayashi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Wire-Wound Muscle-Tendon Complex Drive and Its Application to a Two-Dimensional Robot Configuration, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 758-764, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375220 target='_blank'>[Paper Link]</a></li>
<li>S. Yuzaki, A. Miki, M. Bando, S. Yoshimura, T. Suzuki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Fusion of Body and Environment with Movable Carabiners for Wire-Driven Robots Toward Expansion of Physical Capabilities, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 679-685, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375200 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Makabe, K. Okada, M. Inaba<br>Daily Assistive Modular Robot Design Based on Multi-Objective Black-Box Optimization, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 9970-9977, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10342041 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.14226 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/auto-modular-design/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=ztcq0P92mJI target='_blank'>[Video]</a></li>
<li>Y. Matsuura, <b><u>K. Kawaharazuka</u></b>, N. Hiraoka, K. Kojima, K. Okada, M. Inaba<br>Development of a Whole-Body Work Imitation Learning System by a Biped and Bi-Armed Humanoid, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 10374-10381, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10342502 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.15756 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/jaxon-tablis-imitation/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=RsoI0W8SPPA target='_blank'>[Video]</a></li>
<li>Y. Obinata, <b><u>K. Kawaharazuka</u></b>, N. Kanazawa, N. Yamaguchi, N. Tsukamoto, I. Yanokura, S. Kitagawa, K. Shinjo, K. Okada, M. Inaba<br>Semantic Scene Difference Detection in Daily Life Patroling by Mobile Robots Using Pre-Trained Large-Scale Vision-Language Model, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 3228-3233, 2023, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2023)</font></b>, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2023)</font></b><br> <a href=https://doi.org/10.1109/IROS55552.2023.10342467 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.16552 target='_blank'>[Arxiv Link]</a></li>
<li>K. Miyama, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Five-Fingerd Biomimetic Soft Robotic Hand by 3D Printing the Skin and Skeleton As One Unit, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 6624-6630, 2023, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2023)</font></b><br> <a href=https://doi.org/10.1109/IROS55552.2023.10341570 target='_blank'>[Paper Link]</a></li>
<li>S. Yoshimura, T. Suzuki, M. Bando, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Design Method of a Kangaroo Robot with High Power Legs and an Articulated Soft Tail, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 6631-6638, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10341756 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.07742 target='_blank'>[Arxiv Link]</a></li>
<li>A. Ichikura, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>A Method for Selecting Scenes and Emotion-Based Descriptions for a Robot's Diary, in <i>32nd IEEE International Conference on Robot and Human Interactive Communication (<b>ROMAN2023</b>)</i>, pp. 1683-1688, 2023<br> <a href=https://doi.org/10.1109/RO-MAN57019.2023.10309432 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01951 target='_blank'>[Arxiv Link]</a></li>
<li>A. Miki, <b><u>K. Kawaharazuka</u></b>, M. Bando, K. Okada, K. Kawasaki, M. Inaba<br>System Architecture and Real-World Task Realization of Musculoskeletal Wheeled Robot Musashi-W with Various Hardware Components, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 109-122, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_9 target='_blank'>[Paper Link]</a></li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, S. Hasegawa, K. Okada, M. Inaba<br>Workspace-Based Precision Grasp Pose Generator for Multi-Fingered Robotic Hands, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 379-392, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_29 target='_blank'>[Paper Link]</a></li>
<li>N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 547-560, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_42 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01528 target='_blank'>[Arxiv Link]</a></li>
<li>A. Ichikura, <b><u>K. Kawaharazuka</u></b>, Y. Obinata,, K. Shinjo, K. Okada, M. Inaba<br>Automatic Diary Generation System Including Information on Joint Experiences between Humans and Robots, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 399-412, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44981-9_33 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01948 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>VQA-based Robotic State Recognition Optimized with Genetic Algorithm, in <i>2023 IEEE International Conference on Robotics and Automation (<b>ICRA2023</b>)</i>, pp. 8306-8311, 2023<br> <a href=https://doi.org/10.1109/ICRA48891.2023.10160390 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2303.05052 target='_blank'>[Arxiv Link]</a></li>
<li>H. Sato, <b><u>K. Kawaharazuka</u></b>, T. Makabe, K. Okada, M. Inaba<br>Online Estimation of Self-Body Deflection with Various Sensor Data Based on Directional Statistics, in <i>2023 IEEE/SICE International Symposium on System Integration (<b>SII2023</b>)</i>, pp. 1-8, 2023<br> <a href=https://doi.org/10.1109/SII55687.2023.10039450 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2306.03616 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, T. Suzuki, Y. Ribayashi, Y. Toshimitsu, Y. Nagamatsu, K. Okada, M. Inaba<br>Hardware Design and Learning-Based Software Architecture of Musculoskeletal Wheeled Robot Musashi-W for Real-World Applications, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 413-419, 2022, <b><font color='red'>Best Interactive Paper Award Finalist</font></b><br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000123 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11729 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=VhBfpYB-QxI target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Suzuki, K. Okada, M. Inaba<br>Continuous Jumping of a Parallel Wire-Driven Monopedal Robot RAMIEL Using Reinforcement Learning, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 759-764, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000182 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11205 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=y8YqJt3HZvY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada, M. Inaba<br>Learning-Based Wiping Behavior of Low-Rigidity Robots Considering Various Surface Materials and Task Definitions, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 919-924, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000172 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11198 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=N47IXZ6Q0io target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, D. Kusuyama, A. Miki, K. Shinjo, M. Bando, T. Suzuki, Y. Kojio, K. Okada, M. Inaba<br>Design of Robot Foot with Outer Edge Measurement Structure and Chair Rotation Motion by Friction Control, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 314-321, 2022, (<b>Top 7 Best Oral Paper Presentation</b>)<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000127 target='_blank'>[Paper Link]</a></li>
<li>K. Miyama, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, N. Yamaguchi, K. Okada, M. Inaba<br>Design of a Five-Fingered Hand with Full-Fingered Tactile Sensors Using Conductive Filaments and Its Application to Bending after Insertion Motion, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 780-785, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000181 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.00732 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Realization of Seated Walk by a Musculoskeletal Humanoid with Buttock-Contact Sensors From Human Constrained Teaching, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5774-5780, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9982103 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.00892 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=r1vhMWBkiHU target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Online Learning Feedback Control Considering Hysteresis for Musculoskeletal Structures, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5767-5773, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981052 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11808 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=8exSF0LB4t8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Ribayashi, A. Miki, Y. Toshimitsu, T. Suzuki, K. Okada, M. Inaba<br>Learning of Balance Controller Considering Changes in Body State for Musculoskeletal Humanoids, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5809-5816, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981051 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11803 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=OZh__9a4OTQ target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, A. Miki, K. Okada, M. Inaba<br>DIJE: Dense Image Jacobian Estimation for Robust Robotic Self-Recognition and Visual Servoing, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 2219-2226, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981868 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=7wFUZGFtjLE target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, D. Kusuyama, A. Miki, K. Shinjo, M. Bando, T. Suzuki, Y. Kojio, K. Okada, M. Inaba<br>Imitation Behavior of the Outer Edge of the Foot by Humanoids Using a Simplified Contact State Representation, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 4243-4249, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981673 target='_blank'>[Paper Link]</a></li>
<li>T. Suzuki, Y. Toshimitsu, Y. Nagamatsu, <b><u>K. Kawaharazuka</u></b>, A. Miki, Y. Ribayashi, M. Bando, K. Kojima, Y. Kakiuchi, K. Okada, M. Inaba<br>RAMIEL: A Parallel-Wire Driven Monopedal Robot for High and Continuous Jumping, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5017-5024, 2022, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2022)</font></b><br> <a href=https://doi.org/10.1109/IROS47612.2022.9981963 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2311.04573 target='_blank'>[Arxiv Link]</a> <a href=https://tenrobo18.github.io/ramiel-iros2022/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=dPmIMdITTwM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Shinjo, Y. Kawamura, K. Okada, M. Inaba<br>Environmentally Adaptive Control Including Variance Minimization Using Stochastic Predictive Network with Parametric Bias: Application to Mobile Robots, in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2021</b>)</i>, pp. 8381-8387, 2021<br> <a href=https://doi.org/10.1109/IROS51168.2021.9636416 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.08275 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, M. Nishiura, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture, in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2021</b>)</i>, pp. 3204-3210, 2021<br> <a href=https://doi.org/10.1109/IROS51168.2021.9636845 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Hiraoka, Y. Koga, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Online Learning of Danger Avoidance for Complex Structures of Musculoskeletal Humanoids and Its Applications, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 349-355, 2021<br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555792 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Motion Modification Method of Musculoskeletal Humanoids by Human Teaching Using Muscle-Based Compensation Control, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 83-89, 2021<br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555772 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06323 target='_blank'>[Arxiv Link]</a></li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Development of Musculoskeletal Legs with Planar Interskeletal Structures to Realize Human Comparable Moving Function, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 17-24, 2021, <b><font color='red'>Best Oral Paper Award</font></b>, <b><font color='red'>Finalists of Mike Stilman Paper Award</font></b><br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555807 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.00890 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=zF0YdU5bTbg target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Biomimetic Operational Space Control for Musculoskeletal Humanoid Optimizing across Muscle Activation and Joint Nullspace, in <i>2021 IEEE International Conference on Robotics and Automation (<b>ICRA2021</b>)</i>, pp. 1184-1190, 2021<br> <a href=https://doi.org/10.1109/ICRA48506.2021.9561919 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=vthQNaqoXuM target='_blank'>[Video]</a></li>
<li>S. Nakashima, <b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Asano, Y. Kakiuchi, K. Okada, K. Kawasaki, M. Inaba<br>Restoring Force Design of Active Self-Healing Tension Transmission System and Application to Tendon-Driven Legged Robot, in <i>2021 IEEE International Conference on Robotics and Automation (<b>ICRA2021</b>)</i>, pp. 7033-7038, 2021<br> <a href=https://doi.org/10.1109/ICRA48506.2021.9561531 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, S. Nakashima, Y. Toshimitsu, Y. Omura, Y. Koga, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Stability Recognition with Active Vibration for Bracing Behaviors and Motion Extensions Using Environment in Musculoskeletal Humanoids, in <i>2021 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2021</b>)</i>, pp. 126-133, 2021<br> <a href=https://doi.org/10.1109/RoboSoft51838.2021.9479430 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-driven Structures of Musculoskeletal Humanoids, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 3585-3590, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341510 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 3598-3603, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341488 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, C. Nabeshima<br>Tool Shape Optimization through Backpropagation of Neural Network, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 8387-8393, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341583 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.12202 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=UjmdjYiUttA target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka M. Nishiura, Y. Koga, Y. Omura, M. Tomita, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Biomimetic Control Scheme for Musculoskeletal Humanoids Based on Motor Directional Tuning in the Brain, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 7784-7791, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9340896 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=fbEi3qmh8pw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the Predictive Model of Sensor State Transition, in <i>2020 IEEE International Conference on Robotics and Automation (<b>ICRA2020</b>)</i>, pp. 4572-4578, 2020<br> <a href=https://doi.org/10.1109/ICRA40945.2020.9197188 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.17136 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=JSK6ljJSIpQ target='_blank'>[Video]</a></li>
<li>T. Nishio, M. Zhao, F. Shi, T. Anzai, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Stable Control in Climbing and Descending Flight under Upper Walls using Ceiling Effect Model based on Aerodynamics, in <i>2020 IEEE International Conference on Robotics and Automation (<b>ICRA2020</b>)</i>, pp. 172-178, 2020<br> <a href=https://doi.org/10.1109/ICRA40945.2020.9197137 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, K. Tsuzuki, M. Onitsuka, Y. Nagamatsu, K. Shinjo, T. Makabe, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Component Modularized Design of Musculoskeletal Humanoid Platform Musashi to Investigate Learning Control Systems, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 7294-7301, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8968068 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.22000 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=t2JZraUT3lY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, M. Onitsuka, K. Shinjo, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Task-specific Self-body Controller Acquisition by Musculoskeletal Humanoids: Application to Pedal Control in Autonomous Driving, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 813-818, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967910 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.08270 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=FPwRuyzzdEc target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, C. Nabeshima<br>Dynamic Task Control Method of a Flexible Manipulator Using a Deep Recurrent Neural Network, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 7689-7695, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967923 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.12201 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=WwCNPGUFjho target='_blank'>[Video]</a></li>
<li>K. Shinjo, <b><u>K. Kawaharazuka</u></b>, Y. Asano, S. Nakashima, S. Makino, M. Onitsuka, K. Tsuzuki, K. Okada, K. Kawasaki, M. Inaba<br>Foot with a Core-shell Structural Six-axis Force Sensor for Pedal Depressing and Recovering from Foot Slipping during Pedal Pushing Toward Autonomous Driving by Humanoids, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 3049-3054, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967519 target='_blank'>[Paper Link]</a></li>
<li>S. Nakashima, T. Shirai, <b><u>K. Kawaharazuka</u></b>, Y. Asano Y. Kakiuchi, K. Okada, M. Inaba<br>An Approach of Facilitated Investigation of Active Self-healing Tension Transmission System Oriented for Legged Robots, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 2567-2572, 2019, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2019)</font></b><br> <a href=https://doi.org/10.1109/IROS40897.2019.8967949 target='_blank'>[Paper Link]</a></li>
<li>T. Makabe, T. Shirai, Y. Nagamatsu, <b><u>K. Kawaharazuka</u></b>, S. Fumihito, K. Okada, M. Inaba<br>Development of Joint Module with Two-Speed Gear Transmission and Joint Lock Mechanism during Driving for Task Adaptable Robot, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 5123-5130, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8968232 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Reflex-based Motion Strategy of Musculoskeletal Humanoids under Environmental Contact Using Muscle Relaxation Control, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 114-119, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9034994 target='_blank'>[Paper Link]</a></li>
<li>Y. Koga, <b><u>K. Kawaharazuka</u></b>, M. Onitsuka, T. Makabe, K. Tsuzuki, Y. Omura, Y. Asano, K. Okada, M. Inaba<br>Modification of Muscle Antagonistic Relations and Hand Trajectory on the Dynamic Motion of Musculoskeletal Humanoid, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 632-637, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9035012 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.00737 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Asano, S. Nakashima, I. Yanokura, M. Onitsuka, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Koga, Y. Omura, K. Okada, M. Inaba<br>Ankle-Hip-Stepping Stabilizer on Tendon-Driven Humanoid Kengoro by Integration of Muscle-Joint-Work Space Controllers for Knee-Stretched Humanoid Balance, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 397-402, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9035008 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, J. Tamura, C. Nabeshima<br>Dynamic Manipulation of Flexible Objects with Torque Sequence Using a Deep Neural Network, in <i>2019 IEEE International Conference on Robotics and Automation (<b>ICRA2019</b>)</i>, pp. 2139-2145, 2019<br> <a href=https://doi.org/10.1109/ICRA.2019.8793513 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/1901.10142 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=EuB-TWygkNA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Makabe, S. Makino, K. Tsuzuki, Y. Nagamatsu, Y. Asano, T. Shirai, F. Sugai, K. Okada, K. Kawasaki, M. Inaba<br>TWIMP: Two-Wheel Inverted Musculoskeletal Pendulum as a Learning Control Platform in the Real World with Environmental Physical Contact, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 784-790, 2018, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8624923 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.14080 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=6Y4FpXx6axQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>A Method of Joint Angle Estimation Using Only Relative Changes in Muscle Lengths for Tendon-driven Humanoids with Complex Musculoskeletal Structures, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 1128-1135, 2018<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8625002 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.14100 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=J0q9q7tWJDU target='_blank'>[Video]</a></li>
<li>T. Makabe, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, K. Wada, S. Makino, M. Kawamura, A. Fujii, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Development of Movable Binocular High-Resolution Eye-Camera Unit for Humanoid and the Evaluation of Looking Around Fixation Control and Object Recognition, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 840-845, 2018<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8625072 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, A. Fujii, Y. Asano, K. Okada, M. Inaba<br>Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids, in <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, pp. 1711-1717, 2018<br> <a href=https://doi.org/10.1109/IROS.2018.8593428 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05286 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=jdYbMOj84TA target='_blank'>[Video]</a></li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, A. Fujii, T. Makabe, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints, in <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, pp. 4562-4567, 2018, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2018)</font></b>, <b><font color='red'>IROS ICROS Best Application Paper Award 2018 Finalists</font></b><br> <a href=https://doi.org/10.1109/IROS.2018.8594316 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.17452 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=HRwTFfnlCAs target='_blank'>[Video]</a></li>
<li>A. Fujii, S. Nakashima, M. Kawamura, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Development and Functional Evaluation of a Deformable Membrane Capsule for an Open Ball Glenohumeral Joint, in <i>2018 IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics (<b>BIOROB2018</b>)</i>, pp. 853-858, 2018<br> <a href=https://doi.org/10.1109/BIOROB.2018.8488005 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, Y. Kakiuchi, K. Okada, M. Inaba<br>Human Mimetic Forearm Design with Radioulnar Joint using Miniature Bone-muscle Modules and its Applications, in <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, pp. 4956-4962, 2017, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2017)</font></b><br> <a href=https://doi.org/10.1109/IROS.2017.8206377 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09934 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=h1sEw56zCwo target='_blank'>[Video]</a></li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>High-power, flexible, robust hand: Development of musculoskeletal hand using machined springs and realization of self-weight supporting motion with humanoid, in <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, pp. 1187-1192, 2017<br> <a href=https://doi.org/10.1109/IROS.2017.8202291 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.17459 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=wDDwQoYPRbA target='_blank'>[Video]</a></li>
<li>Y. Asano, T. Kozuki, S. Ookubo, M. Kawamura, S. Nakashima, T. Katayama, Y. Iori, H. Toshinori, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Kakiuchi, K. Okada, M. Inaba<br>Human Mimetic Musculoskeletal Humanoid Kengoro toward Real World Physically Interactive Actions, in <i>2016 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2016</b>)</i>, pp. 876-883, 2016, <b><font color='red'>Best Interactive Paper Award Finalist</font></b><br> <a href=https://doi.org/10.1109/HUMANOIDS.2016.7803376 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=RA4u_9FLzso target='_blank'>[Video]</a></li>
</ol>
<h3> International Workshop, Extended Abstract, etc. </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, T. Matsushima, S. Kurita, C. Paxton, A. Zeng, T. Ogata, T. Taniguchi<br>Special issue on real-world robot applications of the foundation models, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1231, 2024, (<b>Preface</b>)<br> <a href=https://doi.org/10.1080/01691864.2024.2408066 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada<br>Reflexive Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, 2024, <b><font color='red'>Excellent Practice Award</font></b>, (<b>Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects</b>)</li>
<li>S. Yoshimura, T. Suzuki, M. Bando, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Kangaroo-inspired Robot with High-Power Legs and an Articulated Tail, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, 2024, (<b>Workshop on Bio-inspired, Biomimetics, and Biohybrid (Cyborg) Systems</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Neural Information Processing Systems (<b>NeurIPS2023</b>)</i>, 2023, (<b>6th Robot Learning Workshop: Pretraining, Fine-Tuning, and Generalization with Large Scale Models</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Conference on Robot Learning (<b>CoRL2023</b>)</i>, 2023, (<b>2nd Workshop on Language and Robot Learning: Language as Grounding</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Conference on Robot Learning (<b>CoRL2023</b>)</i>, 2023, (<b>Workshop on Towards Generalist Robots: Learning Paradigms for Scalable Skill Acquisition</b>)</li>
<li>Y. Ribayashi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, K. Kawasaki, M. Inaba<br>Muscle-Tendon Complex-Inspired Deformable Exteriors as a Wire-Drive Extension, <i>11th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2023</b>)</i>, 2023<br> <a href=https://doi.org/10.18910/92308 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Modeling and Online Learning of Musculoskeletal Intersensory Networks for Static Controls of Tendon-driven Humanoids, <i>9th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2019</b>)</i>, 2019, <b><font color='red'>Company of Biologists Early Career Researcher Grant (500 GBP)</font></b><br> <a href=https://doi.org/10.5075/epfl-BIOROB-AMAM2019-11 target='_blank'>[Paper Link]</a></li>
</ol>
<h3> arXiv </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Binary State Recognition by Robots using Visual Question Answering of Pre-Trained Vision-Language Model, arXiv preprint arXiv:2310.16405, 2023<br> <a href=https://arxiv.org/abs/2310.16405 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Obinata, N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, I. Yanokura, S. Kim, K. Okada, M. Inaba<br>Foundation Model based Open Vocabulary Task Planning and Executive System for General Purpose Service Robots, arXiv preprint arXiv:2308.03357, 2023<br> <a href=https://arxiv.org/abs/2308.03357 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=fiN4Zibk6Sg target='_blank'>[Video]</a></li>
</ol>
<h3> Domestic Journal Papers </h3>
<ol>
<li>吉野 幸一郎, 谷口 忠大, 持橋 大地, <b><u>河原塚 健人</u></b>, 松嶋 達也, 品川 政太朗, 小林 一郎<br>NLP2024 併設ワークショップ「大規模言語モデルの実世界応用」, <i>自然言語処理学会誌 (<b>NLP</b>)</i>, vol. 31, no. 2, pp. 809-815, 2024<br> <a href=https://doi.org/10.5715/jnlp.31.809 target='_blank'>[Paper Link]</a></li>
<li>新城 光樹, 大日方 慶樹, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>ロボットの階層移動のためのマルチセンサ・IoT スイッチを用いた簡易取付可能なエレベータ状態認識・操作システム, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, 2024</li>
<li>三木 章寛,  永松 祐弥, 板東 正祐, <b><u>河原塚 健人</u></b>, 利光 泰徳, 平岡 直樹, 岡田 慧, 稲葉 雅幸<br>高応答性を備え多様なロボットの扱いを可能とするハードウェア抽象化デバイス制御プラットフォーム開発, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 43, no. 1, pp. 75-86, 2024<br> <a href=https://doi.org/10.7210/jrsj.43.75 target='_blank'>[Paper Link]</a></li>
<li><b><u>河原塚 健人</u></b>, 大日方 慶樹, 金沢 直晃, 岡田 慧, 稲葉 雅幸<br>大規模視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための状態認識, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 259-265, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.259 target='_blank'>[Paper Link]</a></li>
<li>鈴木 天馬, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>パラレルワイヤ脚の跳躍性能に関する力学モデルに基づく検討と実機における検証, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 274-282, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.274 target='_blank'>[Paper Link]</a></li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>料理レシピ記述解析と視覚 - 言語モデルの時系列利用による食材状態変化認識に基づくロボットの調理作業実行, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 266-273, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.266 target='_blank'>[Paper Link]</a></li>
<li><b><u>河原塚 健人</u></b><br>情報化身体の学習理論に基づく成長ロボットの革新と創成, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 41, no. 8, pp. 669-672, 2023, (<b>解説記事</b>)<br> <a href=https://doi.org/10.7210/jrsj.41.669 target='_blank'>[Paper Link]</a></li>
<li><b><u>河原塚 健人</u></b><br>パラメトリックバイアスを含む深層予測モデル学習, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 40, no. 9, pp. 784-789, 2022, (<b>解説記事</b>)<br> <a href=https://doi.org/10.7210/jrsj.40.784 target='_blank'>[Paper Link]</a></li>
<li>浅野 悠紀, <b><u>河原塚 健人</u></b>, 永松 祐弥, 古賀 悠矢, 大村 柚介, 真壁 佑, 藤井 綺香, 中島 慎介, 新城 光樹, 西浦 学, 利光 泰徳, 冨田 幹, 岡田 慧, 清水 智哉, 近藤 淳, 川崎 宏治, 豊島 浩二, 稲葉 雅幸<br>ロボット技術の社会実装に向けた腱駆動ヒューマノイドによる自動車運転の実証実験と義足開発への展開 --腱駆動ヒューマノイドによる自動車運転を通じた産官学の社会連携活動--, <i>日本ロボット学会誌 (<b>JRSJ</b>)</i>, vol. 40, no. 3, pp. 240-250, 2022<br> <a href=https://doi.org/10.7210/jrsj.40.240 target='_blank'>[Paper Link]</a></li>
</ol>
<h3> Domestic Conference Proceedings (Peer Reviewed) </h3>
<ol>
<li><b><u>河原塚 健人</u></b>, 大日方 慶樹, 金沢 直晃, 岡田 慧, 稲葉 雅幸<br>視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための離散・連続状態認識, in <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, pp. 34-35, 2023</li>
<li>大日方 慶樹, <b><u>河原塚 健人</u></b>, 金沢 直晃, 山口 直也, 塚本 直人, 矢野倉 伊織, 北川 晋吾, 岡田 慧, 稲葉 雅幸<br>事前学習済み視覚-言語モデルを用いた巡回ロボットの長期記憶に基づく日常環境の状況分類, in <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, pp. 36-37, 2023</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>調理支援ロボットの視覚-言語モデル時系列利用によるレシピ記述からの食材状態変化認識, in <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, pp. 66-67, 2023, <b><font color='red'>ロボティクスシンポジア研究奨励賞</font></b></li>
<li>鈴木 天馬, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>パラレルワイヤ一本脚ロボットの跳躍モデルと設計法, in <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, pp. 50-51, 2023</li>
<li>深山 和浩, 李林 嘉元, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>骨格表皮を一体に3Dプリントしたロボットハンドの開発, in <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, pp. 293-294, 2023</li>
<li>三木 章寛, 板東 正祐, 永松 祐弥, <b><u>河原塚 健人</u></b>, 利光 泰徳, 平岡 直樹, 岡田 慧, 稲葉 雅幸<br>多種ロボットの扱いと高応答性を両立したハードウェア抽象化デバイス制御プラットフォーム開発, in <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, pp. 239-240, 2023, <b><font color='red'>第3回日本ロボット学会ロボティクスシンポジア優秀研究・技術賞</font></b></li>
<li><b><u>河原塚 健人</u></b>, 牧野 将吾, 川村 将矢, 藤井 綺香, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける身体組織の柔軟性による筋経路変化を考慮した逐次的自己身体像の獲得, in <i>第23回ロボティクスシンポジア (<b>ROBOSYM18J</b>)</i>, pp. 306-312, 2018</li>
</ol>
<h3> Domestic Conference Proceedings (No Reviewed) </h3>
<ol>
<li><b><u>河原塚 健人</u></b>, 大日方 慶樹, 金沢 直晃, 塚本 直人, 岡田 慧<br>全天球カメラと事前学習済み視覚-言語モデルによる事前知識を必要としない反射型Open Vocabulary Navigation, in <i>第25回SICEシステムインテグレーション部門講演会 (<b>SI24J</b>)</i>, 1F6-04, 2024</li>
<li>井上 信多郎, <b><u>河原塚 健人</u></b>, 鈴木 天馬, 勇崎 颯太, 李林 嘉元, 佐原 侑太, 岡田 慧<br>環境接続可能なワイヤ駆動ロボットCubiXによる筋骨格ヒューマノイドMusashiの運動能力拡張, in <i>第25回SICEシステムインテグレーション部門講演会 (<b>SI24J</b>)</i>, 3E5-08, 2024</li>
<li><b><u>河原塚 健人</u></b>, 金沢 直晃, 大日方 慶樹, 岡田 慧<br>大規模視覚-言語モデルによる調理ロボットの時系列食材状態認識, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 3D2-03, 2024</li>
<li><b><u>河原塚 健人</u></b>, 松嶋 達也, 宮澤 和貴<br>基盤モデルの実ロボット応用 - チュートリアルA, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 3D1-01, 2024<br> <a href=https://speakerdeck.com/haraduka/rsj2024-ji-pan-moderunoshi-robotutoying-yong-tiyutoriarua-he-yuan-zhong target='_blank'>[Slide]</a></li>
<li>松嶋 達也, 宮澤 和貴, <b><u>河原塚 健人</u></b><br>基盤モデルの実ロボット応用 - チュートリアルB, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 3D1-02, 2024</li>
<li>宮澤 和貴, <b><u>河原塚 健人</u></b>, 松嶋 達也<br>基盤モデルの実ロボット応用 - チュートリアルC, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 3D1-03, 2024</li>
<li>井上 信多郎, <b><u>河原塚 健人</u></b>, 鈴木 天馬, 勇崎 颯太, 岡田 慧, 稲葉 雅幸<br>環境接続可能なワイヤ駆動ロボットCubiXによる2台の飛行アンカーを用いた雲梯動作, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 1J5-03, 2024</li>
<li>米田 慶太, <b><u>河原塚 健人</u></b>, 岡田 慧<br>弾性脚を用いた六脚ロボットの設計と強化学習を用いた対面壁登り動作の実現, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 2H1-05, 2024</li>
<li>服部 高拓, <b><u>河原塚 健人</u></b>, 岡田 慧<br>身体にアクチュエータを一切含まない腱駆動歩行ロボットの設計と制御, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 2H1-06, 2024</li>
<li>大日方 慶樹, 賈 浩宇, <b><u>河原塚 健人</u></b>, 金沢 直晃, 岡田 慧<br>あいまいな生活支援ロボット動作記述のVLMとARデバイスを用いた提示と指示による展開, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 3D3-02, 2024</li>
<li>吉村 駿之介, 鈴木 天馬, 佐原 侑太, <b><u>河原塚 健人</u></b>, 岡田 慧<br>柔軟ラティス構造を活用したワイヤ駆動人工筋肉で構成される人体模倣脚の製作, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 3J1-05, 2024</li>
<li>勇崎 颯太, 鈴木 天馬, 井上 信多郎, <b><u>河原塚 健人</u></b>, 岡田 慧<br>ワイヤ駆動空中移動ロボットの地上と空中を含む多様なロコモーション, in <i>第42回日本ロボット学会学術講演会 (<b>RSJ24J</b>)</i>, 1J5-04, 2024</li>
<li><b><u>河原塚 健人</u></b>, 吉村 駿之介, 鈴木 天馬, 岡田 慧, 稲葉 雅幸<br>可変経由点を含む腱駆動ロボットのワイヤ配置設計最適化, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 1A1-M02, 2024</li>
<li>井上 信多郎, <b><u>河原塚 健人</u></b>, 鈴木 天馬, 勇崎 颯太, 岡田 慧, 稲葉 雅幸<br>環境接続可能なワイヤ駆動ロボットによる空間移動と物体操作, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 1A1-M01, 2024</li>
<li>鈴木 天馬, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>受動3次元ワイヤ動力伝達機構における伝達効率の解析, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 1P1-O09, 2024</li>
<li>澤口 昇吾, 鈴木 天馬, 三木 章寛, <b><u>河原塚 健人</u></b>, 勇崎 颯太, 吉村 駿之介, 岡田 慧, 稲葉 雅幸<br>力強さと動作範囲を両立するワイヤ駆動型身体拡張ウェアラブルロボット Vlimb の設計法, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 1P2-E06, 2024</li>
<li>勇崎 颯太, 鈴木 天馬, 吉村 駿之介, 澤口 昇吾, 井上 信多郎, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>大出力ワイヤ巻き取り機と大径タイヤを有するワイヤ駆動空中移動ロボットの開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 1P1-N09, 2024</li>
<li>吉村 駿之介, 三木 章寛, 深山 和浩, 佐原 侑太, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>柔軟ラティス構造を活用したワイヤ駆動人工筋肉と筋骨格上腕構造の構成, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I01, 2024</li>
<li>佐原 侑太, 三木 章寛, 李林 嘉元, 吉村 駿之介, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>靭帯を備えた肩複合体の筋骨格シミュレーションモデルの構成法と制御, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I02, 2024</li>
<li>三木 章寛, 佐原 侑太, 吉村 駿之介, 李林 嘉元, 勇崎 颯太, 深山 和浩, 長谷川 峻, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>関節液内包機能と関節受容器機能を備えた人体模倣ロボットの関節包構成法, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I03, 2024</li>
<li>李林 嘉元, 佐原 侑太, 澤口 昇吾, 深山 和浩, 三木 章寛, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>アーチ状構造材を用いた膨張を伴う変形の設計とワイヤ巻取式人工筋肉への適用, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 2P1-K10, 2024</li>
<li>園田 美郷, 唐 安南, 石田 寛和, 平岡 拓真, <b><u>河原塚 健人</u></b>, 小島 邦生, 岡田 慧, 稲葉 雅幸<br>相対ロッド位置姿勢に着目した正二十面体テンセグリティロボットの転がり運動制御方策の学習獲得, in <i>日本機械学会ロボティクス・メカトロニクス講演会'24 (<b>ROBOMECH24J</b>)</i>, 2P1-M10, 2024</li>
<li>大日方 慶樹, 塚本 直人, <b><u>河原塚 健人</u></b>, 金沢 直晃, 岡田 慧, 稲葉 雅幸<br>生活支援ロボットの現場知識に基づくオンライン動作プログラム展開, in <i>第38回人工知能学会全国大会 (<b>JSAI24J</b>)</i>, 4E1-GS-8-04, 2024</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>基盤モデルと古典プランニングを用いたレシピ記述からの実世界調理計画認識実行ロボットシステム, in <i>言語処理学会第30回年次大会 (<b>NLP24J</b>)</i>, E1-3, 2024</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>対象物状態中心の調理行動記述に基づくレシピからの卵料理の実世界調理実行ロボットシステム, in <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 3G2-08, 2023, <b><font color='red'>優秀講演賞</font></b></li>
<li>深山 和浩, 李林 嘉元, 三木 章寛, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>導電性フィラメントによる表皮骨格一体ロボットハンドの接触点推定に関する研究, in <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 2E3-08, 2023</li>
<li>三木 章寛, 佐原 侑太, 深山 和浩, 李林 嘉元, 長谷川 峻, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>人の関節潤滑機能を模した人体模倣ロボットの液体滲出軟骨機構の構成法, in <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 2E3-07, 2023, <b><font color='red'>優秀講演賞</font></b></li>
<li>湯田 一成, 唐 安南, 小島 邦生, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>等身大ヒューマノイドの全身運動におけるエネルギー効率に着目した関節運動協調性の解析, in <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 3H2-06, 2023</li>
<li>金 淳暁, 金沢 直晃, 長谷川 峻, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>生活支援ロボットを用いた視覚と力覚に基づく頭髪ブラッシング動作生成に関する研究, in <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 3F1-08, 2023</li>
<li><b><u>河原塚 健人</u></b>, 松嶋 達也<br>基盤モデルの実ロボット応用 - チュートリアル1, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1K3-01, 2023<br> <a href=https://speakerdeck.com/haraduka/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru1-ji-cun-noji-pan-moderuwoshi-robotutoniying-yong-surufang-fa target='_blank'>[Slide]</a></li>
<li>松嶋 達也, <b><u>河原塚 健人</u></b><br>基盤モデルの実ロボット応用 - チュートリアル2, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1K3-02, 2023<br> <a href=https://speakerdeck.com/tmats/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru2-shi-robotutoyong-noji-pan-moderuwozuo-tutehuo-yong-surufang-fa target='_blank'>[Slide]</a></li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>調理ロボットのための基盤モデル利用によるレシピ記述からの卵料理の食材状態変化認識と動作シーケンス生成, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1K3-03, 2023</li>
<li>呉 知勳, <b><u>河原塚 健人</u></b>, 石田 寛和, 岡田 慧, 稲葉 雅幸<br>実時間物体追跡を用いた視覚的変化にロバストなロボットのVisuomotor方策獲得システム, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1K3-07, 2023</li>
<li>大日方 慶樹, 金沢 直晃, <b><u>河原塚 健人</u></b>, 矢野倉 伊織, 金 淳暁, 岡田 慧, 稲葉 雅幸<br>大規模言語モデルによるタスク実行管理器生成法とRoboCup JapanOpen @Home League GPSRタスクへの応用, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1K4-05, 2023, <b><font color='red'>日本ロボット学会第5回優秀講演賞</font></b></li>
<li>塚本 直人, <b><u>河原塚 健人</u></b>, 市倉 愛子, 岡田 慧, 稲葉 雅幸<br>大規模視覚-言語モデルとデータベースを用いたロボットの記憶蓄積とユーザーへの共有, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1K4-07, 2023</li>
<li>井上 信多郎, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>椅子型非対称三脚移動ロボットの身体設計と歩容生成, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 2D1-04, 2023</li>
<li>鈴木 天馬, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>ワイヤ干渉駆動アームによる高速打撃動作実現, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 3E4-02, 2023</li>
<li>勇崎 颯太, 鈴木 天馬, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>ワイヤ駆動型3次元空中移動装置のシミュレーションによる検討, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1D2-01, 2023</li>
<li>小塚 陽希, 趙 漠居, 西尾 卓純, 唐 安南, <b><u>河原塚 健人</u></b>, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>実機検証に基づく時間遅れに着目したマルチロータ障害物回避のための汎用的な学習方策の構築, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 2H3-05, 2023</li>
<li>吉村 駿之介, 鈴木 天馬, 勇崎 颯太, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>多目的ブラックボックス最適化とモデル予測制御による拮抗ワイヤ駆動脚の筋配置生成, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 3I3-07, 2023</li>
<li>三木 章寛, 佐原 侑太, 深山 和浩, 吉村 駿之介, 李林 嘉元, 長谷川 峻, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>人間の関節可動域を満たす模擬靭帯構成法の基礎的検討, in <i>第41回日本ロボット学会学術講演会 (<b>RSJ23J</b>)</i>, 1B3-03, 2023</li>
<li><b><u>河原塚 健人</u></b>, 真壁 佑, 岡田 慧, 稲葉 雅幸<br>多目的ブラックボックス最適化に基づく作業支援モジュラーロボット設計, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1P1-G13, 2023</li>
<li><b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>制約付き模倣学習によるロボットの腹腔鏡手術の基本技能訓練, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 2P2-B22, 2023</li>
<li>吉村 駿之介, 鈴木 天馬, 板東 正祐, 勇崎 颯太, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>脚と尻尾を有するカンガルーロボットの構成法と跳躍動作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1A1-E19, 2023, <b><font color='red'>日本機械学会若手優秀講演フェロー賞</font></b></li>
<li>深山 和浩, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>五指を有する表皮骨格一体型ロボットハンドの製作, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1A1-F23, 2023</li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Object size based fingertip workspace processing for acceleration of grasp pose generation, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1A1-F24, 2023</li>
<li>勇崎 颯太, 三木 章寛, 板東 正祐, 吉村 駿之介, 鈴木 天馬, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>環境を利用した身体能力拡張行動のための可動カラビナワイヤモジュールの設計と動作実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1A1-I11, 2023</li>
<li>市倉 愛子, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>ロボットのお散歩体験日記 - 記述内容の違いによる読者の感想比較, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1A2-C26, 2023</li>
<li>鈴木 天馬, 板東 正祐, <b><u>河原塚 健人</u></b>, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>3次元受動ワイヤ整列装置の製作と7自由度マニュピレータへの適用, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1A1-H16, 2023</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 石田 寛和, 岡田 慧, 稲葉 雅幸<br>反復自動データ収集を用いた模倣学習による環境設備操作タスクの実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1P1-D05, 2023</li>
<li>大日方 慶樹, <b><u>河原塚 健人</u></b>, 金沢 直晃, 山口 直也, 塚本 直人, 矢野倉 伊織, 北川 晋吾, 岡田 慧, 稲葉 雅幸<br>大規模視覚-言語モデルとチャットインタフェースを用いた生活環境の分類とロボットタスクマッピングシステム, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 1P1-D06, 2023</li>
<li>小塚 陽希, 趙 漠居, 西尾 卓純, 唐 安南, <b><u>河原塚 健人</u></b>, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>汎用的なマルチロータに適応可能な学習方策による障害物回避動作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 2A2-D10, 2023, <b><font color='red'>日本ロボット学会第2回若手講演賞</font></b></li>
<li>三木 章寛, <b><u>河原塚 健人</u></b>, 板東 正祐, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>脱着可能なワイヤモジュールを用いた環境物自在操作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 2P1-C25, 2023</li>
<li>李林 嘉元, 深山 和浩, 三木 章寛, <b><u>河原塚 健人</u></b>, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>ワイヤ巻取式筋腱複合体駆動の製作と二次元的ロボット構成における検証, in <i>日本機械学会ロボティクス・メカトロニクス講演会'23 (<b>ROBOMECH23J</b>)</i>, 2P2-D19, 2023</li>
<li><b><u>河原塚 健人</u></b>, 大日方 慶樹, 金沢 直晃, 岡田 慧, 稲葉 雅幸<br>日常生活支援ロボットに向けた大規模視覚-言語モデルと進化的計算に基づく状態認識, in <i>第37回人工知能学会全国大会 (<b>JSAI23J</b>)</i>, 3G1-OS-24a-04, 2023</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>大規模基盤モデル利用による料理レシピ記述からの食材状態変化を考慮した調理認識計画行動ロボットシステム, in <i>第37回人工知能学会全国大会 (<b>JSAI23J</b>)</i>, 3G1-OS-24a-02, 2023</li>
<li><b><u>河原塚 健人</u></b>, 金沢 直晃, 岡田 慧, 稲葉 雅幸<br>低剛性ロボットの身体変化を考慮した自律的視覚サーボ学習, in <i>第23回SICEシステムインテグレーション部門講演会 (<b>SI22J</b>)</i>, 3P2-H07, 2022</li>
<li>楠山 大樹, 真壁 佑, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>ヒト・ロボットを運搬可能なモビリティのバランス制御, in <i>第23回SICEシステムインテグレーション部門講演会 (<b>SI22J</b>)</i>, 1A2-D02, 2022</li>
<li>李林 嘉元, 深山 和浩, 三木 章寛, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>ワイヤ巻取式筋腱複合体駆動によるロボット構成の基礎的検討, in <i>第23回SICEシステムインテグレーション部門講演会 (<b>SI22J</b>)</i>, 1P3-E09, 2022</li>
<li>金 淳暁, 北川 晋吾, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>RGB 画像による髪の乱雑領域認識と圧力センサを付けた櫛による頭皮接触認識を用いたロボット整髪システムの研究, in <i>第23回SICEシステムインテグレーション部門講演会 (<b>SI22J</b>)</i>, 3A2-B08, 2022</li>
<li>三木 章寛, 板東 正祐, 永松 祐弥, <b><u>河原塚 健人</u></b>, 利光 泰徳, 平岡 直樹, 岡田 慧, 稲葉 雅幸<br>軸駆動, 腱駆動, 台車型, 既製品を含む多様なロボットを扱うためのハードウェア抽象化デバイス制御プラットフォーム開発, in <i>第23回SICEシステムインテグレーション部門講演会 (<b>SI22J</b>)</i>, 3A2-E16, 2022</li>
<li><b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>一般化多感覚相関モデル学習に基づく身体図式の獲得と認識制御, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 1F1-03, 2022</li>
<li><b><u>河原塚 健人</u></b>, 鈴木 天馬, 岡田 慧, 稲葉 雅幸<br>パラレルワイヤ駆動一本脚跳躍ロボットRAMIELの強化学習に基づく連続跳躍動作の実現, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 2F3-05, 2022</li>
<li>真壁 佑, <b><u>河原塚 健人</u></b>, 永松 祐弥, 安斎 智紀, 菅井 文仁, 岡田 慧, 稲葉 雅幸<br>セルフロック減速機構と冗長センサを備えたサーボモジュールの設計開発と多関節アームにおける応用, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 2K1-06, 2022</li>
<li>勇崎 颯太, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>家庭用3Dプリンタで自作可能な大型ベアリング・サイクロイド減速機サーボモジュールの開発, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 2K1-07, 2022</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 石田 寛和, 岡田 慧, 稲葉 雅幸<br>ロボットの反復 pick-and-place 自動データ収集によるOne-Shot 教示把持動作スキル学習システム, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 3F1-03, 2022</li>
<li>鈴木 天馬, <b><u>河原塚 健人</u></b>, 深山 和浩, 岡田 慧, 稲葉 雅幸<br>無減速ワイヤ干渉駆動を用いた軽量・バックドライバブルなロボットアームの開発, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 3E2-03, 2022</li>
<li>石田 寛和, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>分節化型Behavioral Cloningとモジュール性に着目したその有効条件の説明, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 3F2-02, 2022</li>
<li>吉村 駿之介, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>3Dプリンタとサーボモジュールで製作可能なアームで体重を支持し移動する車輪型腱駆動ロボットの開発, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 4E1-07, 2022</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>Parametric Bias を用いた食材特徴を考慮可能な調理ロボットの包丁切断操作学習, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 4I1-06, 2022</li>
<li>深山 和浩, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>表皮と骨格を一体で3Dプリンティングする腱駆動ソフトロボットハンドの開発, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 4K2-08, 2022</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>Parametric Bias を用いた食材特徴を考慮可能な調理ロボットの包丁切断操作学習, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 4I1-06, 2022</li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Taxonomy-aware workspace-based grasp pose generation, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 1J1-04, 2022</li>
<li>三木 章寛, 板東 正祐, <b><u>河原塚 健人</u></b>, 李林 嘉元, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドによる動作周期の探索に基づくロープ投げ操作の実現, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 4E1-05, 2022</li>
<li>李林 嘉元, 三木 章寛, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>腱駆動ヒューマノイドによるスティック把持状態と剛性の変化を利用したドラムロール実現, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 4E1-06, 2022</li>
<li>新城 光樹, 大日方 慶樹, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>移動ロボットのフロア間移動のためのマルチセンサ・IoTスイッチによるエレベータ状態認識・操作システム, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 1D1-05, 2022</li>
<li>小塚 陽希, 趙 漠居, <b><u>河原塚 健人</u></b>, 唐 安南, 岡田 慧, 稲葉 雅幸<br>強化学習を用いた動的障害物環境下でのマルチロータ高速移動, in <i>第40回日本ロボット学会学術講演会 (<b>RSJ22J</b>)</i>, 1G1-02, 2022</li>
<li><b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>Parametric Biasを含む深層予測モデル学習と多様な実ロボットへの応用, in <i>第36回人工知能学会全国大会 (<b>JSAI22J</b>)</i>, 2M5-OS-19c-01, 2022</li>
<li><b><u>河原塚 健人</u></b>, 三木 章寛, 利光 泰徳, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける筋増加を考慮可能な適応的身体図式学習システム, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2A2-I10, 2022</li>
<li><b><u>河原塚 健人</u></b>, 三木 章寛, 板東 正祐, 岡田 慧, 稲葉 雅幸<br>深層予測モデル学習による可変剛性と素材変化を考慮した動的柔軟布操作, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2A1-O05, 2022, <b><font color='red'>ベストデモンストレーション賞</font></b></li>
<li>利光 泰徳, <b><u>河原塚 健人</u></b>, 三木 章寛, 岡田 慧, 稲葉 雅幸<br>密画像ヤコビアンの推定法DIJEとビジュアルサーボ制御への応用, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2A2-I09, 2022</li>
<li>若林 隼平, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>操作教示に基づく補助必要度を考慮した食器類の濯ぎと擦り動作学習, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2A1-O06, 2022</li>
<li>板東 正祐, <b><u>河原塚 健人</u></b>, 三木 章寛, 岡田 慧, 稲葉 雅幸<br>双腕ロボットによるロープ回し動作の目標手先軌道生成, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2A1-N08, 2022</li>
<li>深山 和浩, 長谷川 峻, <b><u>河原塚 健人</u></b>, 山口 直也, 岡田 慧, 稲葉 雅幸<br>神経内包柔軟表皮を有し道具使用を行う五指ハンドの開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2A1-K02, 2022</li>
<li>李林 嘉元, <b><u>河原塚 健人</u></b>, 利光 泰徳, 楠山 大樹, 三木 章寛, 新城 光樹, 板東 正祐, 鈴木 天馬, 小椎尾 侑多, 岡田 慧, 稲葉 雅幸<br>側面力覚を有するロボットフットによる椅子着座状態における回転動作制御, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 1P1-T07, 2022</li>
<li>李林 嘉元, <b><u>河原塚 健人</u></b>, 利光 泰徳, 楠山 大樹, 三木 章寛, 新城 光樹, 板東 正祐, 鈴木 天馬, 小椎尾 侑多, 岡田 慧, 稲葉 雅幸<br>人体の足裏外周縁接触圧分布計測装置を用いたロボット脚による模倣行動の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 1P1-T08, 2022</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>Parametric Biasを用いた調理ロボットの包丁切断操作における食材特徴学習, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 1A1-T11, 2022</li>
<li>鈴木 天馬, 利光 泰徳, 永松 祐弥, <b><u>河原塚 健人</u></b>, 三木 章寛, 李林 嘉元, 板東 正祐, 小島 邦生, 垣内 洋平, 岡田 慧, 稲葉 雅幸<br>パラレルワイヤ型一本脚跳躍ロボットRAMIELの設計と跳躍動作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2P1-L10, 2022, <b><font color='red'>ベストデモンストレーション賞</font></b></li>
<li><b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>逐次的な把持状態変化を考慮した適応的道具先端操作学習, in <i>第22回SICEシステムインテグレーション部門講演会 (<b>SI21J</b>)</i>, 1D2-04, 2021</li>
<li><b><u>河原塚 健人</u></b>, 新城 光樹, 河村 洋一郎, 岡田 慧, 稲葉 雅幸<br>確率的深層予測モデル学習による分散最小化を含む環境適応型制御 - 台車型ロボットへの適用 -, in <i>第22回SICEシステムインテグレーション部門講演会 (<b>SI21J</b>)</i>, 1H3-02, 2021, <b><font color='red'>優秀講演賞</font></b></li>
<li>三木 章寛, <b><u>河原塚 健人</u></b>, 板東 正祐, 岡田 慧, 稲葉 雅幸<br>台車型筋骨格ヒューマノイドによる布操作を含んだ一連のテーブルセッティング動作の実現, in <i>第22回SICEシステムインテグレーション部門講演会 (<b>SI21J</b>)</i>, 1D2-03, 2021</li>
<li><b><u>河原塚 健人</u></b>, 河村 洋一郎, 岡田 慧, 稲葉 雅幸<br>Parametric Biasを用いた動作スタイルを制約可能な模倣学習, in <i>第39回日本ロボット学会学術講演会 (<b>RSJ21J</b>)</i>, 1I3-01, 2021</li>
<li><b><u>河原塚 健人</u></b>, 西浦 学, 大村 柚介, 古賀 悠矢, 利光 泰徳, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>機能的・空間的接続を利用した冗長なセンサ・アクチュエータの自動分割: 筋骨格ヒューマノイドの筋分割への適用, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 1A1-D06, 2021</li>
<li><b><u>河原塚 健人</u></b>, 利光 泰徳, 西浦 学, 古賀 悠矢, 大村 柚介, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋破断を補償する冗長性を最大限活用した筋骨格ヒューマノイドの設計最適化, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 2P3-H04, 2021</li>
<li>古賀 悠矢, <b><u>河原塚 健人</u></b>, 利光 泰徳, 西浦 学, 大村 柚介, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋骨格ヒューマノイドの肩複合体における冗長性を活かした姿勢生成と物体操作を目的とした自己身体像の実機学習, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 1A1-D07, 2021</li>
<li>若林 隼平, 北川 晋吾, <b><u>河原塚 健人</u></b>, 室岡 貴之, 岡田 慧, 稲葉 雅幸<br>視覚情報に基づく食器類の把持の冗長性を考慮した自己教師あり把持学習, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 1A1-F09, 2021</li>
<li>大村 柚介, <b><u>河原塚 健人</u></b>, 永松 祐弥, 古賀 悠矢, 西浦 学, 利光 泰徳, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋骨格ヒューマノイドによる人体模倣両耳聴を用いた視野外環境認識行動, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 2A1-I15, 2021</li>
<li>西浦 学, <b><u>河原塚 健人</u></b>, 利光 泰徳, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>接触状態を含む身体モデルと強化学習を用いた筋骨格ヒューマノイドによる環境接触行動, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 2A1-I16, 2021</li>
<li>利光 泰徳, <b><u>河原塚 健人</u></b>, 西浦 学, 古賀 悠矢, 大村 柚介, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋骨格ヒューマノイド腕部の筋・関節冗長性を活用したタスク空間における制御, in <i>日本機械学会ロボティクス・メカトロニクス講演会'21 (<b>ROBOMECH21J</b>)</i>, 2P2-G15, 2021</li>
<li><b><u>河原塚 健人</u></b>, 小川 徹, 鍋嶌 厚太<br>ニューラルネットワークの誤差逆伝播による道具形状最適化, in <i>第21回SICEシステムインテグレーション部門講演会 (<b>SI20J</b>)</i>, 3D3-05, 2020, <b><font color='red'>優秀講演賞</font></b></li>
<li><b><u>河原塚 健人</u></b>, 平岡 直樹, 都築 敬, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>温度モデルパラメータのオンライン学習を用いたモータコア温度推定と制御: 筋骨格ヒューマノイドへの適用, in <i>第21回SICEシステムインテグレーション部門講演会 (<b>SI20J</b>)</i>, 2F3-14, 2020</li>
<li><b><u>河原塚 健人</u></b>, 古賀 悠矢, 都築 敬, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>拮抗筋抑制制御と拮抗筋予見伸長制御による冗長な筋を有する筋骨格ヒューマノイドの最大関節速度を突破する動作戦略, in <i>第21回SICEシステムインテグレーション部門講演会 (<b>SI20J</b>)</i>, 2D2-08, 2020</li>
<li>大村 柚介, <b><u>河原塚 健人</u></b>, 永松 祐弥, 古賀 悠矢, 西浦 学, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>人体外耳機構を模したヒューマノイドの両耳間スペクトル差学習に基づく空間音源方向推定システム, in <i>第21回SICEシステムインテグレーション部門講演会 (<b>SI20J</b>)</i>, 1C3-17, 2020</li>
<li><b><u>河原塚 健人</u></b>, 都築 敬, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>Parametric Biasを含む再帰型ニューラルネットワークを用いた柔軟ハンドの物体認識・動的接触制御/検知/シミュレーション, in <i>第38回日本ロボット学会学術講演会 (<b>RSJ20J</b>)</i>, 2A1-05, 2020</li>
<li>鬼塚 盛宇, 西浦 学, <b><u>河原塚 健人</u></b>, 都築 敬, 利光 泰徳, 大村 柚介, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>面状骨格間構造を利用し広い可動域においてモーメントアームを確保し高出力での環境接触動作が可能な筋骨格脚の開発, in <i>第38回日本ロボット学会学術講演会 (<b>RSJ20J</b>)</i>, 2G2-08, 2020</li>
<li>利光 泰徳, <b><u>河原塚 健人</u></b>, 都築 敬, 鬼塚 盛宇, 西浦 学, 古賀 悠矢, 大村 柚介, 冨田 幹, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>Motor Directional Tuning現象に基づく筋張力制御による筋骨格ヒューマノイドの上肢動作, in <i>日本機械学会ロボティクス・メカトロニクス講演会'20 (<b>ROBOMECH20J</b>)</i>, 1P1-G05, 2020</li>
<li>大村 柚介, <b><u>河原塚 健人</u></b>, 永松 祐弥, 都築 敬, 鬼塚 盛宇, 古賀 悠矢, 西浦 学, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>外耳構造を有し音響処理を行う人体模倣ヒューマノイドの耳機構の設計開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'20 (<b>ROBOMECH20J</b>)</i>, 1A1-E12, 2020</li>
<li><b><u>河原塚 健人</u></b>, 都築 敬, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>Musculoskeletal AutoEncoder: 筋骨格ヒューマノイドの状態推定・制御・シミュレーションを統一的に扱う筋骨格センサ間ネットワークのオンライン獲得手法, in <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 3B3-06, 2019, <b><font color='red'>第35回研究奨励賞</font></b></li>
<li><b><u>河原塚 健人</u></b>, 小川 徹, 田村 淳太郎, 鍋嶌 厚太<br>深層学習を用いた関節トルク入力による動的な柔軟物体操作, in <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 1A2-06, 2019, <b><font color='red'>第35回研究奨励賞</font></b></li>
<li>中島 慎介, <b><u>河原塚 健人</u></b>, 浅野 悠紀, 垣内 洋平, 岡田 慧, 稲葉 雅幸<br>自己修復張力伝達モジュールを備える腱駆動脚ロボットの開発, in <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 1K3-01, 2019</li>
<li>西浦 学, <b><u>河原塚 健人</u></b>, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける環境物体に応じた適応的剛性レンジ選択とその可変剛性制御戦略の獲得, in <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 1K3-06, 2019</li>
<li>浅野 悠紀, 都築 敬, <b><u>河原塚 健人</u></b>, 鬼塚 盛宇, 古賀 悠矢, 大村 柚介, 永松 祐弥, 真壁 佑, 藤井 綺香, 新城 光樹, 中島 慎介, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>腱駆動ヒューマノイドにおける認識判断操作統合に基づく自動車運転の実証実験, in <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 3L2-06, 2019</li>
<li><b><u>河原塚 健人</u></b>, 牧野 将吾, 都築 敬, 鬼塚 盛宇, 永松 祐弥, 新城 光樹, 真壁 佑, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>学習制御模索のためのモジュラー型筋骨格プラットフォームの設計開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 2P1-C06, 2019</li>
<li><b><u>河原塚 健人</u></b>, 都築 敬, 牧野 将吾, 鬼塚 盛宇, 新城 光樹, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋骨格ヒューマノイドにおけるタスク特化した動的自己身体制御の獲得 - 自動運転におけるペダル操作への応用 -, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 1A1-L08, 2019</li>
<li>真壁 佑, 白井 拓磨, 永松 裕弥, <b><u>河原塚 健人</u></b>, 菅井 文仁, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>用途適応型ロボットのための、駆動時二段可変減速非駆動時ロック機構を持つ関節モジュールの設計開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 2A2-F08, 2019</li>
<li>都築 敬, <b><u>河原塚 健人</u></b>, 真壁 佑, 鬼塚 盛宇, 牧野 将吾, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>可動眼球と自己身体を用いた距離認識機能の獲得, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 1A1-M10, 2019</li>
<li>大村 柚介, <b><u>河原塚 健人</u></b>, 牧野 将吾, 鬼塚 盛宇, 新城 光樹, 都築 敬, 古賀 悠矢, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける時系列聴覚情報を用いた打音認識に基づく動作獲得, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K03, 2019</li>
<li>古賀 悠矢, <b><u>河原塚 健人</u></b>, 牧野 将吾, 鬼塚 盛宇, 真壁 佑, 都築 敬, 大村 柚介, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドのダイナミック動作における筋の拮抗関係と手先軌道の修正, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K02, 2019</li>
<li>新城 光樹, <b><u>河原塚 健人</u></b>, 浅野 悠紀, 中島 慎介, 牧野 将吾, 鬼塚 盛宇, 都築 敬, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>コア・シェル構造を有する6軸力計測モジュールをつま先・踵に持つ足部ユニットを用いた等身大筋骨格腱駆動ヒューマノイドによるペダル踏み・復帰動作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K01, 2019</li>
<li>鬼塚 盛宇, <b><u>河原塚 健人</u></b>, 牧野 将吾, 新城 光樹, 都築 敬, 中島 慎介, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける面状牽引構造を有する関節の開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'19 (<b>ROBOMECH19J</b>)</i>, 1A1-J02, 2019</li>
<li><b><u>河原塚 健人</u></b>, 都築 敬, 牧野 将吾, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格構造における長期的自己身体像獲得と可変剛性制御の実現, in <i>第36回日本ロボット学会学術講演会 (<b>RSJ18J</b>)</i>, 1J2-02, 2018</li>
<li><b><u>河原塚 健人</u></b>, 真壁 佑, 牧野 将吾, 都築 敬, 永松 祐弥, 浅野 悠紀, 白井 拓磨, 菅井 文仁, 岡田 慧, 稲葉 雅幸<br>環境接触を伴う学習型制御研究のための筋骨格型倒立二輪ロボットの開発, in <i>第36回日本ロボット学会学術講演会 (<b>RSJ18J</b>)</i>, 1P2-02, 2018</li>
<li>都築 敬, <b><u>河原塚 健人</u></b>, 鬼塚 盛宇, 真壁 佑, 牧野 将吾, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドによる自動車運転動作の実現に向けたペダル操作戦略, in <i>第36回日本ロボット学会学術講演会 (<b>RSJ18J</b>)</i>, 2P1-05, 2018</li>
<li>鬼塚 盛宇, 真壁 佑, <b><u>河原塚 健人</u></b>, 牧野 将吾, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける脚全体の筋に基づく筋張力 ZMP を用いた平衡動作, in <i>第36回日本ロボット学会学術講演会 (<b>RSJ18J</b>)</i>, 1J2-05, 2018</li>
<li><b><u>河原塚 健人</u></b>, 牧野 将吾, 陳 相羽, 藤井 綺香, 川村 将矢, 真壁 佑, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>擬似球関節モジュールにより冗長な非線形弾性要素を制御可能な筋骨格ヒューマノイドの上肢設計, in <i>日本機械学会ロボティクス・メカトロニクス講演会'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G09, 2018</li>
<li>牧野 将吾, <b><u>河原塚 健人</u></b>, 藤井 綺香, 川村 将矢, 真壁 佑, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>組み合わせ切削ばねによる広可動域関節母指関節と可変剛性指関節をもつ人体模倣型五指ハンドの開発, in <i>日本機械学会ロボティクス・メカトロニクス講演会'18 (<b>ROBOMECH18J</b>)</i>, 1P1-H16, 2018</li>
<li>真壁 佑, <b><u>河原塚 健人</u></b>, 牧野 将吾, 川村 将矢, 藤井 綺香, 鬼塚 盛宇, 浅野 悠紀, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける可動眼球の開発と車両見回し発進動作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G11, 2018</li>
<li>浅野 悠紀, 川村 将矢, <b><u>河原塚 健人</u></b>, 牧野 将吾, 藤井 綺香, 真壁 佑, 鬼塚 盛宇, 岡田 慧, 川崎 宏治, 稲葉 雅幸<br>人体模倣筋骨格ヒューマノイドにおける筋張力を用いた関節空間コントローラによる車両ペダル操作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G07, 2018</li>
<li>藤井綺香, 中島慎介, 川村将矢, <b><u>河原塚健人</u></b>, 牧野将吾, 浅野悠紀, 岡田慧, 稲葉雅幸<br>人体の関節包構造に示唆を得た柔軟で伸縮変形可能な膜構造を備えた開放型球関節の開発, in <i>第18回SICEシステムインテグレーション部門講演会 (<b>SI17J</b>)</i>, 3B4-02, 2017</li>
<li><b><u>河原塚 健人</u></b>, 牧野 将吾, 川村 将矢, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドにおける視覚を利用した関節-筋空間マップの逐次的再学習, in <i>第35回日本ロボット学会学術講演会 (<b>RSJ17J</b>)</i>, 2L1-01, 2017</li>
<li><b><u>河原塚 健人</u></b>, 牧野 将吾, 川村 将矢, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>骨構造一体小型筋モジュールにより構成された橈骨尺骨構造を有する前腕部の設計, in <i>日本機械学会ロボティクス・メカトロニクス講演会'17 (<b>ROBOMECH17J</b>)</i>, 1A1-O11, 2017</li>
<li>牧野 将吾, <b><u>河原塚 健人</u></b>, 川村 将矢, 浅野 悠紀, 岡田 慧, 稲葉 雅幸<br>筋骨格ヒューマノイドのための切削ばねによる柔軟関節を備えた五指ハンドの開発と自己身体負荷保持動作の実現, in <i>日本機械学会ロボティクス・メカトロニクス講演会'17 (<b>ROBOMECH17J</b>)</i>, 2P1-B08, 2017, <b><font color='red'>若手優秀講演フェロー賞</font></b></li>
</ol>
<h3> Invited Talks, Books, etc.</h3>
<ol>
<li><b><u>河原塚 健人</u></b><br>ヒューマノイドと基盤モデル, in <i>LLM-jp 実環境インタラクションWG</i>, 2025.2.14</li>
<li><b><u>河原塚 健人</u></b><br>ロボットにおけるData-centric AI, in <i>第13回 Data-Centric AI勉強会 -Data-centric AI入門 著者LT大会-</i>, 2025.2.12</li>
<li>片岡 裕雄 (監修), 齋藤邦章, 清野舜, 小林滉河, <b><u>河原塚 健人</u></b>, 宮澤 一之, 鈴木 達哉<br>Data-centric AI入門, in <i>技術評論社</i>, 2025.01.08<br> <a href=https://gihyo.jp/book/2025/978-4-297-14663-4 target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>The Point of Tendon-driven Musculoskeletal Humanoids, Invited Talk, in <i>VANJ (Vietnamese Academic Network in Japan) Conference</i>, 2024.12.07<br> <a href=https://conf.vanj.jp/2024/speakers/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>History and Future of Tendon-driven Musculoskeletal Humanoids, in <i>TAI AHR #03 - AI in Hardware and Robotics</i>, 2024.12.06<br> <a href=https://lu.ma/ppgh4amz target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>History and Future of Tendon-driven Musculoskeletal Humanoids, Plenary Talk, in <i>2024 IEEE International Conference on Humanoid Robots (Humanoids)</i>, 2024.11.23<br> <a href=https://2024.ieee-humanoids.org/plenaries/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Building Intelligent Robots: From Musculoskeletal Humanoids to Foundation Models, in <i>Seminar at KIT, Karlsruhe</i>, 2024.11.20</li>
<li><b><u>河原塚 健人</u></b><br>IROS/ICRAのワークショップ開催の経験と展望 ~ Cooking Robotics Workshop@ICRA 2024を主催して ~, in <i>第42回日本ロボット学会学術講演会 学術ランチョンセミナー</i>, 2024.9.5<br> <a href=https://speakerdeck.com/haraduka/rsj2024xue-shu-rantiyonsemina-ruo-shou-zhong-jian-niyoruguo-ji-hua-ridasitupunixiang-kete-zi-liao-he-yuan-zhong target='_blank'>[Slide]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at DLR, Oberpfaffenhofen</i>, 2024.7.31</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at TUM, Munich</i>, 2024.7.30</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at Max Planck Institute, Tubingen</i>, 2024.7.29</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at EPFL, Lausanne</i>, 2024.7.5</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>CRL Seminar at ETH Zurich</i>, 2024.6.28</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Postdoc Seminar at IIT, Genova</i>, 2024.6.20</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Robotic Imitation Learning for Biomedical Applications, in <i>Symposium on Robotics in Biomedical Applications</i>, 2024.6.17<br> <a href=https://sites.google.com/view/srbm/home target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>LLM・VLMの実ロボット応用例とその分類, 講師, in <i>第152回ロボット工学セミナー「ロボットのためのLLM・VLM 利活用」</i>, 2024.5.23<br> <a href=https://www.rsj.or.jp/event/seminar/news/2024/s152.html target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>基盤モデルを用いたロボットの動作計画と制御, 招待講演, in <i>ROS Japan UG #55 Planner特集！</i>, 2024.5.21<br> <a href=https://rosjp.connpass.com/event/313794/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>What is Necessary to Cook Curry with a Robot?, Workshop on "Cooking Robotics: Perception and motion planning", in <i>2024 IEEE International Conference on Robotics and Automation (ICRA)</i>, 2024.5.17<br> <a href=https://sites.google.com/view/icra2024cookingrobotics/home target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Tendon-driven Musculoskeletal Humanoids and Beyond, Workshop on "From Layers to Limbs! Exploring the Interface of 3D Printing and Bio-Inspired Musculoskeletal Robotics", in <i>2024 IEEE International Conference on Soft Robotics (RoboSoft)</i>, 2024.4.14<br> <a href=https://printed-musculoskeletal-robots.ethz.ch/ target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>ロボット研究におけるLLMの実世界応用, 招待講演, in <i>NLP2024併設ワークショップ「大規模言語モデルの実世界応用」</i>, 2024.3.15<br> <a href=https://sites.google.com/grp.riken.jp/langrobonlp2024 target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>筋骨格ヒューマノイドと身体図式学習, 招待講演, in <i>第19回身体性認知科学と実世界応用に関する若手研究会(ECSRA)</i>, 2023.10.29<br> <a href=https://sites.google.com/site/ecsrawebsite/%E8%BA%AB%E4%BD%93%E6%80%A7%E8%AA%8D%E7%9F%A5%E7%A7%91%E5%AD%A6%E3%81%A8%E5%AE%9F%E4%B8%96%E7%95%8C%E5%BF%9C%E7%94%A8%E3%81%AB%E9%96%A2%E3%81%99%E3%82%8B%E8%8B%A5%E6%89%8B%E7%A0%94%E7%A9%B6%E4%BC%9A-ecsra target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>大規模言語モデルの実ロボット応用例, 招待講演, in <i>第5回LLM勉強会(LLM-jp)</i>, 2023.10.18<br> <a href=https://llm-jp.nii.ac.jp/llm/2023/10/18/meeting-5.html target='_blank'>[Website]</a></li>
<li><b><u>K. Kawaharazuka</u></b><br>Learning-based manipulation and grasping with flexible arms and hands, Workshop on "Learning Meets Model-based Methods for Manipulation and Grasping", in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2023.10.5<br> <a href=https://sites.google.com/view/learning-meets-models-iros2023/speakers?authuser=0 target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>大規模言語モデルの実ロボットタスク応用, 招待セッション, in <i>NLP若手の会 第18回シンポジウム (YANS2023)</i>, 2023.8.31<br> <a href=https://yans.anlp.jp/entry/yans2023invitesession target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>脱力可能なヒューマノイドの身体と制御, ロボティクス・メカトロニクス講演会2023シンポジウム「"いいかげん"を科学して未来を創るソフトロボット学4」, in <i>日本機械学会ロボティクス・メカトロニクス講演会</i>, 2023.6.28<br> <a href=https://softrobot.jp/events/2023/06161205082540/ target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>身体図式の自律獲得機能を有する知能ロボットシステムとサイエンス開拓, 若手研究者が描く2050年のAIロボットビジョン (オープンフォーラム: ムーンショット型研究で目指すAIロボット), in <i>第40回日本ロボット学会学術講演会</i>, 2022.9.9<br> <a href=https://ac.rsj-web.org/2022/openforum.html#OF5 target='_blank'>[Website]</a></li>
<li><b><u>河原塚 健人</u></b><br>身体図式の逐次学習機能を有する知能ロボットシステムの研究, in <i>博士論文</i>, <b><font color='red'>研究科長賞</font></b>, 2022.3.24</li>
<li><b><u>河原塚 健人</u></b><br>深層予測モデル学習によるロボットの時間的・空間的柔軟性攻略, キーノート講演 (OS: 確率ロボティクスとデータ工学ロボティクス～認識・行動学習・記号創発～), in <i>第39回日本ロボット学会学術講演会</i>, 2021.9.6</li>
</ol>
        <!-- publication_replace_by_python -->

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Awards (Publication) </h2>
        </div>

<ol>
<li>S. Kim, N. Kanazawa, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Best Student Paper Finalist, <i>2025 IEEE/SICE International Symposium on System Integration (<b>SII2025</b>)</i>, 2025.1.24</li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, Y. Ribayashi, Y. Sahara, K. Okada<br>Mike Stillman Award, <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, 2024.11.24</li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada<br>Excellent Practice Award, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, (<b>Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects</b>), 2024.10.14</li>
<li>Open X-Embodiment Collaboration<br>Finalists of Best Paper Award in Robot Manipulation, <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, 2024.5.16</li>
<li>Open X-Embodiment Collaboration<br>Best Conference Paper Award, <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, 2024.5.16</li>
<li>金沢 直晃, <b><u>河原塚 健人</u></b>, 大日方 慶樹, 岡田 慧, 稲葉 雅幸<br>優秀講演賞, <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 2023.12.16</li>
<li>三木 章寛, 佐原 侑太, 深山 和浩, 李林 嘉元, 長谷川 峻, <b><u>河原塚 健人</u></b>, 岡田 慧, 稲葉 雅幸<br>優秀講演賞, <i>第24回SICEシステムインテグレーション部門講演会 (<b>SI23J</b>)</i>, 2023.12.15</li>
<li>三木 章寛, 板東 正祐, 永松 祐弥, <b><u>河原塚 健人</u></b>, 利光 泰徳, 平岡 直樹, 岡田 慧, 稲葉 雅幸<br>第3回日本ロボット学会ロボティクスシンポジア優秀研究・技術賞, <i>第28回ロボティクスシンポジア (<b>ROBOSYM23J</b>)</i>, 2023.9.13</li>
<li><b><u>河原塚 健人</u></b><br>ベストデモンストレーション賞, <i>日本機械学会ロボティクス・メカトロニクス講演会'22 (<b>ROBOMECH22J</b>)</i>, 2023.6.29</li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, T. Suzuki, Y. Ribayashi, Y. Toshimitsu, Y. Nagamatsu, K. Okada, M. Inaba<br>Best Interactive Paper Award Finalist, <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, 2022.11.30</li>
<li><b><u>K. Kawaharazuka</u></b><br>SICE International Young Authors Award (SIYA-IROS2022), <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, 2022.10.26</li>
<li><b><u>河原塚 健人</u></b><br>研究科長賞, <i>博士論文</i>, 2022.3.24</li>
<li><b><u>河原塚 健人</u></b>, 新城 光樹, 河村 洋一郎, 岡田 慧, 稲葉 雅幸<br>優秀講演賞, <i>第22回SICEシステムインテグレーション部門講演会 (<b>SI21J</b>)</i>, 2021.12.24</li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Finalists of Mike Stilman Paper Award, <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, 2021.7.21</li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Best Oral Paper Award, <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, 2021.7.21</li>
<li><b><u>河原塚 健人</u></b>, 小川 徹, 鍋嶌 厚太<br>優秀講演賞, <i>第21回SICEシステムインテグレーション部門講演会 (<b>SI20J</b>)</i>, 2020.12.25</li>
<li><b><u>河原塚 健人</u></b><br>第35回研究奨励賞, <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 2020.10.9</li>
<li><b><u>河原塚 健人</u></b><br>第35回研究奨励賞, <i>第37回日本ロボット学会学術講演会 (<b>RSJ19J</b>)</i>, 2020.10.9</li>
<li><b><u>K. Kawaharazuka</u></b><br>Company of Biologists Early Career Researcher Grant (500 GBP), <i>9th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2019</b>)</i>, 2019.8.20</li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, A. Fujii, T. Makabe, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>IROS ICROS Best Application Paper Award 2018 Finalists, <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, 2018.10.2</li>
<li><b><u>K. Kawaharazuka</u></b><br>IEEE RAS Japan Joint Chapter Young Award (2017), <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, 2017.9.24</li>
<li>Y. Asano, T. Kozuki, S. Ookubo, M. Kawamura, S. Nakashima, T. Katayama, Y. Iori, H. Toshinori, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Kakiuchi, K. Okada, M. Inaba<br>Best Interactive Paper Award Finalist, <i>2016 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2016</b>)</i>, 2016.11.17</li>
</ol>
          <!-- award_replace_by_python -->

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Awards and Experiences (Others) </h2>
        </div>
        <ol>
          <li>First Place (GPSR task in DSPL), RoboCup@Home JapanOpen2022, 2023.3.6 - 2023.3.9</li>
          <li>First Prize (state-based category), <a href="https://uzh-rpg.github.io/icra2022-dodgedrone/" target='_blank'>ICRA 2022 DodgeDrone Challenge</a>, 2022.5.26</li>
          <li>Part-time Enginner at <a href="https://www.preferred-networks.jp/en/" target='_blank'>Preferred Networks</a>, 2018.10 - 2020.3</li>
          <li>Internship at <a href="https://www.preferred-networks.jp/en/" target='_blank'>Preferred Networks</a>, 2018.8 - 2018.9</li>
          <li>Oral Presentation Award (Second Prize), <a href="http://deeplearning.jp/deeplearningday2018/" target='_blank'>Deep Learning Day 2018</a>, 2018.1.20</li>
          <li>Code Thanks Festival 2017, 2017.12.2</li>
          <li>Jaxa Award (Second Prize), <a href="http://moonhack.jp.klab.com/" target='_blank'>Moon Hack Hackathon 2017</a>, 2017.11.11 - 2017.11.12</li>
          <li>Final Round of Code Festival 2016, 2016.11.26 - 2016.11.27</li>
          <li>2nd RUNNER-UP and ABU ROBOCON AWARD, <a href="http://aburobocon.net/" target='_blank'>ABU Robot Contest 2016</a>, Clean Energy Recharging the World, 2016.8.21</li>
          <li>First Prize <a href="https://official-robocon.com/history/gakusei/about/history/twentyfive/" target='_blank'>NHK Student Robot Contest 2016</a>, Clean Energy Recharging the World, 2016.7.10</li>
          <li>Outstanding Performance Award, Internship at <a href="http://www.worksap.com/" target='_blank'>Works Applications Co., Ltd.</a>, 2016.3.4 - 2016.3.31</li>
          <li>Internship at <a href="http://www.futurestandard.co.jp/about/" target='_blank'>Future Standard Co., Ltd.</a>, 2016.1 - 2016.4</li>
          <li>Third Prize (Senior Division), <a href="http://www.lsse.kyutech.ac.jp/~sociorobo/ja/tomato-robot2015" target='_blank'>Tomato Robot Challenge</a>, 2015.12.18 - 2015.12.20</li>
          <li>Final Round of CODE RUNNER 2015, 2015.12.12</li>
          <li>Final Round of Code Festival 2015, 2015.11.14 - 2015.11.15</li>
          <li>Internship at <a href="https://www.hioki.com/en/" target='_blank'>HIOKI E.E. CORPORATION</a>, 2015.8.17 - 2015.8.28</li>
          <li>Technical Award, <a href="https://official-robocon.com/history/gakusei/about/history/twenty-fourth/" target='_blank'>NHK Student Robot Contest 2015</a>, ROBOMINTON:BADMINTON ROBO GAME (Pit Member), 2015.6.7</li>
          <li>Dowango Award (11/372), <a href="https://icpc.iisf.or.jp/2015-tsukuba/domestic/?lang=en" target='_blank'>ICPC Domestic Preliminary Contest</a>, 2015.6.26</li>
          <li>Final Round of <a href="http://www.ipsj.or.jp/event/samuraicoding/2014-15/index.html" target='_blank'>SamurAI Coding 2014-2015</a>, 2015.3.18</li>
          <li>Final Round of CODE RUNNER 2014, 30, November, 2014</li>
          <li>Technical Award, <a href="http://f3rcontest.web.fc2.com/index.html" target='_blank'>Freshman's Robot Contest 2013 (F^3RC)</a>, 2013.9.29</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Grants-in-Aid and Scholarship </h2>
        </div>
        <ol>
          <li> <b>CRONOS (分担)</b>, 科学技術振興機構 (JST), 2024.10 - 2030.3 </li>
          <li> <b>創発的研究支援事業 (代表)</b>, 科学技術振興機構 (JST), 2024.10 - 2032.3 </li>
          <li> <b>基盤研究B (代表)</b>, 日本学術振興会 (JSPS), 2023.4 - 2027.3 </li>
          <li> <b>挑戦的萌芽 (代表)</b>, 日本学術振興会 (JSPS), 2023.4 - 2026.3 </li>
          <li> <b>ACT-X加速フェーズ (代表)</b>, 科学技術振興機構 (JST), 2023.4 - 2024.3 </li>
          <li> <b>研究活動スタート支援 (代表)</b>, 日本学術振興会 (JSPS), 2022.4 - 2024.3 </li>
          <li> <b>ACT-X (代表)</b>, 科学技術振興機構 (JST), 2020.12 - 2023.3 </li>
          <li> <b>特別研究員 (DC1)</b>, 日本学術振興会 (JSPS), 2019.4 – 2022.3 </li>
          <li> <b>トヨタ・ドワンゴ高度人工知能人材奨学金</b>, 2021.4 - 2022.3 </li>
          <li> <b>トヨタ・ドワンゴ高度人工知能人材奨学金</b>, 2020.4 - 2021.3 </li>
          <li> <b>若手研究者海外挑戦プログラム</b>, 日本学術振興会 (JSPS), 2020.4 – 2020.8 (Covid-19により辞退) </li>
          <li> <b>トヨタ・ドワンゴ高度人工知能人材奨学金</b>, 2018.4 - 2019.3 </li>
          <li> <b>トヨタ・ドワンゴ高度人工知能人材奨学金</b>, 2017.4 - 2018.3 </li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Media </h2>
        </div>
        <ol>
          <li><a href="https://spectrum.ieee.org/video-friday-aibo-foster-parents" target='_blank'>Aibo Foster Parents: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.31</li>
          <li><a href="https://spectrum.ieee.org/video-friday-agile-upgrade" target='_blank'>Agile Upgrade: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-hottest-on-the-ice" target='_blank'>Hottest on the Ice: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.24</li>
          <li><a href="https://prtimes.jp/main/html/rd/p/000000060.000069918.html" target='_blank'>アールティが挑む、国産4足歩行ロボットの未来</a>, PR TIMES, 2024.12.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-multiple-magicbots" target='_blank'>Multiple MagicBots: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.12.06</li>
          <li><a href="https://www.yomiuri.co.jp/science/20241120-OYT1T50012/" target='_blank'>「頭脳」手に入れ「常識」備えたかに見えるロボット…私たちのパートナーか、倫理観なき危険な存在か</a>, 読売新聞, 2024.11.20</li>
          <li><a href="https://newswitch.jp/p/43682" target='_blank'>ロボットに指示・意図どう伝える？…インターフェース最適化へ新手法探る</a>, 日刊工業新聞, 2024.11.24</li>
          <li><a href="https://spectrum.ieee.org/video-friday-quadruped-ladder-climbing" target='_blank'>Quadruped Ladder Climbing: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.10.04</li>
          <li><a href="https://interestingengineering.com/innovation/mini-muscle-power-new-robotic-forearm" target='_blank'>Game-changing mini-muscle motors power new robotic forearm like humans</a>, Interesting Engineering, 2024.09.02</li>
          <li><a href="https://www.dw.com/en/a-robot-at-the-wheel/video-69903705" target='_blank'>A robot at the wheel</a>, Deutsche Welle, 2024.08.31</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robots-table-tennis" target='_blank'>Robots Solving Table Tennis: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.30</li>
          <li><a href="https://spectrum.ieee.org/video-friday-disney-robot-dance" target='_blank'>Disney Robot Dance: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.23</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robot-dog-jump" target='_blank'>Silly Robot Dog Jump: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.16</li>
          <li><a href="https://newswitch.jp/p/42280" target='_blank'>「常識」「データ」使い切れ…基盤モデル・LLM、ロボットに応用</a>, 日刊工業新聞, 2024.07.19</li>
          <li><a href="https://www.gizmodo.jp/2024/06/musashi-humanoid-driving.html" target='_blank'>人型ロボは運転もこなす。クルマまかせの自動運転よりも安心感アップ</a>, GIZMODO JAPAN, 2024.06.18</li>
          <li><a href="https://www.newscientist.com/article/2435826-watch-a-humanoid-robot-driving-a-car-extremely-slowly/" target='_blank'>Watch a humanoid robot driving a car extremely slowly</a>, New Scientist, 2024.06.17</li>
          <li><a href="https://newatlas.com/robotics/musashi-humanoid-autonomous-driving/" target='_blank'>Video: Humanoid chauffeur put in the driving seat for robotaxi future</a>, New Atlas, 2024.06.13</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robots-with-knives" target='_blank'>Robots With Knives: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.05.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-racer-heavy" target='_blank'>RACER Heavy: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.26</li>
          <li><a href="https://abema.tv/video/episode/89-106_s1_p2428" target='_blank'>『すずめの戸締り』椅子をロボットに</a>, ABEMA【週刊BUZZ動画】SNSで話題の動画をピックアップ!, 2024.04.20</li>
          <li><a href="https://spectrum.ieee.org/video-friday-spacehopper" target='_blank'>SpaceHopper: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.19</li>
          <li><a href="https://www.itmedia.co.jp/aiplus/articles/2404/17/news048.html" target='_blank'>「すずめの戸締まり」に登場の“3本脚の椅子”を再現したロボット　東大が開発　歩行し倒れても起き上がる</a>, ITmedia AI+, 2024.04.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robot-dog-can-t-fall" target='_blank'>Robot Dog Can't Fall: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.12</li>
          <li><a href="https://spectrum.ieee.org/video-friday-co-expression" target='_blank'>Co-Expression: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.29</li>
          <li><a href="https://spectrum.ieee.org/video-friday-many-quadrupeds" target='_blank'>Many Quadrupeds: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.15</li>
          <li><a href="https://spectrum.ieee.org/video-friday-human-to-humanoid" target='_blank'>Human to Humanoid: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.08</li>
          <li><a href="https://spectrum.ieee.org/video-friday-tap-finger-move-mountain" target='_blank'>Tap Finger, Move Mountain: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2023.12.01</li>
          <li><a href="https://newswitch.jp/p/39450" target='_blank'>AI・ロボも迷う…“我が家の冷蔵庫問題”が解けたら値千金な理由</a>, 日刊工業新聞, 2023.12.01</li>
          <li><a href="https://newswitch.jp/p/39285" target='_blank'>生活支援ロボット、ＡＩで変革した現在地と展望</a>, 日刊工業新聞, 2023.11.30</li>
          <li><a href="https://spectrum.ieee.org/video-friday-punch-out" target='_blank'>Punch-Out: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2023.11.24</li>
          <li><a href="https://newswitch.jp/p/38378" target='_blank'>腹腔鏡手術の訓練手技をロボットに、東大が制約付き模倣学習開発</a>, 日刊工業新聞, 2023.09.06</li>
          <li><a href="https://www.asahi.com/articles/ASLCJ3412LCJOBJB002.html" target='_blank'>人型ロボット「ムサシ」、車も運転できるよ　東大が披露</a>, 朝日新聞, 2018.11.16</li>
          <li><a href="https://newswitch.jp/p/13673" target='_blank'>東大のヒューマノイド「腱悟郎」、車の運転に成功</a>, 日刊工業新聞, 2018.07.13</li>
          <li><a href="https://www.nikkei.com/article/DGXMZO25019580U7A221C1TJM000/" target='_blank'>東大、日本人の筋骨格再現したロボット開発</a>, 日本経済新聞, 2017.12.24</li>
          <li><a href="https://www.todaishimbun.org/seisakuten20161118/" target='_blank'>初日から300人来場！いま話題の「東京大学制作展『FAKE FUTURE』」ではどんな体験ができるのか？</a>, 東大新聞オンライン, 2016.11.18</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Academic Activities </h2>
        </div>
        <ol>
          <li>Associate Editor, 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025), 2025</li>
          <li>Associate Editor, 2025 IEEE International Conference on Robotics and Automation (ICRA2025), 2025</li>
          <li>Associate Editor, 2024 IEEE International Conference on Humanoid Robots (Humanoids2024), 2024</li>
          <li>Organizer, Organized Session on Real-World Robot Applications of Foundation Models, The 42nd Annual Conference of the Robotics Society of Japan (RSJ2024), 2024</li>
          <li>Organizer, <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Workshop on Cooking Robotics: Perception and motion planning </a>, IEEE International Conference on Robotics and Automation (ICRA2024), 2024</li>
          <li>Associate Editor, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024), 2024</li>
          <li>Section Editor, Special Section on Cognitive Development and Symbol Emergence, Advanced Robotics, 2024</li>
          <li>Guest Editor, <a href="https://www.rsj.or.jp/content/files/pub/ar/CFP/CFP_38_17.pdf" target='_blank'>Special Issue on Real-World Robot Applications of the Foundation Models</a>, Advanced Robotics, 2024</li>
          <li>Organizer, <a href="https://sites.google.com/grp.riken.jp/langrobonlp2024" target='_blank'>Workshop on Real-World Applications of Large Language Models</a>, The 30th Annual Meeting of the Association of Natural Language Processing (NLP2024), 2024</li>
          <li>Associate Editor, 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids2023), 2023</li>
          <li>Organizer, <a href="https://sites.google.com/view/robotics-foundation-models/organized-session-on-rsj2023?authuser=0" target='_blank'>Organized Session on Real-World Robot Applications of Foundation Models</a>, The 41st Annual Conference of the Robotics Society of Japan (RSJ2023), 2023</li>
          <li>Associate Editor, 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids2022), 2022</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> CV </h2>
        </div>
        <a href="static/kawaharazuka-cv.pdf">Download</a>
      </main>
    </div>
  </body>
</html>
