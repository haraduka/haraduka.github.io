<!-- This file is automatically generated. Do not modify -->
<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title> Kento Kawaharazuka </title>
    <link rel="shortcut icon" href="static/favicon.ico">
    <link rel="canonical" href="https://haraduka.github.io">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1XJ0NHR591"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-1XJ0NHR591');
    </script>

    <meta property="twitter:card" content="summary" />
    <meta property="twitter:title" content="Kento Kawaharazuka" />
    <meta property="twitter:image" content="https://haraduka.github.io/static/kawaharazuka.png" />

    <meta property="og:title" content="Kento Kawaharazuka" />
    <meta property="og:url" content="https://haraduka.github.io" />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://haraduka.github.io/static/kawaharazuka.png" />

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
  </head>

  <body>
    <div class="container py-3">

      <nav class="navbar navbar-expand-lg navbar-light fixed-top" style="background-color: #f8f9fa; border-bottom: 1px solid #ddd;">
        <div class="container">
          <a class="navbar-brand mx-auto align-items-center" href="https://haraduka.github.io" style="font-size: 24px; display: flex;">Kento Kawaharazuka</a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse justify-content-end" id="navbarSupportedContent">
            <ul class="navbar-nav" style="font-size: 24px;">
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="robots.html">Robots</a>
              </li>
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="projects.html">Projects</a>
              </li>
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="videos.html">Videos</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <script>
        let lastScrollTop = 0;
        const navbar = document.querySelector('.navbar');

        window.addEventListener('scroll', () => {
          let currentScroll = window.pageYOffset || document.documentElement.scrollTop;

          if (currentScroll > lastScrollTop) {
            // ä¸‹æ–¹å‘ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­
            navbar.classList.add('navbar-hide');
            navbar.classList.remove('navbar-show');
          } else {
            // ä¸Šæ–¹å‘ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­
            navbar.classList.add('navbar-show');
            navbar.classList.remove('navbar-hide');
          }

          lastScrollTop = currentScroll;
        });
      </script>

      <script>
        document.addEventListener("DOMContentLoaded", function () {
          document.querySelectorAll("h1, h2, h3, h4, h5, h6").forEach(function (heading) {
            // æ—¢ã« id ãŒã‚ã‚Œã°ä½¿ã„ã€ãªã‘ã‚Œã°ç”Ÿæˆ
            if (!heading.id) {
              let baseId = heading.textContent.trim().toLowerCase()
                .replace(/[^\w\s\-]/g, '') // è¨˜å·å‰Šé™¤
                .replace(/\s+/g, '-');     // ç©ºç™½ã‚’ãƒã‚¤ãƒ•ãƒ³ã«
              let uniqueId = baseId;
              let counter = 1;
              while (document.getElementById(uniqueId)) {
                uniqueId = baseId + '-' + counter++;
              }
              heading.id = uniqueId;
            }

            // ã‚¢ã‚¤ã‚³ãƒ³ç”Ÿæˆ
            const anchor = document.createElement("a");
            anchor.href = "#" + heading.id;
            anchor.className = "anchor-link";
            anchor.textContent = "ğŸ”—";
            heading.appendChild(anchor);
          });
        });
      </script>


      <main>
        <div class="row py-3">
          <div class="col-md-4 text-center">
            <div style="max-width: 400px">
              <img src="static/kawaharazuka.png" class="img-fluid mx-auto d-block" alt="Image" style="max-width: 100%; height: auto;">
            </div>
          </div>

          <div class="col-md-8 py-3">
            <h2> Kento Kawaharazuka </h2>
            <h3> Lecturer (Junior Associate Professor) </h3>
            Next Generation Artificial Intelligence Research Center (AI Center), <br>
            + Department of Mechano-Informatics, <br>
            Graduate School of Information Science and Technology, <br>
            The University of Tokyo, Japan <br>
            <div class="d-inline-flex mt-4 ms-md-auto">
              <a href="https://scholar.google.co.jp/citations?user=E75YHyUAAAAJ&hl=en" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" height="36" width="36"fill="currentColor" viewBox="0 0 512 512">
                  <path d="M390.9 298.5c0 0 0 .1 .1 .1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7c4.4-7.6 9.4-14.7 15-21.3c27.4-32.6 68.5-53.3 114.4-53.3c33.6 0 64.6 11.1 89.6 29.9c9.1 6.9 17.4 14.7 24.8 23.5c5.6 6.6 10.6 13.8 15 21.3c2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/>
                </svg>
              </a>
              <a href="https://twitter.com/KKawaharazuka" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-twitter-x" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
                </svg>
              </a>
              <a href="https://www.youtube.com/channel/UC3iq44Y7vsriPyFiU02Bcyw" target='_blank' class='me-3'>
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-youtube" viewBox="0 0 16 16">
                  <path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.007 2.007 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.007 2.007 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31.4 31.4 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.007 2.007 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A99.788 99.788 0 0 1 7.858 2h.193zM6.4 5.209v4.818l4.157-2.408z"/>
                </svg>
              </a>
              <a href="https://github.com/haraduka" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
                  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
                </svg>
              </a>
              <a href="mailto:kawaharazuka@jsk.imi.i.u-tokyo.ac.jp" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24">
                  <path fill="currentColor" d="M20 18h-2V9.25L12 13L6 9.25V18H4V6h1.2l6.8 4.25L18.8 6H20m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"/></svg>
                </svg>
              </a>
              <a href="https://www.linkedin.com/in/kento-kawaharazuka-099372285/" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
                  <path fill="currentColor" d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"/></svg>
                </svg>
              </a>
            </div>
          </div>
        </div>
        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Biography </h2>
        </div>
        Kento Kawaharazuka is a lecturer (junior associate professor) in UTokyo AI Center and JSK Robotics Laboratory at the University of Tokyo.
        His research interests are mainly in humanoids, including biomimetics, tendon-driven robots, and machine learning.
        He designs tendon-driven humanoids and develops learning control systems to move them.
        <h3> Career </h3>
        <ul>
          <li> Lecturer (Junior Associate Professor) in UTokyo AI Center and Mechano-Informatics, 2025.2- (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> Visiting Researcher, 2024.6-2024.8 (Robotics and Systems Laboratory, ETH Zurich) </li>
          <li> Project Assistant Professor in Mechano-Informatics, 2022.4-2025.1 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> Ph.D. in Mechano-Informatics, 2019.4-2022.3 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> M.S. in Mechano-Informatics, 2017.4-2019.3 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> B.S. in Mechano-Informatics, 2013.4-2017.3 (Faculty of Engineering, The University of Tokyo) </li>
        </ul>

        <div class="row py-3">
          <div class="col-lg-8 offset-lg-2 text-center">
            <img src="static/robots.jpeg" class="img-fluid mx-auto d-block" alt="Image" style="max-width: 100%; height: auto;">
          </div>
        </div>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> News </h2>
        </div>
        <ul>
          <li><b> 2025.07.31 - We are organizing a IROS2025 workshop on <a href="https://sites.google.com/g.ecc.u-tokyo.ac.jp/iros2025-ws-roboticdesign/" target='_blank'>foundation models for robotic design</a>!</b></li>
          <li><b> 2025.07.29 - MIRU2025ã«ã¦ã€Œãƒ­ãƒœãƒƒãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æœ€å‰ç·šã€ã¨ã„ã†ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è¬›æ¼”ã‚’è¡Œã„ã¾ã—ãŸ.</b></li>
          <li><b> 2025.07.23 - Three papers including one first-authored paper were accepted to Humanoids2025!</b></li>
          <li><b> 2025.07.22 - We are organizing a CoRL2025 workshop on <a href="https://open-hardware-robots.github.io/CoRL2025/" target='_blank'>open-source hardware</a>!</b></li>
          <li><b> 2025.07.16 - è¬›è«‡ç¤¾æ§˜ã‚ˆã‚Šæ›¸ç±ã€ŒåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨ãƒ­ãƒœãƒƒãƒˆã®èåˆã€ãŒå‡ºç‰ˆã•ã‚Œã¾ã™ï¼ãœã²<a href="https://www.amazon.co.jp/dp/4065395852" target='_blank'>äºˆç´„</a>ã—ã¦ãã ã•ã„ï¼</b></li>
          <li><b> 2025.06.16 - Four papers including one first-authored paper were accepted to IROS2025!</b></li>
          <li><b> 2025.06.10 - Our paper on PIMBS (physics-informed musculoskeletal body schema) was accepted to IEEE RA-L!</b></li>
          <li><b> 2025.06.04 - ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š2025ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€9ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2025.06.03 - ROBOMECH2025ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã€Œæ©Ÿæ¢°å­¦ç¿’ã¨äººå‹ãƒ»å¤šè„šãƒ»å¤šé–¢ç¯€ãƒ­ãƒœãƒƒãƒˆã€ã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã—ãŸ.</b></li>
          <li><b> 2025.06.02 - æ±åŒ—å¤§å­¦ã‚¿ãƒ•ï½¥ã‚µã‚¤ãƒãƒ¼ãƒ•ã‚£ã‚¸ã‚«ãƒ«AIç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã—ãŸ.</b></li>
          <li><b> 2025.05.28 - JSAI2025ä¼ç”»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«AIã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶é–‹ç™ºã€ã«ã¦ãƒ‘ãƒãƒªã‚¹ãƒˆã‚’å‹™ã‚ã¾ã—ãŸ.</b></li>
          <li><b> 2025.05.24 - Our paper on reinforcement learning-based obstacle avoidance for aerial robots was accepted to Advanced Robotics!</b></li>
          <li><b> 2025.05.09 - Our workshop on Foundation Models for Robotic Design was accepted to IROS2025!</b></li>
          <li><b> 2025.05.06 - Our paper on self-healing tendon-driven robot was accepted to Advanced Intelligent Systems!</b></li>
          <li><b> 2025.05.01 - IEICEå…ˆç«¯ã‚»ãƒŸãƒŠãƒ¼ã®ã€Œç”ŸæˆAIã®å¿œç”¨ã€è¬›åº§ã«ã¦è¬›å¸«ã‚’å‹™ã‚ã¾ã—ãŸ.</b></li>
          <li><b> 2025.04.09 - Our paper on mobile tendon-driven CubiX was accepted to Advanced Robotic Research!</b></li>
          <li><b> 2025.04.02 - I gave a short talk and joined a panel discussion at the Embodied Intelligence Conference (EI2025).</b></li>
        </ul>
        <div onclick="obj=document.getElementById('open').style; obj.display=(obj.display=='none')?'block':'none';">
          <a style="cursor:pointer;">â–¼ click here to expand</a>
        </div>
        <div id="open" style="display:none;clear:both;">
          <ul>
          <li><b> 2025.03.28 - JST CRDS ç ”ç©¶é–‹ç™ºæˆ¦ç•¥ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰, ç§‘å­¦æŠ€è¡“æœªæ¥æˆ¦ç•¥ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—å ±å‘Šæ›¸ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«AIã‚·ã‚¹ãƒ†ãƒ ã€ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2025.03.18 - ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢ç†è§£ç ”ç©¶ä¼š (PRMU)ã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã™.</b></li>
          <li><b> 2025.02.01 - Kento Kawaharazuka has promoted to Lecturer (Junior Associate Professor) in UTokyo AI Center and Department of Mechano-Informatics!</b></li>
          <li><b> 2025.01.28 - Two papers including one first-authored paper were accepted at ICRA2025!</b></li>
          <li><b> 2025.01.24 - Our front hair styling robot was selected as a Best Student Paper Award Finalist at SII2025!</b></li>
          <li><b> 2025.01.08 - å…±åŒåŸ·ç­†ã—ãŸæ›¸ç±ã€ŒData-Centric AIå…¥é–€ã€ãŒæŠ€è¡“è©•è«–ç¤¾ã‹ã‚‰å‡ºç‰ˆã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2024.12.07 - I gave an inivited talk at VANJ Conference 2024!</b></li>
          <li><b> 2024.12.06 - I gave an inivited talk at Tokyo AI (TAI)!</b></li>
          <li><b> 2024.11.24 - CubiXMusashi won the Mike Stillman Award at Humanoids2024!</b></li>
          <li><b> 2024.11.23 - I gave a plenary talk at Humanoids2024.</b></li>
          <li><b> 2024.11.20 - I gave an invited talk at KIT, Karlsruhe.</b></li>
          <li><b> 2024.11.08 - One paper was accepted to SII2025</b></li>
          <li><b> 2024.09.09 - Eight papers including three first-authored papers were accepted to Humanoids2024.</b></li>
          <li><b> 2024.09.04 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2024ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€10ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2024.08.01 - I gave a talk at Professor Sven Behnke's Lab at University of Bonn.</b></li>
          <li><b> 2024.07.31 - I gave an invited talk at DLR, Oberpfaffenhofen.</b></li>
          <li><b> 2024.07.30 - I gave a talk at Professor Gordon Cheng's Lab at TUM, Munich.</b></li>
          <li><b> 2024.07.29 - I gave an invited talk at Max Planck Institute, Tubingen.</b></li>
          <li><b> 2024.07.05 - I gave a talk at CREATE lab at EPFL, Lausanne.</b></li>
          <li><b> 2024.06.30 - Six papers including two first-authored papers were accepted to IROS2024.</b></li>
          <li><b> 2024.06.28 - I gave an invited talk at CRL Seminar at ETH Zurich.</b></li>
          <li><b> 2024.06.25 - å‰µç™ºçš„ç ”ç©¶æ”¯æ´äº‹æ¥­ã«æ¡æŠã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2024.06.20 - I gave an invited talk at postdoc seminar at IIT, Genova.</b></li>
          <li><b> 2024.06.17 - I gave an invited talk at symposium on robotics in biomedical applications at KTH, Stockholm.</b></li>
          <li><b> 2024.06.03 - I will be conducting research as a visiting researcher at ETH for two and a half months.</b></li>
          <li><b> 2024.05.30 - ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š2024ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€10ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2024.05.28 - äººå·¥çŸ¥èƒ½å­¦ä¼š2024ã«ã¦1ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2024.05.17 - I gave an organizer talk at ICRA2024 workshop on <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Cooking Robotics: Perception and Motion Planning</a>.</b></li>
          <li><b> 2024.05.16 - RT-X project won the Best Conference Paper Award at ICRA2024!</b></li>
          <li><b> 2024.04.15 - I gave an invited talk at RoboSoft2024 workshop on <a href="https://printed-musculoskeletal-robots.ethz.ch/" target='_blank'>From Layers to Limbs! Exploring the Interface of 3D Printing and Bio-Inspired Musculoskeletal Robotics</a>.</b></li>
          <li><b> 2024.03.05 - Our paper "Continuous Object State Recognition for Cooking Robots" was accepted to RA-L!</b></li>
          <li><b> 2024.03.05 - Our paper "SAQIEL: Ultra-Light and Safe Manipulator" was accepted to RA-L!</b></li>
          <li><b> 2024.02.09 - Our new survey paper "Real-World Robot Applications of Foundation Models: A Review" is now on arXiv!</b></li>
          <li><b> 2024.02.09 - "åµæ–™ç†ã®å®Ÿä¸–ç•Œèª¿ç†å®Ÿè¡Œ"ã¨"æ¶²ä½“æ»²å‡ºè»Ÿéª¨æ©Ÿæ§‹ã®æ§‹æˆæ³•"ã«é–¢ã™ã‚‹ç ”ç©¶ãŒè¨ˆæ¸¬è‡ªå‹•åˆ¶å¾¡å­¦ä¼š2023ã«ã¦å„ªç§€è¬›æ¼”è³ã«é¸ã°ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2024.02.04 - I have been staying at Robotic Systems Lab at ETH in Switzerland for the past two weeks. I appreciate the insightful discussions!</b></li>
          <li><b> 2024.02.02 - We organize <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Cooking Robotics Workshop</a> at ICRA2024!</b></li>
          <li><b> 2024.01.30 - We have extended the deadline of Advanced Robotics Special Issue on Real-World Robot Applications of Foundation Models to 29th February.</b></li>
          <li><b> 2024.01.29 - Five papers including two first-authored papers were accepted to ICRA2024.</b></li>
          <li><b> 2024.01.19 - Two papers  were accepted to RoboSoft2024.</b></li>
          <li><b> 2023.12.15 - We visited RoMeLa at UCLA and GITAI.</b></li>
          <li><b> 2023.12.12 - We presented five papers at Humanoids2023.</b></li>
          <li><b> 2023.10.29 - ç¬¬19å›èº«ä½“æ€§èªçŸ¥ç§‘å­¦ã¨å®Ÿä¸–ç•Œå¿œç”¨ã«é–¢ã™ã‚‹è‹¥æ‰‹ç ”ç©¶ä¼š(ECSRA)ã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã™.</b></li>
          <li><b> 2023.10.24 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒVol.41, No.8ã«"æƒ…å ±åŒ–èº«ä½“ã®å­¦ç¿’ç†è«–ã«åŸºã¥ãæˆé•·ãƒ­ãƒœãƒƒãƒˆã®é©æ–°ã¨å‰µæˆ"ã«é–¢ã™ã‚‹è§£èª¬è¨˜äº‹ãŒæ²è¼‰ã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2023.10.18 - ç¬¬5å›LLMå‹‰å¼·ä¼š(LLM-jp)ã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã™.</b></li>
          <li><b> 2023.10.06 - We visited Stanford University.</b></li>
          <li><b> 2023.10.05 - I gave an invited talk at IROS2023 workshop on <a href="https://sites.google.com/view/learning-meets-models-iros2023/speakers?authuser=0" target='_blank'>Learning Meets Model-based Methods for Manipulation and Grasping</a>.</b></li>
          <li><b> 2023.09.30 - Five papers including two first-authored papers were accepted to Humanoids2023.</b></li>
          <li><b> 2023.09.12 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2023ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€12ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2023.08.31 - NLPè‹¥æ‰‹ã®ä¼š(YANS2023)ã®æ‹›å¾…ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ç™ºè¡¨ã—ã¾ã™.</b></li>
          <li><b> 2023.06.29 - "å‹•çš„æŸ”è»Ÿå¸ƒæ“ä½œ"ã®ç ”ç©¶ãŒãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š2022ã«ã¦ãƒ™ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è³ã«é¸ã°ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2023.06.29 - ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š2023ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€13ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2023.06.28 - ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š2023ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ã€Œ"ã„ã„ã‹ã’ã‚“"ã‚’ç§‘å­¦ã—ã¦æœªæ¥ã‚’å‰µã‚‹ã‚½ãƒ•ãƒˆãƒ­ãƒœãƒƒãƒˆå­¦4ã€ã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã™.</b></li>
          <li><b> 2023.06.22 - Five papers including one first-authored paper were accepted to IROS2023.</b></li>
          <li><b> 2023.06.06 - äººå·¥çŸ¥èƒ½å­¦ä¼š2023ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€2ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2023.06.02 - One paper was accepted to ROMAN2023.</b></li>
          <li><b> 2023.05.30 - Four papers were accepted to IAS18.</b></li>
          <li><b> 2023.05.17 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2023ã«ã¦OS4ã€ŒåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ã€ã‚’ä¸»å‚¬ã—ã¾ã™.</b></li>
          <li><b> 2023.04.10 - One paper was accepted to AMAM2023.</b></li>
          <li><b> 2023.04.05 - æ–°å­¦æœŸã‹ã‚‰3äººã®B4ãŒè‡ªåˆ†ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åŠ ã‚ã‚Šã¾ã—ãŸ.</b></li>
          <li><b> 2023.04.01 - JST ACT-Xã€ŒAIæ´»ç”¨ã§æŒ‘ã‚€å­¦å•ã®é©æ–°ã¨å‰µæˆã€ã®åŠ é€Ÿãƒ•ã‚§ãƒ¼ã‚ºã«æ¡æŠã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2023.01.19 - Two first-authored papers (including one RAM paper) were accepted to ICRA2023.</b></li>
          <li><b> 2022.12.16 - ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢2023ã«ä¸»è‘—1ä»¶ã‚’å«ã‚€6ä»¶ã®ç™ºè¡¨ãŒæ¡æŠã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2022.12.14 - è¨ˆæ¸¬è‡ªå‹•åˆ¶å¾¡å­¦ä¼š2022ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€5ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2022.11.30 - "Hardware and Software Design of Musashi-W" was selected as Best Interactive Paper Award Finalist at Humanoids2022.</b></li>
          <li><b> 2022.11.21 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒVol.40, No.9ã«"ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒã‚¤ã‚¢ã‚¹ã‚’å«ã‚€æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"ã«é–¢ã™ã‚‹è§£èª¬è¨˜äº‹ãŒæ²è¼‰ã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2022.10.26 - "Self-Supervised Learning of Visual Servoing" was selected as SICE International Young Authors Award at IROS2022.</b></li>
          <li><b> 2022.10.26 - "Parallel-Wire Driven Monopedal Robot RAMIEL" was selected as SICE International Young Authors Award at IROS2022.</b></li>
          <li><b> 2022.09.09 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2022 "è‹¥æ‰‹ç ”ç©¶è€…ãŒæã2050å¹´ã®AIãƒ­ãƒœãƒƒãƒˆãƒ“ã‚¸ãƒ§ãƒ³"OFã«ã¦æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã™.</b></li>
          <li><b> 2022.09.05 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2022ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€14ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2022.09.26 - Five papers including three first-authored papers were accepted to Humanoids2022.</b></li>
          <li><b> 2022.06.30 - Seven papers including four first-authored papers (including one RA-L paper) were accepted to IROS2022.</b></li>
          <li><b> 2022.06.17 - "Human-mimetic Binaural Ear Design" was accepted to Robomech Journal.</b></li>
          <li><b> 2022.06.15 - äººå·¥çŸ¥èƒ½å­¦ä¼š2022ã«ã¦ä¸»è‘—1ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2022.06.03 - æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼š2022ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€10ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2022.06.01 - "Roboust Continous Motion Against Muscle Rupture" was accepted to Robotics and Autonomous Systems.</b></li>
          <li><b> 2022.05.27 - We won the first prize of state-based category at DodgeDrone Challenge at ICRA2022.</b></li>
          <li><b> 2022.05.23 - "Dynamic Cloth Manipulation" was accepted to Frontiers in Neurorobotics.</b></li>
          <li><b> 2022.04.05 - æ–°å­¦æœŸã‹ã‚‰2äººã®B4ã¨1äººã®M1ãŒè‡ªåˆ†ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åŠ ã‚ã‚Šã¾ã—ãŸ.</b></li>
          <li><b> 2022.04.01 - I received Ph.D. and became a project assistant professor at JSK Roboics Laboratory.</b></li>
          <li><b> 2022.03.24 - åšå£«è«–æ–‡ãŒç ”ç©¶ç§‘é•·è³ã«é¸ã°ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2022.02.01 - Two papers including one first-authored paper (including one RA-L paper) were accepted to ICRA2022.</b></li>
          <li><b> 2022.01.21 - "ç¢ºç‡çš„æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"ã«é–¢ã™ã‚‹ç ”ç©¶ãŒSI2021ã«ãŠã„ã¦å„ªç§€è¬›æ¼”è³ã«é¸ã°ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2021.12.15 - è¨ˆæ¸¬è‡ªå‹•åˆ¶å¾¡å­¦ä¼š2021ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€3ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2021.09.09 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2021ã«ã¦"æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"ã«ã¤ã„ã¦ã‚­ãƒ¼ãƒãƒ¼ãƒˆè¬›æ¼”ã‚’è¡Œã„ã¾ã™.</b></li>
          <li><b> 2021.09.06 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2021ã«ã¦ä¸»è‘—1ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2021.07.22 - "Design of MusashiOLegs" was selected as Best Oral Paper Award at Humanoids2020.</b></li>
          <li><b> 2021.07.01 - Five papers including four first-authored papers (including three RA-L papers) were accepted to IROS2021.</b></li>
          <li><b> 2021.06.06 - æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼š2021ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€7ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2021.05.01 - Three papers including two first-authored papers were accepted to Humanoids2020.</b></li>
          <li><b> 2021.03.01 - Four papers including two first-authored papers (including one RA-L and one RAM papers) were accepted to ICRA2021.</b></li>
          <li><b> 2021.02.10 - One first-authored paper was accepted to RoboSoft2021.</b></li>
          <li><b> 2021.01.27 - "é“å…·å½¢çŠ¶æœ€é©åŒ–"ã«é–¢ã™ã‚‹ç ”ç©¶ãŒè¨ˆæ¸¬è‡ªå‹•åˆ¶å¾¡å­¦ä¼š2020ã«ã¦å„ªç§€è¬›æ¼”è³ã«é¸ã°ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2020.12.16 - è¨ˆæ¸¬è‡ªå‹•åˆ¶å¾¡å­¦ä¼š2020ã«ã¦ä¸»è‘—3ä»¶ã‚’å«ã‚€4ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2020.11.24 - "æˆé•·ãƒ­ãƒœãƒƒãƒˆ"ã«é–¢ã™ã‚‹èª²é¡ŒãŒJST ACT-Xã€ŒAIæ´»ç”¨ã§æŒ‘ã‚€å­¦å•ã®é©æ–°ã¨å‰µæˆã€é ˜åŸŸã«æ¡æŠã•ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2020.10.10 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2020ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€2ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2020.10.09 - "æŸ”è»Ÿç‰©ä½“æ“ä½œ"ã¨"Musculoskeletal AutoEncoder"ã«é–¢ã™ã‚‹ç ”ç©¶ãŒæ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2019ã«ã¦ç ”ç©¶å¥¨åŠ±è³ã«é¸ã°ã‚Œã¾ã—ãŸ.</b></li>
          <li><b> 2020.07.03 - Six papers including five first-authored papers (including two RA-L papers) were accepted to IROS2020.</b></li>
          <li><b> 2020.05.27 - æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼š2020ã«ã¦2ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2020.05.13 - "Autonomous Driving by Musculoskeletal Humanoids" was accepted to Robotics and Autonomous Magazine.</b></li>
          <li><b> 2020.04.20 - "Human Mimetic Forearm and Hand Design" was accepted to Journal of Robotics and Mechatronics.</b></li>
          <li><b> 2020.01.22 - Three papers including two first-authored papers (including one RA-L paper) were accepted to ICRA2020.</b></li>
          <li><b> 2019.10.09 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2019ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€5ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2019.08.26 - Three papers including one first-authored paper were accepted to Humanoids2019.</b></li>
          <li><b> 2019.06.21 - Seven papers including four first-authored paper (including one RA-L paper)were accepted to IROS2019.</b></li>
          <li><b> 2019.06.05 - æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼š2019ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€8ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2019.04.13 - One first-authored paper was accepted to AMAM2019.</b></li>
          <li><b> 2019.01.22 - One first-authored paper was accepted to ICRA2019.</b></li>
          <li><b> 2018.10.02 - "Five-Fingered Hand Design" was selected as IROS ICROS Best Application Paper Award 2018 Finalists at IROS2018.</b></li>
          <li><b> 2018.09.21 - Three papers including two first-authored papers were accepted to Humanoids2018.</b></li>
          <li><b> 2018.09.05 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2018ã«ã¦ä¸»è‘—2ä»¶ã‚’å«ã‚€4ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2018.06.29 - Two papers including one first-authored paper were accepted to IROS2018.</b></li>
          <li><b> 2018.06.02 - æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼š2018ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€4ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2018.03.06 - One first-authored paper (RA-L paper) was accepted to IROS2018.</b></li>
          <li><b> 2017.09.24 - "Human Mimetic Forearm Design" was selected as IEEE RAS Japan Joint Chapter Young Award at IROS2017.</b></li>
          <li><b> 2017.09.11 - æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š2017ã«ã¦ä¸»è‘—1ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          <li><b> 2017.06.29 - Three papers including two first-authored paper (including one RA-L paper) were accepted to IROS2017.</b></li>
          <li><b> 2017.05.10 - æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼š2017ã«ã¦ä¸»è‘—1ä»¶ã‚’å«ã‚€2ä»¶ã®ç™ºè¡¨ãŒã‚ã‚Šã¾ã™.</b></li>
          </ul>
        </div>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Publications </h2>
        </div>
<h3> International Journal Papers </h3>
<ol>
<li>L. Wu, H. Jia, <b><u>K. Kawaharazuka</u></b>, H. Ishida, K. Okada<br>Dexterous Grasp Dataset Augmentation based on Grasp Synthesis with Fingertip Workspace Cloud and Contact-Aware Sampling, <i>Advanced Robotics (<b>AR</b>)</i>, 2025</li>
<li><b><u>K. Kawaharazuka</u></b>, T. Hattori, K. Yoneda, K. Okada<br>PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 10, no. 7, pp. 7611-7618, 2025, (<b>presented at ICRA2026</b>)<br> <a href=https://doi.org/10.1109/LRA.2025.3577525 target='_blank'>[Paper Link]</a> <a href=https://haraduka.github.io/pinn-body-schema/ target='_blank'>[Project Page]</a></li>
<li>S. Nakashima, <b><u>K. Kawaharazuka</u></b>, Y. Nagamatsu, K. Shinjo, A. Miki, Y. Asano, Y. Kakiuchi, K. Okada, M. Inaba<br>Liquid Metal Sloshing for High-load Active Self-healing System: An Application to Tendon-driven Legged Robot, <i>Advanced Intelligent Systems (<b>AISY</b>)</i>, 2025<br> <a href=https://doi.org/10.1002/aisy.202500040 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=6ZZuyH0jLhA target='_blank'>[Video]</a></li>
<li>H. Kozuka, M. Zhao, A. Tang, T. Nishio, I. Yanokura, <b><u>K. Kawaharazuka</u></b>, J. Sugihara, K. Sugihara, K. Okada, M. Inaba<br>GenAerialNav: Obstacle Avoidance in Real Flight for Generalized Multirotors by Reinforcement Learning with Variable Acc-Properties in Dynamics, <i>Advanced Robotics (<b>AR</b>)</i>, 2025<br> <a href=https://doi.org/10.1080/01691864.2025.2506091 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=exHWNdzYHaM target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, K. Okada, M. Inaba<br>Overcoming Physical Limitations Utilizing the Surrounding Environment with a Wire-Driven Multipurpose Robot, <i>Advanced Robotics Research (<b>ADRR</b>)</i>, vol. 1, no. 1, pp. 202400021, 2025<br> <a href=https://doi.org/10.1002/adrr.202400021 target='_blank'>[Paper Link]</a> <a href=https://shin0805.github.io/cubix-overcoming/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=Vn5Kx3mq41g target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Matsushima, A. Gambardella, J. Guo, C. Paxton, A. Zeng<br>Real-World Robot Applications of Foundation Models: A Review, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1232-1254, 2024, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.1080/01691864.2024.2408593 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2402.05741 target='_blank'>[Arxiv Link]</a></li>
<li>N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>Real-world cooking robot system from recipes based on food state recognition using foundation models and PDDL, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1318-1334, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2407136 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.02874 target='_blank'>[Arxiv Link]</a> <a href=https://kanazawanaoaki.github.io/cook-from-recipe-pddl/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=3bQRTAKV0wM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada, M. Inaba<br>Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1307-1317, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2393409 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.11380 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/omnidirectional-vlm/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=T2Uezkpu5u4 target='_blank'>[Video]</a></li>
<li>S. Wakabayashi, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Behavioral Learning of Dish Rinsing and Scrubbing based on Interruptive Direct Teaching Considering Assistance Rate, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 15, pp. 1052-1065, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2379393 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09360 target='_blank'>[Arxiv Link]</a> <a href=https://shmpwk.github.io/projects/dish_wash/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=db4OcVsz3YY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, 2024, (<b>presented at ICRA2025</b>)<br> <a href=https://doi.org/10.1109/MRA.2024.3415111 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.06427 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic Environmental State Recognition with Pre-Trained Vision-Language Models and Black-Box Optimization, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1255-1264, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2366995 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.17519 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/vlm-bbo/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=aOoQcEdVb6M target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, Y. Obinata, K. Okada, M. Inaba<br>Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 5, pp. 4059-4066, 2024, (<b>presented at Humanoids2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2024.3375257 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.08239 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/continuous-state-recognition/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=480caUHXrE0 target='_blank'>[Video]</a></li>
<li>T. Suzuki, M. Bando, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>SAQIEL: Ultra-Light and Safe Manipulator with Passive 3D Wire Alignment Mechanism, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 4, pp. 3720-3727, 2024, (<b>presented at IROS2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2024.3371219 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.01803 target='_blank'>[Arxiv Link]</a> <a href=https://tenrobo18.github.io/saqiel-ral2023-webpage/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=QEluGqmj-k8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Yoshimura, T. Suzuki, K. Okada, M. Inaba<br>Design Optimization of Wire Arrangement With Variable Relay Points in Numerical Simulation for Tendon-Driven Robots, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 2, pp. 1388-1395, 2024, (<b>presented at IROS2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2023.3342667 target='_blank'>[Paper Link]</a> <a href=http://arxiv.org/abs/2401.02730 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/muscle-arrange-optimization/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=Uq9Ympi7KMw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Deep Predictive Model Learning with Parametric Bias: Handling Modeling Difficulties and Temporal Model Changes, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, vol. 31, no. 4, pp. 81-99, 2023, (<b>presented at ICRA2023</b>)<br> <a href=https://doi.org/10.1109/MRA.2022.3217744 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.15726 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada, M. Inaba<br>Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 7, no. 3, pp. 7881-7887, 2022, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2022)</font></b>, (<b>presented at IROS2022</b>)<br> <a href=https://doi.org/10.1109/LRA.2022.3186074 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11798 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=ulWgQTVDGQA target='_blank'>[Video]</a></li>
<li>Y. Omura, <b><u>K. Kawaharazuka</u></b>, Y. Nagamatsu, Y. Koga, M. Nishiura, Y. Toshimitsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Human-mimetic binaural ear design and sound source direction estimation for task realization of musculoskeletal humanoids, <i>Robomech Journal</i>, vol. 9, no. 17, pp. 1-15, 2022<br> <a href=https://doi.org/10.1186/s40648-022-00231-x target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.06427 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=d8YB1UJfDCM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, K. Okada, M. Inaba<br>Dynamic Cloth Manipulation Considering Variable Stiffness and Material Change Using Deep Predictive Model With Parametric Bias, <i>Frontiers in Neurorobotics</i>, vol. 16, pp. 1-16, 2022<br> <a href=https://doi.org/10.3389/fnbot.2022.890695 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.15635 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=wDJmIL0ZkbE target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Toshimitsu, Y. Omura, Y. Koga, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Robust Continuous Motion Strategy Against Muscle Rupture using Online Learning of Redundant Intersensory Networks for Musculoskeletal Humanoids, <i>Robotics and Autonomous Systems (<b>RAS</b>)</i>, vol. 152, pp. 1-14, 2022<br> <a href=https://doi.org/10.1016/j.robot.2022.104067 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.14951 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=deRDl2zI_0c target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, Y. Toshimitsu, K. Okada, M. Inaba<br>Adaptive Body Schema Learning System Considering Additional Muscles for Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 7, no. 2, pp. 3459-3466, 2022, (<b>presented at ICRA2022</b>)<br> <a href=https://doi.org/10.1109/LRA.2022.3147457 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06322 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=cc0223BgKlA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Adaptive Robotic Tool-Tip Control Learning Considering Online Changes in Grasping State, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 3, pp. 5992-5999, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3088807 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08052 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=cpimgpBHgxY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Kawamura, K. Okada, M. Inaba<br>Imitation Learning with Additional Constraints on Motion Style using Parametric Bias, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 3, pp. 5897-5904, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3087423 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08057 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=dunhjxYzvUA target='_blank'>[Video]</a></li>
<li>Y. Koga, <b><u>K. Kawaharazuka</u></b>, Y, Toshimitsu, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Self-Body Image Acquisition and Posture Generation with Redundancy using Musculoskeletal Humanoid Shoulder Complex for Object Manipulation, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 4, pp. 6686-6692, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3095318 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06320 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=YS_shMahQSQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Koga, Y. Omura, Y. Toshimitsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Automatic Grouping of Redundant Sensors and Actuators Using Functional and Spatial Connections: Application to Muscle Grouping for Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 2, pp. 1981-1988, 2021, (<b>presented at ICRA2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3060715 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.00678 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=TWJqvRVSVFk target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Koga, Y. Omura, T. Makabe, K. Shinjo, M. Onitsuka, Y. Nagamatsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Toward Autonomous Driving by Musculoskeletal Humanoids: Study of Developed Hardware and Learning-Based Software, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, vol. 27, no. 3, pp. 84-96, 2020, (<b>presented at ICRA2021</b>)<br> <a href=https://doi.org/10.1109/MRA.2020.2987805 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.05573 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=qQqv2pFMhmo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Object Recognition, Dynamic Contact Simulation, Detection, and Control of the Flexible Musculoskeletal Hand Using a Recurrent Neural Network With Parametric Bias, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 3, pp. 4580-4587, 2020, (<b>presented at IROS2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.3002199 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08050 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=c4mhS5BvkPw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Hiraoka, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Estimation and Control of Motor Core Temperature with Online Learning of Thermal Model Parameters: Application to Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 3, pp. 4273-4280, 2020, (<b>presented at IROS2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.2990889 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08055 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Musculoskeletal AutoEncoder: A Unified Online Acquisition Method of Intersensory Networks for State Estimation, Control, and Simulation of Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 2, pp. 2411-2418, 2020, (<b>presented at ICRA2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.2972841 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.17134 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=E510TsXRTf8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, S. Nakashima, Y. Asano, K. Okada, M. Inaba<br>Human Mimetic Forearm and Hand Design with a Radioulnar Joint and Flexible Machined Spring Finger for Human Skillful Motions, <i>Journal of Robotics and Mechatronics (<b>JRM</b>)</i>, vol. 32, no. 2, pp. 445-458, 2020, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.20965/jrm.2020.p0445 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09934 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=h1sEw56zCwo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Long-time Self-body Image Acquisition and its Application to the Control of Musculoskeletal Structures, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 4, no. 3, pp. 2965-2972, 2019, (<b>presented at IROS2019</b>)<br> <a href=https://doi.org/10.1109/LRA.2019.2923968 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05293 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=P5Z4XRYXYzA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>Online Learning of Joint-Muscle Mapping using Vision in Tendon-driven Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 3, no. 2, pp. 772-779, 2018, (<b>presented at ICRA2018</b>)<br> <a href=https://doi.org/10.1109/LRA.2018.2789849 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05295 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=8_A6--bzAeQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Kawamura, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Antagonist Inhibition Control in Redundant Tendon-driven Structures Based on Human Reciprocal Innervation for Wide Range Limb Motion of Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 2, no. 4, pp. 2119-2126, 2017, (<b>presented at IROS2017</b>)<br> <a href=https://doi.org/10.1109/LRA.2017.2720854 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.00705 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=nFMRb1SCs1Q target='_blank'>[Video]</a></li>
</ol>
<h3> International Conference Proceedings (Peer Reviewed) </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, S. Sawaguchi, A. Iwata, K. Yoneda, T. Suzuki, K. Okada<br>MEVITA: Open-Source Bipedal Robot Assembled from E-Commerce Components via Sheet Metal Welding, in <i>Humanoids2025</i>, 2025, (<b>The first two authors contributed equally to this work</b>)</li>
<li>T. Suzuki, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>A Universal Wire Testing Machine for Enhancing the Performance of Wire-Driven Robots, in <i>Humanoids2025</i>, 2025</li>
<li>T. Hattori, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Design and Development of a Remotely Wire-Driven Walking Robot, in <i>Humanoids2025</i>, 2025</li>
<li><b><u>K. Kawaharazuka</u></b>, S. Inoue, Y. Sahara, K. Yoneda, T. Suzuki, K. Okada<br>Design Optimization of Three-Dimensional Wire Arrangement Considering Wire Crossings for Tendon-driven Robots, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025<br> <a href=https://arxiv.org/abs/2507.04235 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/muscle-3d-opt/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cy510s-kOaY target='_blank'>[Video]</a></li>
<li>K. Yoneda, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, T. Hattori, K. Okada<br>KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025<br> <a href=https://arxiv.org/abs/2507.06562 target='_blank'>[Arxiv Link]</a> <a href=https://keitayoneda.github.io/kleiyn-chimney-climbing/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cLfUhyNFOeY target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, K. Yoneda, S. Yuzaki, Y. Sahara, T. Suzuki, K. Okada<br>An RGB-D Camera-Based Multi-Small Flying Anchors Control for Wire-Driven Robots Connecting to the Environment, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025</li>
<li>S. Yoshimura, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025</li>
<li>R. Watanabe, T. Miki, F. Shi, Y. Kadokawa, F. Bjelonic, <b><u>K. Kawaharazuka</u></b>, A. Cramariuc, M. Hutter<br>Learning Quiet Walking for a Small Home Robot, in <i>2025 IEEE International Conference on Robotics and Automation (<b>ICRA2025</b>)</i>, 2025<br> <a href=https://arxiv.org/abs/2502.10983 target='_blank'>[Arxiv Link]</a> <a href=https://sony.github.io/QuietWalk/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=6RjkBHSYEcc target='_blank'>[Video]</a></li>
<li>S. Kim, N. Kanazawa, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Front Hair Styling Robot System Using Path Planning for Root-Centric Strand Adjustment, in <i>2025 IEEE/SICE International Symposium on System Integration (<b>SII2025</b>)</i>, 2025, <b><font color='red'>Best Student Paper Finalist</font></b><br> <a href=https://arxiv.org/abs/2501.10991 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=AUBmOXsnqbg target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Inoue, T. Suzuki, S. Yuzaki, S. Sawaguchi, K. Okada, M. Inaba<br>MEVIUS: A Quadruped Robot Easily Constructed through E-Commerce with Sheet Metal Welding and Machining, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 631-636, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769853 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.14721 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/mevius-hardware/ target='_blank'>[Project Page]</a> <a href=https://github.com/haraduka/mevius target='_blank'>[Source Code]</a> <a href=https://www.youtube.com/watch?v=XXJ4EK3Y4zQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 934-940, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769848 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.22707 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=4LzAM_bGBAI target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, Y. Ribayashi, Y. Sahara, K. Okada<br>CubiXMusashi: Fusion of Wire-Driven CubiX and Musculoskeletal Humanoid Musashi toward Unlimited Performance, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 274-279, 2024, <b><font color='red'>Mike Stillman Award</font></b><br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769840 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.23682 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/cubixmusashi/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=IvzP98-r_mo target='_blank'>[Video]</a></li>
<li>Y. Iwata, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Integrative Wrapping System for a Dual-Arm Humanoid Robot, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 84-90, 2024, <b><font color='red'>Kanako Miura Award</font></b><br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769922 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.08389 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Obinata, H. Jia, <b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada<br>Remote Life Support Robot Interface System for Global Task Planning and Local Action Expansion Using Foundation Models, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 738-743, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769852 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.10038 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=bM0w69k0LM8 target='_blank'>[Video]</a></li>
<li>S. Sawaguchi, T. Suzuki, A. Miki, <b><u>K. Kawaharazuka</u></b>, S. Yuzaki, S. Yoshimura, Y. Ribayashi, K. Okada, M. Inaba<br>Vlimb: A Wire-Driven Wearable Robot for Bodily Extension, Balancing Powerfulness and Reachability, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 851-857, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769893 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.09565 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=JIRoCHnsVrw target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, Y. Sahara, S. Sawaguchi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Fundamental Three-Dimensional Configuration of Wire-Wound Muscle-Tendon Complex Drive, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 980-987, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769901 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.03838 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=EDeAqg7aAb4 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Robot Design Optimization with Rotational and Prismatic Joints Using Black-Box Multi-Objective Optimization, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 4571-4577, 2024<br> <a href=https://doi.org/10.1109/IROS58592.2024.10802642 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.20038 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/prismatic-joint-opt/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=XTihjUsbkNw target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, K. Okada, M. Inaba<br>CubiX: Portable Wire-Driven Parallel Robot Connecting to and Utilizing the Environment, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 1296-1301, 2024, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2024)</font></b>, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2024)</font></b><br> <a href=https://doi.org/10.1109/IROS58592.2024.10802299 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.05933 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/cubix-hardware/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=R5ZrzMPEFZs target='_blank'>[Video]</a></li>
<li>S. Yoshimura, A. Miki, K. Miyama, Y. Sahara, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Patterned Structure Muscle : Arbitrary Shaped Wire-Driven Artificial Muscle Utilizing Anisotropic Flexible Structure for Musculoskeletal Robots, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 13930-13937, 2024, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2024)</font></b>, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2024)</font></b><br> <a href=https://doi.org/10.1109/IROS58592.2024.10801899 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.07682 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Sahara, A. Miki, Y. Ribayashi, S. Yoshimura, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Construction of Musculoskeletal Simulation for Shoulder Complex with Ligaments and Its Validation via Model Predictive Control, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 327-333, 2024<br> <a href=https://doi.org/10.1109/IROS58592.2024.10802465 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.05931 target='_blank'>[Arxiv Link]</a> <a href=https://sahara-yuta.github.io/projects/shoulder-complex-simulation target='_blank'>[Project Page]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Robotic Constrained Imitation Learning for the Peg Transfer Task in Fundamentals of Laparoscopic Surgery, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 606-612, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610059 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.03440 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/fls-imitation/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cg7bFTj_hPo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Adaptive Whole-body Robotic Tool-use Learning on Low-rigidity Plastic-made Humanoids Using Vision and Tactile Sensors, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 583-589, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610913 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.04826 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/wholebody-tooluse/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=auCYNiMiXXE target='_blank'>[Video]</a></li>
<li>A. Tang, T. Hiraoka, N. Hiraoka, F. Shi, <b><u>K. Kawaharazuka</u></b>, K. Kojima, K. Okada, M. Inaba<br>HumanMimic: Learning Natural Locomotion and Transitions for Humanoid Robot via Wasserstein Adversarial Imitation, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 13107-13114, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610449 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.14225 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=sdM11yHpzi8 target='_blank'>[Video]</a></li>
<li>K. Shirai, C. C. Beltran-Hernandez, M. Hamaya, A. Hashimoto, S. Tanaka, <b><u>K. Kawaharazuka</u></b>, K. Tanaka, Y. Ushiku, S. Mori<br>Vision-Language Interpreter for Robot Task Planning, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 2051-2058, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10611112 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2311.00967 target='_blank'>[Arxiv Link]</a> <a href=https://kskshr.github.io/vilain/ target='_blank'>[Project Page]</a> <a href=https://github.com/omron-sinicx/vilain target='_blank'>[Source Code]</a></li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 6892-6903, 2024, <b><font color='red'>Best Conference Paper Award</font></b>, <b><font color='red'>Finalists of Best Paper Award in Robot Manipulation</font></b><br> <a href=https://doi.org/10.1109/ICRA57147.2024.10611477 target='_blank'>[Paper Link]</a> <a href=https://robotics-transformer-x.github.io/paper.pdf target='_blank'>[Arxiv Link]</a> <a href=https://robotics-transformer-x.github.io/ target='_blank'>[Project Page]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Body Design and Gait Generation of Chair-Type Asymmetrical Tripedal Low-rigidity Robot, in <i>2024 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2024</b>)</i>, pp. 593-600, 2024<br> <a href=https://doi.org/10.1109/RoboSoft60065.2024.10522029 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05932 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/chair-type-tripedal-robot/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=-f8LDlhmdBg target='_blank'>[Video]</a></li>
<li>A. Miki, Y. Sahara, K. Miyama, Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, S. Hasegawa, K. Okada, M. Inaba<br>Designing Fluid-Exuding Cartilage for Biomimetic Robots Mimicking Human Joint Lubrication Function, in <i>2024 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2024</b>)</i>, pp. 452-459, 2024<br> <a href=https://doi.org/10.1109/RoboSoft60065.2024.10521920 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.06740 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 458-465, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375211 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2303.05674 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, Y. Obinata, K. Okada, M. Inaba<br>Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via Large-Scale Vision-Language Model, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 452-457, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375239 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2312.07451 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=WIJLf-KmvM0 target='_blank'>[Video]</a></li>
<li>S. Yoshimura, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Optimization of Muscle Arrangement Extraction from Human Waist Structure for Biomimetic Humanoid Implementation, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 583-590, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375213 target='_blank'>[Paper Link]</a></li>
<li>Y. Ribayashi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Wire-Wound Muscle-Tendon Complex Drive and Its Application to a Two-Dimensional Robot Configuration, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 758-764, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375220 target='_blank'>[Paper Link]</a></li>
<li>S. Yuzaki, A. Miki, M. Bando, S. Yoshimura, T. Suzuki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Fusion of Body and Environment with Movable Carabiners for Wire-Driven Robots Toward Expansion of Physical Capabilities, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 679-685, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375200 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Makabe, K. Okada, M. Inaba<br>Daily Assistive Modular Robot Design Based on Multi-Objective Black-Box Optimization, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 9970-9977, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10342041 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.14226 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/auto-modular-design/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=ztcq0P92mJI target='_blank'>[Video]</a></li>
<li>Y. Matsuura, <b><u>K. Kawaharazuka</u></b>, N. Hiraoka, K. Kojima, K. Okada, M. Inaba<br>Development of a Whole-Body Work Imitation Learning System by a Biped and Bi-Armed Humanoid, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 10374-10381, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10342502 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.15756 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/jaxon-tablis-imitation/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=RsoI0W8SPPA target='_blank'>[Video]</a></li>
<li>Y. Obinata, <b><u>K. Kawaharazuka</u></b>, N. Kanazawa, N. Yamaguchi, N. Tsukamoto, I. Yanokura, S. Kitagawa, K. Shinjo, K. Okada, M. Inaba<br>Semantic Scene Difference Detection in Daily Life Patroling by Mobile Robots Using Pre-Trained Large-Scale Vision-Language Model, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 3228-3233, 2023, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2023)</font></b>, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2023)</font></b><br> <a href=https://doi.org/10.1109/IROS55552.2023.10342467 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.16552 target='_blank'>[Arxiv Link]</a></li>
<li>K. Miyama, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Five-Fingerd Biomimetic Soft Robotic Hand by 3D Printing the Skin and Skeleton As One Unit, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 6624-6630, 2023, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2023)</font></b><br> <a href=https://doi.org/10.1109/IROS55552.2023.10341570 target='_blank'>[Paper Link]</a></li>
<li>S. Yoshimura, T. Suzuki, M. Bando, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Design Method of a Kangaroo Robot with High Power Legs and an Articulated Soft Tail, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 6631-6638, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10341756 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.07742 target='_blank'>[Arxiv Link]</a></li>
<li>A. Ichikura, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>A Method for Selecting Scenes and Emotion-Based Descriptions for a Robot's Diary, in <i>32nd IEEE International Conference on Robot and Human Interactive Communication (<b>ROMAN2023</b>)</i>, pp. 1683-1688, 2023<br> <a href=https://doi.org/10.1109/RO-MAN57019.2023.10309432 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01951 target='_blank'>[Arxiv Link]</a></li>
<li>A. Miki, <b><u>K. Kawaharazuka</u></b>, M. Bando, K. Okada, K. Kawasaki, M. Inaba<br>System Architecture and Real-World Task Realization of Musculoskeletal Wheeled Robot Musashi-W with Various Hardware Components, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 109-122, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_9 target='_blank'>[Paper Link]</a></li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, S. Hasegawa, K. Okada, M. Inaba<br>Workspace-Based Precision Grasp Pose Generator for Multi-Fingered Robotic Hands, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 379-392, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_29 target='_blank'>[Paper Link]</a></li>
<li>N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 547-560, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_42 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01528 target='_blank'>[Arxiv Link]</a></li>
<li>A. Ichikura, <b><u>K. Kawaharazuka</u></b>, Y. Obinata,, K. Shinjo, K. Okada, M. Inaba<br>Automatic Diary Generation System Including Information on Joint Experiences between Humans and Robots, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 399-412, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44981-9_33 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01948 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>VQA-based Robotic State Recognition Optimized with Genetic Algorithm, in <i>2023 IEEE International Conference on Robotics and Automation (<b>ICRA2023</b>)</i>, pp. 8306-8311, 2023<br> <a href=https://doi.org/10.1109/ICRA48891.2023.10160390 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2303.05052 target='_blank'>[Arxiv Link]</a></li>
<li>H. Sato, <b><u>K. Kawaharazuka</u></b>, T. Makabe, K. Okada, M. Inaba<br>Online Estimation of Self-Body Deflection with Various Sensor Data Based on Directional Statistics, in <i>2023 IEEE/SICE International Symposium on System Integration (<b>SII2023</b>)</i>, pp. 1-8, 2023<br> <a href=https://doi.org/10.1109/SII55687.2023.10039450 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2306.03616 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, T. Suzuki, Y. Ribayashi, Y. Toshimitsu, Y. Nagamatsu, K. Okada, M. Inaba<br>Hardware Design and Learning-Based Software Architecture of Musculoskeletal Wheeled Robot Musashi-W for Real-World Applications, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 413-419, 2022, <b><font color='red'>Best Interactive Paper Award Finalist</font></b><br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000123 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11729 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=VhBfpYB-QxI target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Suzuki, K. Okada, M. Inaba<br>Continuous Jumping of a Parallel Wire-Driven Monopedal Robot RAMIEL Using Reinforcement Learning, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 759-764, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000182 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11205 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=y8YqJt3HZvY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada, M. Inaba<br>Learning-Based Wiping Behavior of Low-Rigidity Robots Considering Various Surface Materials and Task Definitions, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 919-924, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000172 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11198 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=N47IXZ6Q0io target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, D. Kusuyama, A. Miki, K. Shinjo, M. Bando, T. Suzuki, Y. Kojio, K. Okada, M. Inaba<br>Design of Robot Foot with Outer Edge Measurement Structure and Chair Rotation Motion by Friction Control, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 314-321, 2022, (<b>Top 7 Best Oral Paper Presentation</b>)<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000127 target='_blank'>[Paper Link]</a></li>
<li>K. Miyama, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, N. Yamaguchi, K. Okada, M. Inaba<br>Design of a Five-Fingered Hand with Full-Fingered Tactile Sensors Using Conductive Filaments and Its Application to Bending after Insertion Motion, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 780-785, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000181 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.00732 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Realization of Seated Walk by a Musculoskeletal Humanoid with Buttock-Contact Sensors From Human Constrained Teaching, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5774-5780, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9982103 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.00892 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=r1vhMWBkiHU target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Online Learning Feedback Control Considering Hysteresis for Musculoskeletal Structures, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5767-5773, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981052 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11808 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=8exSF0LB4t8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Ribayashi, A. Miki, Y. Toshimitsu, T. Suzuki, K. Okada, M. Inaba<br>Learning of Balance Controller Considering Changes in Body State for Musculoskeletal Humanoids, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5809-5816, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981051 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11803 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=OZh__9a4OTQ target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, A. Miki, K. Okada, M. Inaba<br>DIJE: Dense Image Jacobian Estimation for Robust Robotic Self-Recognition and Visual Servoing, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 2219-2226, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981868 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=7wFUZGFtjLE target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, D. Kusuyama, A. Miki, K. Shinjo, M. Bando, T. Suzuki, Y. Kojio, K. Okada, M. Inaba<br>Imitation Behavior of the Outer Edge of the Foot by Humanoids Using a Simplified Contact State Representation, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 4243-4249, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981673 target='_blank'>[Paper Link]</a></li>
<li>T. Suzuki, Y. Toshimitsu, Y. Nagamatsu, <b><u>K. Kawaharazuka</u></b>, A. Miki, Y. Ribayashi, M. Bando, K. Kojima, Y. Kakiuchi, K. Okada, M. Inaba<br>RAMIEL: A Parallel-Wire Driven Monopedal Robot for High and Continuous Jumping, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5017-5024, 2022, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2022)</font></b><br> <a href=https://doi.org/10.1109/IROS47612.2022.9981963 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2311.04573 target='_blank'>[Arxiv Link]</a> <a href=https://tenrobo18.github.io/ramiel-iros2022/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=dPmIMdITTwM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Shinjo, Y. Kawamura, K. Okada, M. Inaba<br>Environmentally Adaptive Control Including Variance Minimization Using Stochastic Predictive Network with Parametric Bias: Application to Mobile Robots, in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2021</b>)</i>, pp. 8381-8387, 2021<br> <a href=https://doi.org/10.1109/IROS51168.2021.9636416 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.08275 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=4LzAM_bGBAI target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, M. Nishiura, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture, in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2021</b>)</i>, pp. 3204-3210, 2021<br> <a href=https://doi.org/10.1109/IROS51168.2021.9636845 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2502.12803 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=kSkTid0RSQg target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Hiraoka, Y. Koga, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Online Learning of Danger Avoidance for Complex Structures of Musculoskeletal Humanoids and Its Applications, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 349-355, 2021<br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555792 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Motion Modification Method of Musculoskeletal Humanoids by Human Teaching Using Muscle-Based Compensation Control, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 83-89, 2021<br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555772 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06323 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=e3EBWVx7z90 target='_blank'>[Video]</a></li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Development of Musculoskeletal Legs with Planar Interskeletal Structures to Realize Human Comparable Moving Function, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 17-24, 2021, <b><font color='red'>Best Oral Paper Award</font></b>, <b><font color='red'>Finalists of Mike Stilman Paper Award</font></b><br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555807 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.00890 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=zF0YdU5bTbg target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Biomimetic Operational Space Control for Musculoskeletal Humanoid Optimizing across Muscle Activation and Joint Nullspace, in <i>2021 IEEE International Conference on Robotics and Automation (<b>ICRA2021</b>)</i>, pp. 1184-1190, 2021<br> <a href=https://doi.org/10.1109/ICRA48506.2021.9561919 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=vthQNaqoXuM target='_blank'>[Video]</a></li>
<li>S. Nakashima, <b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Asano, Y. Kakiuchi, K. Okada, K. Kawasaki, M. Inaba<br>Restoring Force Design of Active Self-Healing Tension Transmission System and Application to Tendon-Driven Legged Robot, in <i>2021 IEEE International Conference on Robotics and Automation (<b>ICRA2021</b>)</i>, pp. 7033-7038, 2021<br> <a href=https://doi.org/10.1109/ICRA48506.2021.9561531 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, S. Nakashima, Y. Toshimitsu, Y. Omura, Y. Koga, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Stability Recognition with Active Vibration for Bracing Behaviors and Motion Extensions Using Environment in Musculoskeletal Humanoids, in <i>2021 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2021</b>)</i>, pp. 126-133, 2021<br> <a href=https://doi.org/10.1109/RoboSoft51838.2021.9479430 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-driven Structures of Musculoskeletal Humanoids, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 3585-3590, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341510 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2502.12808 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 3598-3603, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341488 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2502.12811 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, C. Nabeshima<br>Tool Shape Optimization through Backpropagation of Neural Network, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 8387-8393, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341583 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.12202 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=UjmdjYiUttA target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka M. Nishiura, Y. Koga, Y. Omura, M. Tomita, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Biomimetic Control Scheme for Musculoskeletal Humanoids Based on Motor Directional Tuning in the Brain, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 7784-7791, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9340896 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=fbEi3qmh8pw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the Predictive Model of Sensor State Transition, in <i>2020 IEEE International Conference on Robotics and Automation (<b>ICRA2020</b>)</i>, pp. 4572-4578, 2020<br> <a href=https://doi.org/10.1109/ICRA40945.2020.9197188 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.17136 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=JSK6ljJSIpQ target='_blank'>[Video]</a></li>
<li>T. Nishio, M. Zhao, F. Shi, T. Anzai, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Stable Control in Climbing and Descending Flight under Upper Walls using Ceiling Effect Model based on Aerodynamics, in <i>2020 IEEE International Conference on Robotics and Automation (<b>ICRA2020</b>)</i>, pp. 172-178, 2020<br> <a href=https://doi.org/10.1109/ICRA40945.2020.9197137 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, K. Tsuzuki, M. Onitsuka, Y. Nagamatsu, K. Shinjo, T. Makabe, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Component Modularized Design of Musculoskeletal Humanoid Platform Musashi to Investigate Learning Control Systems, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 7294-7301, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8968068 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.22000 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=t2JZraUT3lY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, M. Onitsuka, K. Shinjo, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Task-specific Self-body Controller Acquisition by Musculoskeletal Humanoids: Application to Pedal Control in Autonomous Driving, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 813-818, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967910 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.08270 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=FPwRuyzzdEc target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, C. Nabeshima<br>Dynamic Task Control Method of a Flexible Manipulator Using a Deep Recurrent Neural Network, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 7689-7695, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967923 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.12201 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=WwCNPGUFjho target='_blank'>[Video]</a></li>
<li>K. Shinjo, <b><u>K. Kawaharazuka</u></b>, Y. Asano, S. Nakashima, S. Makino, M. Onitsuka, K. Tsuzuki, K. Okada, K. Kawasaki, M. Inaba<br>Foot with a Core-shell Structural Six-axis Force Sensor for Pedal Depressing and Recovering from Foot Slipping during Pedal Pushing Toward Autonomous Driving by Humanoids, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 3049-3054, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967519 target='_blank'>[Paper Link]</a></li>
<li>S. Nakashima, T. Shirai, <b><u>K. Kawaharazuka</u></b>, Y. Asano Y. Kakiuchi, K. Okada, M. Inaba<br>An Approach of Facilitated Investigation of Active Self-healing Tension Transmission System Oriented for Legged Robots, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 2567-2572, 2019, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2019)</font></b><br> <a href=https://doi.org/10.1109/IROS40897.2019.8967949 target='_blank'>[Paper Link]</a></li>
<li>T. Makabe, T. Shirai, Y. Nagamatsu, <b><u>K. Kawaharazuka</u></b>, S. Fumihito, K. Okada, M. Inaba<br>Development of Joint Module with Two-Speed Gear Transmission and Joint Lock Mechanism during Driving for Task Adaptable Robot, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 5123-5130, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8968232 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Reflex-based Motion Strategy of Musculoskeletal Humanoids under Environmental Contact Using Muscle Relaxation Control, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 114-119, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9034994 target='_blank'>[Paper Link]</a></li>
<li>Y. Koga, <b><u>K. Kawaharazuka</u></b>, M. Onitsuka, T. Makabe, K. Tsuzuki, Y. Omura, Y. Asano, K. Okada, M. Inaba<br>Modification of Muscle Antagonistic Relations and Hand Trajectory on the Dynamic Motion of Musculoskeletal Humanoid, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 632-637, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9035012 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.00737 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=XDGOLhZcUHg target='_blank'>[Video]</a></li>
<li>Y. Asano, S. Nakashima, I. Yanokura, M. Onitsuka, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Koga, Y. Omura, K. Okada, M. Inaba<br>Ankle-Hip-Stepping Stabilizer on Tendon-Driven Humanoid Kengoro by Integration of Muscle-Joint-Work Space Controllers for Knee-Stretched Humanoid Balance, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 397-402, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9035008 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, J. Tamura, C. Nabeshima<br>Dynamic Manipulation of Flexible Objects with Torque Sequence Using a Deep Neural Network, in <i>2019 IEEE International Conference on Robotics and Automation (<b>ICRA2019</b>)</i>, pp. 2139-2145, 2019<br> <a href=https://doi.org/10.1109/ICRA.2019.8793513 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/1901.10142 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=EuB-TWygkNA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Makabe, S. Makino, K. Tsuzuki, Y. Nagamatsu, Y. Asano, T. Shirai, F. Sugai, K. Okada, K. Kawasaki, M. Inaba<br>TWIMP: Two-Wheel Inverted Musculoskeletal Pendulum as a Learning Control Platform in the Real World with Environmental Physical Contact, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 784-790, 2018, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8624923 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.14080 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=6Y4FpXx6axQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>A Method of Joint Angle Estimation Using Only Relative Changes in Muscle Lengths for Tendon-driven Humanoids with Complex Musculoskeletal Structures, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 1128-1135, 2018<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8625002 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.14100 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=J0q9q7tWJDU target='_blank'>[Video]</a></li>
<li>T. Makabe, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, K. Wada, S. Makino, M. Kawamura, A. Fujii, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Development of Movable Binocular High-Resolution Eye-Camera Unit for Humanoid and the Evaluation of Looking Around Fixation Control and Object Recognition, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 840-845, 2018<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8625072 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, A. Fujii, Y. Asano, K. Okada, M. Inaba<br>Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids, in <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, pp. 1711-1717, 2018<br> <a href=https://doi.org/10.1109/IROS.2018.8593428 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05286 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=jdYbMOj84TA target='_blank'>[Video]</a></li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, A. Fujii, T. Makabe, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints, in <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, pp. 4562-4567, 2018, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2018)</font></b>, <b><font color='red'>IROS ICROS Best Application Paper Award 2018 Finalists</font></b><br> <a href=https://doi.org/10.1109/IROS.2018.8594316 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.17452 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=HRwTFfnlCAs target='_blank'>[Video]</a></li>
<li>A. Fujii, S. Nakashima, M. Kawamura, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Development and Functional Evaluation of a Deformable Membrane Capsule for an Open Ball Glenohumeral Joint, in <i>2018 IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics (<b>BIOROB2018</b>)</i>, pp. 853-858, 2018<br> <a href=https://doi.org/10.1109/BIOROB.2018.8488005 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, Y. Kakiuchi, K. Okada, M. Inaba<br>Human Mimetic Forearm Design with Radioulnar Joint using Miniature Bone-muscle Modules and its Applications, in <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, pp. 4956-4962, 2017, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2017)</font></b><br> <a href=https://doi.org/10.1109/IROS.2017.8206377 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09934 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=h1sEw56zCwo target='_blank'>[Video]</a></li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>High-power, flexible, robust hand: Development of musculoskeletal hand using machined springs and realization of self-weight supporting motion with humanoid, in <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, pp. 1187-1192, 2017<br> <a href=https://doi.org/10.1109/IROS.2017.8202291 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.17459 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=wDDwQoYPRbA target='_blank'>[Video]</a></li>
<li>Y. Asano, T. Kozuki, S. Ookubo, M. Kawamura, S. Nakashima, T. Katayama, Y. Iori, H. Toshinori, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Kakiuchi, K. Okada, M. Inaba<br>Human Mimetic Musculoskeletal Humanoid Kengoro toward Real World Physically Interactive Actions, in <i>2016 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2016</b>)</i>, pp. 876-883, 2016, <b><font color='red'>Best Interactive Paper Award Finalist</font></b><br> <a href=https://doi.org/10.1109/HUMANOIDS.2016.7803376 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=RA4u_9FLzso target='_blank'>[Video]</a></li>
</ol>
<h3> International Workshop, Extended Abstract, etc. </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, T. Matsushima, S. Kurita, C. Paxton, A. Zeng, T. Ogata, T. Taniguchi<br>Special issue on real-world robot applications of the foundation models, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1231, 2024, (<b>Preface</b>)<br> <a href=https://doi.org/10.1080/01691864.2024.2408066 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada<br>Reflexive Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, 2024, <b><font color='red'>Excellent Practice Award</font></b>, (<b>Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects</b>)</li>
<li>S. Yoshimura, T. Suzuki, M. Bando, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Kangaroo-inspired Robot with High-Power Legs and an Articulated Tail, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, 2024, (<b>Workshop on Bio-inspired, Biomimetics, and Biohybrid (Cyborg) Systems</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Neural Information Processing Systems (<b>NeurIPS2023</b>)</i>, 2023, (<b>6th Robot Learning Workshop: Pretraining, Fine-Tuning, and Generalization with Large Scale Models</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Conference on Robot Learning (<b>CoRL2023</b>)</i>, 2023, (<b>2nd Workshop on Language and Robot Learning: Language as Grounding</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Conference on Robot Learning (<b>CoRL2023</b>)</i>, 2023, (<b>Workshop on Towards Generalist Robots: Learning Paradigms for Scalable Skill Acquisition</b>)</li>
<li>Y. Ribayashi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, K. Kawasaki, M. Inaba<br>Muscle-Tendon Complex-Inspired Deformable Exteriors as a Wire-Drive Extension, <i>11th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2023</b>)</i>, 2023<br> <a href=https://doi.org/10.18910/92308 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Modeling and Online Learning of Musculoskeletal Intersensory Networks for Static Controls of Tendon-driven Humanoids, <i>9th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2019</b>)</i>, 2019, <b><font color='red'>Company of Biologists Early Career Researcher Grant (500 GBP)</font></b><br> <a href=https://doi.org/10.5075/epfl-BIOROB-AMAM2019-11 target='_blank'>[Paper Link]</a></li>
</ol>
<h3> arXiv </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Binary State Recognition by Robots using Visual Question Answering of Pre-Trained Vision-Language Model, arXiv preprint arXiv:2310.16405, 2023<br> <a href=https://arxiv.org/abs/2310.16405 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Obinata, N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, I. Yanokura, S. Kim, K. Okada, M. Inaba<br>Foundation Model based Open Vocabulary Task Planning and Executive System for General Purpose Service Robots, arXiv preprint arXiv:2308.03357, 2023<br> <a href=https://arxiv.org/abs/2308.03357 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=fiN4Zibk6Sg target='_blank'>[Video]</a></li>
</ol>
<h3> Domestic Journal Papers </h3>
<ol>
<li>å‰é‡ å¹¸ä¸€éƒ, è°·å£ å¿ å¤§, æŒæ©‹ å¤§åœ°, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾å¶‹ é”ä¹Ÿ, å“å· æ”¿å¤ªæœ—, å°æ— ä¸€éƒ<br>NLP2024 ä½µè¨­ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å®Ÿä¸–ç•Œå¿œç”¨ã€, <i>è‡ªç„¶è¨€èªå‡¦ç†å­¦ä¼šèªŒ (<b>NLP</b>)</i>, vol. 31, no. 2, pp. 809-815, 2024<br> <a href=https://doi.org/10.5715/jnlp.31.809 target='_blank'>[Paper Link]</a></li>
<li>æ–°åŸ å…‰æ¨¹, å¤§æ—¥æ–¹ æ…¶æ¨¹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ­ãƒœãƒƒãƒˆã®éšå±¤ç§»å‹•ã®ãŸã‚ã®ãƒãƒ«ãƒã‚»ãƒ³ã‚µãƒ»IoTã‚¹ã‚¤ãƒƒãƒã‚’ç”¨ã„ãŸç°¡æ˜“å–ä»˜å¯èƒ½ãªã‚¨ãƒ¬ãƒ™ãƒ¼ã‚¿çŠ¶æ…‹èªè­˜ãƒ»æ“ä½œã‚·ã‚¹ãƒ†ãƒ , <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 43, no. 2, pp. 189-197, 2025<br> <a href=https://doi.org/10.7210/jrsj.43.189 target='_blank'>[Paper Link]</a></li>
<li>ä¸‰æœ¨ ç« å¯›,  æ°¸æ¾ ç¥å¼¥, æ¿æ± æ­£ç¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, å¹³å²¡ ç›´æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>é«˜å¿œç­”æ€§ã‚’å‚™ãˆå¤šæ§˜ãªãƒ­ãƒœãƒƒãƒˆã®æ‰±ã„ã‚’å¯èƒ½ã¨ã™ã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŠ½è±¡åŒ–ãƒ‡ãƒã‚¤ã‚¹åˆ¶å¾¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–‹ç™º, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 43, no. 1, pp. 75-86, 2024<br> <a href=https://doi.org/10.7210/jrsj.43.75 target='_blank'>[Paper Link]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤§è¦æ¨¡è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã¨éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ããƒ­ãƒœãƒƒãƒˆã®ãŸã‚ã®çŠ¶æ…‹èªè­˜, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 259-265, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.259 target='_blank'>[Paper Link]</a></li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ã‚¤ãƒ¤è„šã®è·³èºæ€§èƒ½ã«é–¢ã™ã‚‹åŠ›å­¦ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãæ¤œè¨ã¨å®Ÿæ©Ÿã«ãŠã‘ã‚‹æ¤œè¨¼, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 274-282, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.274 target='_blank'>[Paper Link]</a></li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>æ–™ç†ãƒ¬ã‚·ãƒ”è¨˜è¿°è§£æã¨è¦–è¦š - è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ™‚ç³»åˆ—åˆ©ç”¨ã«ã‚ˆã‚‹é£ŸæçŠ¶æ…‹å¤‰åŒ–èªè­˜ã«åŸºã¥ããƒ­ãƒœãƒƒãƒˆã®èª¿ç†ä½œæ¥­å®Ÿè¡Œ, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 266-273, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.266 target='_blank'>[Paper Link]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>æƒ…å ±åŒ–èº«ä½“ã®å­¦ç¿’ç†è«–ã«åŸºã¥ãæˆé•·ãƒ­ãƒœãƒƒãƒˆã®é©æ–°ã¨å‰µæˆ, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 41, no. 8, pp. 669-672, 2023, (<b>è§£èª¬è¨˜äº‹</b>)<br> <a href=https://doi.org/10.7210/jrsj.41.669 target='_blank'>[Paper Link]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒã‚¤ã‚¢ã‚¹ã‚’å«ã‚€æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 40, no. 9, pp. 784-789, 2022, (<b>è§£èª¬è¨˜äº‹</b>)<br> <a href=https://doi.org/10.7210/jrsj.40.784 target='_blank'>[Paper Link]</a></li>
<li>æµ…é‡ æ‚ ç´€, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ°¸æ¾ ç¥å¼¥, å¤è³€ æ‚ çŸ¢, å¤§æ‘ æŸšä»‹, çœŸå£ ä½‘, è—¤äº• ç¶ºé¦™, ä¸­å³¶ æ…ä»‹, æ–°åŸ å…‰æ¨¹, è¥¿æµ¦ å­¦, åˆ©å…‰ æ³°å¾³, å†¨ç”° å¹¹, å²¡ç”° æ…§, æ¸…æ°´ æ™ºå“‰, è¿‘è—¤ æ·³, å·å´ å®æ²», è±Šå³¶ æµ©äºŒ, ç¨²è‘‰ é›…å¹¸<br>ãƒ­ãƒœãƒƒãƒˆæŠ€è¡“ã®ç¤¾ä¼šå®Ÿè£…ã«å‘ã‘ãŸè…±é§†å‹•ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹è‡ªå‹•è»Šé‹è»¢ã®å®Ÿè¨¼å®Ÿé¨“ã¨ç¾©è¶³é–‹ç™ºã¸ã®å±•é–‹ --è…±é§†å‹•ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹è‡ªå‹•è»Šé‹è»¢ã‚’é€šã˜ãŸç”£å®˜å­¦ã®ç¤¾ä¼šé€£æºæ´»å‹•--, <i>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šèªŒ (<b>JRSJ</b>)</i>, vol. 40, no. 3, pp. 240-250, 2022<br> <a href=https://doi.org/10.7210/jrsj.40.240 target='_blank'>[Paper Link]</a></li>
</ol>
<h3> Domestic Conference Proceedings (Peer Reviewed) </h3>
<ol>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã¨éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ããƒ­ãƒœãƒƒãƒˆã®ãŸã‚ã®é›¢æ•£ãƒ»é€£ç¶šçŠ¶æ…‹èªè­˜, in <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, pp. 34-35, 2023</li>
<li>å¤§æ—¥æ–¹ æ…¶æ¨¹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é‡‘æ²¢ ç›´æ™ƒ, å±±å£ ç›´ä¹Ÿ, å¡šæœ¬ ç›´äºº, çŸ¢é‡å€‰ ä¼Šç¹”, åŒ—å· æ™‹å¾, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>äº‹å‰å­¦ç¿’æ¸ˆã¿è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå·¡å›ãƒ­ãƒœãƒƒãƒˆã®é•·æœŸè¨˜æ†¶ã«åŸºã¥ãæ—¥å¸¸ç’°å¢ƒã®çŠ¶æ³åˆ†é¡, in <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, pp. 36-37, 2023</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>èª¿ç†æ”¯æ´ãƒ­ãƒœãƒƒãƒˆã®è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«æ™‚ç³»åˆ—åˆ©ç”¨ã«ã‚ˆã‚‹ãƒ¬ã‚·ãƒ”è¨˜è¿°ã‹ã‚‰ã®é£ŸæçŠ¶æ…‹å¤‰åŒ–èªè­˜, in <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, pp. 66-67, 2023, <b><font color='red'>ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ç ”ç©¶å¥¨åŠ±è³</font></b></li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ã‚¤ãƒ¤ä¸€æœ¬è„šãƒ­ãƒœãƒƒãƒˆã®è·³èºãƒ¢ãƒ‡ãƒ«ã¨è¨­è¨ˆæ³•, in <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, pp. 50-51, 2023</li>
<li>æ·±å±± å’Œæµ©, ææ— å˜‰å…ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>éª¨æ ¼è¡¨çš®ã‚’ä¸€ä½“ã«3Dãƒ—ãƒªãƒ³ãƒˆã—ãŸãƒ­ãƒœãƒƒãƒˆãƒãƒ³ãƒ‰ã®é–‹ç™º, in <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, pp. 293-294, 2023</li>
<li>ä¸‰æœ¨ ç« å¯›, æ¿æ± æ­£ç¥, æ°¸æ¾ ç¥å¼¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, å¹³å²¡ ç›´æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤šç¨®ãƒ­ãƒœãƒƒãƒˆã®æ‰±ã„ã¨é«˜å¿œç­”æ€§ã‚’ä¸¡ç«‹ã—ãŸãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŠ½è±¡åŒ–ãƒ‡ãƒã‚¤ã‚¹åˆ¶å¾¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–‹ç™º, in <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, pp. 239-240, 2023, <b><font color='red'>ç¬¬3å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢å„ªç§€ç ”ç©¶ãƒ»æŠ€è¡“è³</font></b></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, å·æ‘ å°†çŸ¢, è—¤äº• ç¶ºé¦™, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹èº«ä½“çµ„ç¹”ã®æŸ”è»Ÿæ€§ã«ã‚ˆã‚‹ç­‹çµŒè·¯å¤‰åŒ–ã‚’è€ƒæ…®ã—ãŸé€æ¬¡çš„è‡ªå·±èº«ä½“åƒã®ç²å¾—, in <i>ç¬¬23å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM18J</b>)</i>, pp. 306-312, 2018</li>
</ol>
<h3> Domestic Conference Proceedings (No Reviewed) </h3>
<ol>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ã‚ªãƒ¼ãƒ—ãƒ³ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨å­¦ç¿’åˆ¶å¾¡ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2025, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 3M1-01, 2025</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾¤å£ æ˜‡å¾, å²©ç”° æ­©, ç±³ç”° æ…¶å¤ª, éˆ´æœ¨ å¤©é¦¬, å²¡ç”° æ…§<br>MEVITA: E-Commerceã«ã‚ˆã‚Šèª°ã§ã‚‚ç°¡å˜ã«æ§‹ç¯‰å¯èƒ½ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹äºŒè¶³æ­©è¡Œãƒ­ãƒœãƒƒãƒˆ, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 3M1-05, 2025</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, è´¾ æµ©å®‡, å²¡ç”° æ…§<br>å¤šç›®çš„ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æœ€é©åŒ–ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½µç”¨ã—ãŸåŠ¹ç‡çš„ãªãƒ­ãƒœãƒƒãƒˆèº«ä½“è¨­è¨ˆ, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1M5-01, 2025</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾å¶‹ é”ä¹Ÿ, å®®æ¾¤ å’Œè²´<br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2025 (1), in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1M1-01, 2025</li>
<li>æ¾å¶‹ é”ä¹Ÿ, å®®æ¾¤ å’Œè²´, <b><u>æ²³åŸå¡š å¥äºº</u></b><br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2025 (2), in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1M1-02, 2025</li>
<li>å®®æ¾¤ å’Œè²´, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾å¶‹ é”ä¹Ÿ<br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2025 (3), in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1M1-03, 2025</li>
<li>æœéƒ¨ é«˜æ‹“, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, ç±³ç”° æ…¶å¤ª, å²¡ç”° æ…§<br>é éš”ãƒ¯ã‚¤ãƒ¤é§†å‹•å‹ç§»å‹•ä½œæ¥­ãƒ­ãƒœãƒƒãƒˆREWWARMã®ç‰¹æ€§è©•ä¾¡ã¨åˆ¶å¾¡, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1H3-01, 2025</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>éšå±¤çš„ã‚¤ãƒ³ãƒ•ã‚£ãƒ«æ§‹é€ ã‚’æœ‰ã™ã‚‹ãƒãƒ«ãƒãƒãƒ†ãƒªã‚¢ãƒ«3Dãƒ—ãƒªãƒ³ãƒˆåœ§åŠ›ã‚»ãƒ³ã‚µã®é–‹ç™º, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1P3-01, 2025</li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>ãƒ¯ã‚¤ãƒ¤å¹²æ¸‰é§†å‹•ãƒãƒ‹ãƒ¥ãƒ”ãƒ¬ãƒ¼ã‚¿ã®å—å‹•ãƒ—ãƒ¼ãƒªã«ãŠã‘ã‚‹å¼µåŠ›æå¤±ã®è£œå„Ÿ, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1P3-02, 2025</li>
<li>å‹‡å´ é¢¯å¤ª, äº•ä¸Š ä¿¡å¤šéƒ, éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>ãƒ¯ã‚¤ãƒ¤é§†å‹•ç©ºä¸­ç§»å‹•ãƒ­ãƒœãƒƒãƒˆCALVADOSã®ãƒ‰ãƒ­ãƒ¼ãƒ³ã¨ã®é€£æºã«ã‚ˆã‚‹éšœå®³ç‰©å›é¿è¡Œå‹•ã®å®Ÿç¾, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 1R3-06, 2025</li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª,, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç’°å¢ƒæ¥ç¶šå¯èƒ½ãªãƒ¯ã‚¤ãƒ¤é§†å‹•ãƒ­ãƒœãƒƒãƒˆCubiXã®é“å…·åˆä½“åˆ©ç”¨ã«ã‚ˆã‚‹å¤šç¨®ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 2E2-04, 2025</li>
<li>ä¸‰æœ¨ ç« å¯›, é•·è°·å· å³», ææ— å˜‰å…ƒ, ä½åŸ ä¾‘å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>äººä½“ã®æ„Ÿè¦šå™¨é…ç½®ã‚’æ¨¡å€£ã—ãŸç”Ÿä½“æ¨¡å€£çš®è†šã®æ§‹æˆã¨æ¤œè¨¼, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 2H2-02, 2025</li>
<li>ææ— å˜‰å…ƒ, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>ç­‹è…±è¤‡åˆä½“é§†å‹•ã‚’ç”¨ã„ãŸèº«ä½“æ§‹æˆã«ãŠã‘ã‚‹å¼¾æ€§åˆ©ç”¨å‹•ä½œ, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 2H3-01, 2025</li>
<li>å²©ç”° æ­©, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç±³ç”° æ…¶å¤ª, å²¡ç”° æ…§<br>ç­‰èº«å¤§åŒè…•ãƒ­ãƒœãƒƒãƒˆã®å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹é‰„æ£’å¤§è»Šè¼ªå‹•ä½œã®ç²å¾—, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 3M2-02, 2025</li>
<li>ç±³ç”° æ…¶å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æœéƒ¨ é«˜æ‹“, å²¡ç”° æ…§<br>è…°é–¢ç¯€ã‚’æœ‰ã™ã‚‹å››è„šãƒ­ãƒœãƒƒãƒˆKLEIYNã«ã‚ˆã‚‹å¼·åŒ–å­¦ç¿’ã«åŸºã¥ãç«‹ã¡ä¸ŠãŒã‚Šå‹•ä½œã¨äºŒè¶³æ­©è¡Œã®å®Ÿç¾, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 3M2-05, 2025</li>
<li>ä½åŸ ä¾‘å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>è…±ã®å·»ãä»˜ãã¨çµŒè·¯çŸ­çµ¡ã‚’è€ƒæ…®ã—ãŸè…±é§†å‹•ã‚¢ãƒ¼ãƒ ã®è¨­è¨ˆæœ€é©åŒ–, in <i>ç¬¬43å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ25J</b>)</i>, 3H3-01, 2025</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å›è»¢é–¢ç¯€ã¨ç›´å‹•é–¢ç¯€ã‚’å«ã‚€ãƒ­ãƒœãƒƒãƒˆè¨­è¨ˆã®å¤šç›®çš„ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æœ€é©åŒ–, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 1A1-Q01, 2025</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, äº•ä¸Š ä¿¡å¤šéƒ, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, æ¾¤å£ æ˜‡å¾, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>MEVIUS: é‡‘å±åˆ‡å‰Šã¨æ¿é‡‘æº¶æ¥ã«ã‚ˆã‚ŠE-Commerceã§å®¹æ˜“ã«æ§‹ç¯‰å¯èƒ½ãª4è„šãƒ­ãƒœãƒƒãƒˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 2A2-A07, 2025</li>
<li>ç±³ç”° æ…¶å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, æœéƒ¨ é«˜æ‹“, å²¡ç”° æ…§<br>è…°é–¢ç¯€ã‚’æœ‰ã™ã‚‹å››è„šãƒ­ãƒœãƒƒãƒˆKLEIYNã®å¼·åŒ–å­¦ç¿’ã«åŸºã¥ãæ­©è¡Œã¨å£ç™»ã‚Šå‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 2A2-A08, 2025</li>
<li>æœéƒ¨ é«˜æ‹“, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, ç±³ç”° æ…¶å¤ª, å²¡ç”° æ…§<br>ãƒ¯ã‚¤ãƒ¤é éš”é§†å‹•æ©Ÿæ§‹ã¨å¯å¤‰å‰›æ€§ä¼¸ç¸®æ©Ÿæ§‹ã‚’æœ‰ã™ã‚‹ç´°å¾„ç§»å‹•ä½œæ¥­ãƒ­ãƒœãƒƒãƒˆã®è¨­è¨ˆé–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 1P1-E02, 2025</li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹sim2realã«å‘ã‘ãŸãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ã‚¤ãƒ¤é§†å‹•ä¸€æœ¬è„šè·³èºãƒ­ãƒœãƒƒãƒˆRAMIEL2ã®è¨­è¨ˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 1P1-E03, 2025</li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç±³ç”° æ…¶å¤ª, å‹‡å´ é¢¯å¤ª, ä½åŸ ä¾‘å¤ª, éˆ´æœ¨ å¤©é¦¬, å²¡ç”° æ…§<br>ç’°å¢ƒæ¥ç¶šãƒ¯ã‚¤ãƒ¤é§†å‹•ãƒ­ãƒœãƒƒãƒˆã«ãŠã‘ã‚‹RGB-Dã‚«ãƒ¡ãƒ©ã‚’ç”¨ã„ãŸãƒãƒ«ãƒå°å‹é£›è¡Œã‚¢ãƒ³ã‚«ãƒ¼åˆ¶å¾¡, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 2A2-J03, 2025</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>å°é›»æ€§è§¦è¦šæ§‹é€ ã‚’æœ‰ã™ã‚‹æŸ”è»Ÿãƒ©ãƒ†ã‚£ã‚¹æ§‹é€ ç­‹ã§æ§‹æˆã•ã‚ŒãŸäººä½“æ¨¡å€£è„šã®è§¦è¦šåå¿œå‹•ä½œ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 2A2-L05, 2025</li>
<li>å‹‡å´ é¢¯å¤ª, äº•ä¸Š ä¿¡å¤šéƒ, éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>ãƒ¯ã‚¤ãƒ¤é§†å‹•ç©ºä¸­ç§»å‹•ãƒ­ãƒœãƒƒãƒˆCALVADOSã®è»Œé“è¨ˆç”»ã¨ã‚¸ãƒ£ãƒ³ãƒ—å‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 1A2-Q01, 2025</li>
<li>Xu Dong, Shun Hasegawa, Liqi Wu, <b><u>Kento Kawaharazuka</u></b>, Kunio Kojima, Kei Okada<br>A Dual-Track Pulley Actuation System for the Development of Lightweight and Compact Cable-driven Upper Limb Exosuits, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'25 (<b>ROBOMECH25J</b>)</i>, 2P2-K12, 2025</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, å¡šæœ¬ ç›´äºº, å²¡ç”° æ…§<br>å…¨å¤©çƒã‚«ãƒ¡ãƒ©ã¨äº‹å‰å­¦ç¿’æ¸ˆã¿è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äº‹å‰çŸ¥è­˜ã‚’å¿…è¦ã¨ã—ãªã„åå°„å‹Open Vocabulary Navigation, in <i>ç¬¬25å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI24J</b>)</i>, 1F6-04, 2024, <b><font color='red'>å„ªç§€è¬›æ¼”è³</font></b></li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, ææ— å˜‰å…ƒ, ä½åŸ ä¾‘å¤ª, å²¡ç”° æ…§<br>ç’°å¢ƒæ¥ç¶šå¯èƒ½ãªãƒ¯ã‚¤ãƒ¤é§†å‹•ãƒ­ãƒœãƒƒãƒˆCubiXã«ã‚ˆã‚‹ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰Musashiã®é‹å‹•èƒ½åŠ›æ‹¡å¼µ, in <i>ç¬¬25å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI24J</b>)</i>, 3E5-08, 2024, <b><font color='red'>å„ªç§€è¬›æ¼”è³</font></b></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, é‡‘æ²¢ ç›´æ™ƒ, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§<br>å¤§è¦æ¨¡è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹èª¿ç†ãƒ­ãƒœãƒƒãƒˆã®æ™‚ç³»åˆ—é£ŸæçŠ¶æ…‹èªè­˜, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 3D2-03, 2024</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾å¶‹ é”ä¹Ÿ, å®®æ¾¤ å’Œè²´<br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«A, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 3D1-01, 2024<br> <a href=https://speakerdeck.com/haraduka/rsj2024-ji-pan-moderunoshi-robotutoying-yong-tiyutoriarua-he-yuan-zhong target='_blank'>[Slide]</a></li>
<li>æ¾å¶‹ é”ä¹Ÿ, å®®æ¾¤ å’Œè²´, <b><u>æ²³åŸå¡š å¥äºº</u></b><br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«B, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 3D1-02, 2024</li>
<li>å®®æ¾¤ å’Œè²´, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾å¶‹ é”ä¹Ÿ<br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«C, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 3D1-03, 2024</li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç’°å¢ƒæ¥ç¶šå¯èƒ½ãªãƒ¯ã‚¤ãƒ¤é§†å‹•ãƒ­ãƒœãƒƒãƒˆCubiXã«ã‚ˆã‚‹2å°ã®é£›è¡Œã‚¢ãƒ³ã‚«ãƒ¼ã‚’ç”¨ã„ãŸé›²æ¢¯å‹•ä½œ, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 1J5-03, 2024</li>
<li>ç±³ç”° æ…¶å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>å¼¾æ€§è„šã‚’ç”¨ã„ãŸå…­è„šãƒ­ãƒœãƒƒãƒˆã®è¨­è¨ˆã¨å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸå¯¾é¢å£ç™»ã‚Šå‹•ä½œã®å®Ÿç¾, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 2H1-05, 2024</li>
<li>æœéƒ¨ é«˜æ‹“, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>èº«ä½“ã«ã‚¢ã‚¯ãƒãƒ¥ã‚¨ãƒ¼ã‚¿ã‚’ä¸€åˆ‡å«ã¾ãªã„è…±é§†å‹•æ­©è¡Œãƒ­ãƒœãƒƒãƒˆã®è¨­è¨ˆã¨åˆ¶å¾¡, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 2H1-06, 2024</li>
<li>å¤§æ—¥æ–¹ æ…¶æ¨¹, è³ˆ æµ©å®‡, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é‡‘æ²¢ ç›´æ™ƒ, å²¡ç”° æ…§<br>ã‚ã„ã¾ã„ãªç”Ÿæ´»æ”¯æ´ãƒ­ãƒœãƒƒãƒˆå‹•ä½œè¨˜è¿°ã®VLMã¨ARãƒ‡ãƒã‚¤ã‚¹ã‚’ç”¨ã„ãŸæç¤ºã¨æŒ‡ç¤ºã«ã‚ˆã‚‹å±•é–‹, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 3D3-02, 2024</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, éˆ´æœ¨ å¤©é¦¬, ä½åŸ ä¾‘å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>æŸ”è»Ÿãƒ©ãƒ†ã‚£ã‚¹æ§‹é€ ã‚’æ´»ç”¨ã—ãŸãƒ¯ã‚¤ãƒ¤é§†å‹•äººå·¥ç­‹è‚‰ã§æ§‹æˆã•ã‚Œã‚‹äººä½“æ¨¡å€£è„šã®è£½ä½œ, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 3J1-05, 2024</li>
<li>å‹‡å´ é¢¯å¤ª, éˆ´æœ¨ å¤©é¦¬, äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§<br>ãƒ¯ã‚¤ãƒ¤é§†å‹•ç©ºä¸­ç§»å‹•ãƒ­ãƒœãƒƒãƒˆã®åœ°ä¸Šã¨ç©ºä¸­ã‚’å«ã‚€å¤šæ§˜ãªãƒ­ã‚³ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ24J</b>)</i>, 1J5-04, 2024</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å‰æ‘ é§¿ä¹‹ä»‹, éˆ´æœ¨ å¤©é¦¬, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¯å¤‰çµŒç”±ç‚¹ã‚’å«ã‚€è…±é§†å‹•ãƒ­ãƒœãƒƒãƒˆã®ãƒ¯ã‚¤ãƒ¤é…ç½®è¨­è¨ˆæœ€é©åŒ–, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 1A1-M02, 2024</li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç’°å¢ƒæ¥ç¶šå¯èƒ½ãªãƒ¯ã‚¤ãƒ¤é§†å‹•ãƒ­ãƒœãƒƒãƒˆã«ã‚ˆã‚‹ç©ºé–“ç§»å‹•ã¨ç‰©ä½“æ“ä½œ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 1A1-M01, 2024</li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å—å‹•3æ¬¡å…ƒãƒ¯ã‚¤ãƒ¤å‹•åŠ›ä¼é”æ©Ÿæ§‹ã«ãŠã‘ã‚‹ä¼é”åŠ¹ç‡ã®è§£æ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 1P1-O09, 2024, <b><font color='red'>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šè‹¥æ‰‹å„ªç§€è¬›æ¼”ãƒ•ã‚§ãƒ­ãƒ¼è³</font></b></li>
<li>æ¾¤å£ æ˜‡å¾, éˆ´æœ¨ å¤©é¦¬, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å‹‡å´ é¢¯å¤ª, å‰æ‘ é§¿ä¹‹ä»‹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>åŠ›å¼·ã•ã¨å‹•ä½œç¯„å›²ã‚’ä¸¡ç«‹ã™ã‚‹ãƒ¯ã‚¤ãƒ¤é§†å‹•å‹èº«ä½“æ‹¡å¼µã‚¦ã‚§ã‚¢ãƒ©ãƒ–ãƒ«ãƒ­ãƒœãƒƒãƒˆ Vlimb ã®è¨­è¨ˆæ³•, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 1P2-E06, 2024</li>
<li>å‹‡å´ é¢¯å¤ª, éˆ´æœ¨ å¤©é¦¬, å‰æ‘ é§¿ä¹‹ä»‹, æ¾¤å£ æ˜‡å¾, äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤§å‡ºåŠ›ãƒ¯ã‚¤ãƒ¤å·»ãå–ã‚Šæ©Ÿã¨å¤§å¾„ã‚¿ã‚¤ãƒ¤ã‚’æœ‰ã™ã‚‹ãƒ¯ã‚¤ãƒ¤é§†å‹•ç©ºä¸­ç§»å‹•ãƒ­ãƒœãƒƒãƒˆã®é–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 1P1-N09, 2024</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, ä¸‰æœ¨ ç« å¯›, æ·±å±± å’Œæµ©, ä½åŸ ä¾‘å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>æŸ”è»Ÿãƒ©ãƒ†ã‚£ã‚¹æ§‹é€ ã‚’æ´»ç”¨ã—ãŸãƒ¯ã‚¤ãƒ¤é§†å‹•äººå·¥ç­‹è‚‰ã¨ç­‹éª¨æ ¼ä¸Šè…•æ§‹é€ ã®æ§‹æˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I01, 2024</li>
<li>ä½åŸ ä¾‘å¤ª, ä¸‰æœ¨ ç« å¯›, ææ— å˜‰å…ƒ, å‰æ‘ é§¿ä¹‹ä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>é­å¸¯ã‚’å‚™ãˆãŸè‚©è¤‡åˆä½“ã®ç­‹éª¨æ ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆæ³•ã¨åˆ¶å¾¡, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I02, 2024</li>
<li>ä¸‰æœ¨ ç« å¯›, ä½åŸ ä¾‘å¤ª, å‰æ‘ é§¿ä¹‹ä»‹, ææ— å˜‰å…ƒ, å‹‡å´ é¢¯å¤ª, æ·±å±± å’Œæµ©, é•·è°·å· å³», <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>é–¢ç¯€æ¶²å†…åŒ…æ©Ÿèƒ½ã¨é–¢ç¯€å—å®¹å™¨æ©Ÿèƒ½ã‚’å‚™ãˆãŸäººä½“æ¨¡å€£ãƒ­ãƒœãƒƒãƒˆã®é–¢ç¯€åŒ…æ§‹æˆæ³•, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I03, 2024</li>
<li>ææ— å˜‰å…ƒ, ä½åŸ ä¾‘å¤ª, æ¾¤å£ æ˜‡å¾, æ·±å±± å’Œæµ©, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ã‚¢ãƒ¼ãƒçŠ¶æ§‹é€ æã‚’ç”¨ã„ãŸè†¨å¼µã‚’ä¼´ã†å¤‰å½¢ã®è¨­è¨ˆã¨ãƒ¯ã‚¤ãƒ¤å·»å–å¼äººå·¥ç­‹è‚‰ã¸ã®é©ç”¨, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 2P1-K10, 2024</li>
<li>åœ’ç”° ç¾éƒ·, å” å®‰å—, çŸ³ç”° å¯›å’Œ, å¹³å²¡ æ‹“çœŸ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å°å³¶ é‚¦ç”Ÿ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç›¸å¯¾ãƒ­ãƒƒãƒ‰ä½ç½®å§¿å‹¢ã«ç€ç›®ã—ãŸæ­£äºŒåé¢ä½“ãƒ†ãƒ³ã‚»ã‚°ãƒªãƒ†ã‚£ãƒ­ãƒœãƒƒãƒˆã®è»¢ãŒã‚Šé‹å‹•åˆ¶å¾¡æ–¹ç­–ã®å­¦ç¿’ç²å¾—, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'24 (<b>ROBOMECH24J</b>)</i>, 2P1-M10, 2024</li>
<li>å¤§æ—¥æ–¹ æ…¶æ¨¹, å¡šæœ¬ ç›´äºº, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é‡‘æ²¢ ç›´æ™ƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç”Ÿæ´»æ”¯æ´ãƒ­ãƒœãƒƒãƒˆã®ç¾å ´çŸ¥è­˜ã«åŸºã¥ãã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‹•ä½œãƒ—ãƒ­ã‚°ãƒ©ãƒ å±•é–‹, in <i>ç¬¬38å›äººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼š (<b>JSAI24J</b>)</i>, 4E1-GS-8-04, 2024</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨å¤å…¸ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’ç”¨ã„ãŸãƒ¬ã‚·ãƒ”è¨˜è¿°ã‹ã‚‰ã®å®Ÿä¸–ç•Œèª¿ç†è¨ˆç”»èªè­˜å®Ÿè¡Œãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ , in <i>è¨€èªå‡¦ç†å­¦ä¼šç¬¬30å›å¹´æ¬¡å¤§ä¼š (<b>NLP24J</b>)</i>, E1-3, 2024</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¯¾è±¡ç‰©çŠ¶æ…‹ä¸­å¿ƒã®èª¿ç†è¡Œå‹•è¨˜è¿°ã«åŸºã¥ããƒ¬ã‚·ãƒ”ã‹ã‚‰ã®åµæ–™ç†ã®å®Ÿä¸–ç•Œèª¿ç†å®Ÿè¡Œãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ , in <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 3G2-08, 2023, <b><font color='red'>å„ªç§€è¬›æ¼”è³</font></b></li>
<li>æ·±å±± å’Œæµ©, ææ— å˜‰å…ƒ, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å°é›»æ€§ãƒ•ã‚£ãƒ©ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹è¡¨çš®éª¨æ ¼ä¸€ä½“ãƒ­ãƒœãƒƒãƒˆãƒãƒ³ãƒ‰ã®æ¥è§¦ç‚¹æ¨å®šã«é–¢ã™ã‚‹ç ”ç©¶, in <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 2E3-08, 2023</li>
<li>ä¸‰æœ¨ ç« å¯›, ä½åŸ ä¾‘å¤ª, æ·±å±± å’Œæµ©, ææ— å˜‰å…ƒ, é•·è°·å· å³», <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>äººã®é–¢ç¯€æ½¤æ»‘æ©Ÿèƒ½ã‚’æ¨¡ã—ãŸäººä½“æ¨¡å€£ãƒ­ãƒœãƒƒãƒˆã®æ¶²ä½“æ»²å‡ºè»Ÿéª¨æ©Ÿæ§‹ã®æ§‹æˆæ³•, in <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 2E3-07, 2023, <b><font color='red'>å„ªç§€è¬›æ¼”è³</font></b></li>
<li>æ¹¯ç”° ä¸€æˆ, å” å®‰å—, å°å³¶ é‚¦ç”Ÿ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‰èº«å¤§ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®å…¨èº«é‹å‹•ã«ãŠã‘ã‚‹ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã«ç€ç›®ã—ãŸé–¢ç¯€é‹å‹•å”èª¿æ€§ã®è§£æ, in <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 3H2-06, 2023</li>
<li>é‡‘ æ·³æš, é‡‘æ²¢ ç›´æ™ƒ, é•·è°·å· å³», <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç”Ÿæ´»æ”¯æ´ãƒ­ãƒœãƒƒãƒˆã‚’ç”¨ã„ãŸè¦–è¦šã¨åŠ›è¦šã«åŸºã¥ãé ­é«ªãƒ–ãƒ©ãƒƒã‚·ãƒ³ã‚°å‹•ä½œç”Ÿæˆã«é–¢ã™ã‚‹ç ”ç©¶, in <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 3F1-08, 2023</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¾å¶‹ é”ä¹Ÿ<br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«1, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1K3-01, 2023<br> <a href=https://speakerdeck.com/haraduka/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru1-ji-cun-noji-pan-moderuwoshi-robotutoniying-yong-surufang-fa target='_blank'>[Slide]</a></li>
<li>æ¾å¶‹ é”ä¹Ÿ, <b><u>æ²³åŸå¡š å¥äºº</u></b><br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1K3-02, 2023<br> <a href=https://speakerdeck.com/tmats/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru2-shi-robotutoyong-noji-pan-moderuwozuo-tutehuo-yong-surufang-fa target='_blank'>[Slide]</a></li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>èª¿ç†ãƒ­ãƒœãƒƒãƒˆã®ãŸã‚ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ã«ã‚ˆã‚‹ãƒ¬ã‚·ãƒ”è¨˜è¿°ã‹ã‚‰ã®åµæ–™ç†ã®é£ŸæçŠ¶æ…‹å¤‰åŒ–èªè­˜ã¨å‹•ä½œã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1K3-03, 2023</li>
<li>å‘‰ çŸ¥å‹³, <b><u>æ²³åŸå¡š å¥äºº</u></b>, çŸ³ç”° å¯›å’Œ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å®Ÿæ™‚é–“ç‰©ä½“è¿½è·¡ã‚’ç”¨ã„ãŸè¦–è¦šçš„å¤‰åŒ–ã«ãƒ­ãƒã‚¹ãƒˆãªãƒ­ãƒœãƒƒãƒˆã®Visuomotoræ–¹ç­–ç²å¾—ã‚·ã‚¹ãƒ†ãƒ , in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1K3-07, 2023</li>
<li>å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, çŸ¢é‡å€‰ ä¼Šç¹”, é‡‘ æ·³æš, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚¿ã‚¹ã‚¯å®Ÿè¡Œç®¡ç†å™¨ç”Ÿæˆæ³•ã¨RoboCup JapanOpen @Home League GPSRã‚¿ã‚¹ã‚¯ã¸ã®å¿œç”¨, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1K4-05, 2023, <b><font color='red'>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šç¬¬5å›å„ªç§€è¬›æ¼”è³</font></b></li>
<li>å¡šæœ¬ ç›´äºº, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¸‚å€‰ æ„›å­, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤§è¦æ¨¡è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ç”¨ã„ãŸãƒ­ãƒœãƒƒãƒˆã®è¨˜æ†¶è“„ç©ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å…±æœ‰, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1K4-07, 2023</li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>æ¤…å­å‹éå¯¾ç§°ä¸‰è„šç§»å‹•ãƒ­ãƒœãƒƒãƒˆã®èº«ä½“è¨­è¨ˆã¨æ­©å®¹ç”Ÿæˆ, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 2D1-04, 2023</li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ¯ã‚¤ãƒ¤å¹²æ¸‰é§†å‹•ã‚¢ãƒ¼ãƒ ã«ã‚ˆã‚‹é«˜é€Ÿæ‰“æ’ƒå‹•ä½œå®Ÿç¾, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 3E4-02, 2023</li>
<li>å‹‡å´ é¢¯å¤ª, éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ¯ã‚¤ãƒ¤é§†å‹•å‹3æ¬¡å…ƒç©ºä¸­ç§»å‹•è£…ç½®ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹æ¤œè¨, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1D2-01, 2023</li>
<li>å°å¡š é™½å¸Œ, è¶™ æ¼ å±…, è¥¿å°¾ å“ç´”, å” å®‰å—, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>å®Ÿæ©Ÿæ¤œè¨¼ã«åŸºã¥ãæ™‚é–“é…ã‚Œã«ç€ç›®ã—ãŸãƒãƒ«ãƒãƒ­ãƒ¼ã‚¿éšœå®³ç‰©å›é¿ã®ãŸã‚ã®æ±ç”¨çš„ãªå­¦ç¿’æ–¹ç­–ã®æ§‹ç¯‰, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 2H3-05, 2023</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤šç›®çš„ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æœ€é©åŒ–ã¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ã«ã‚ˆã‚‹æ‹®æŠ—ãƒ¯ã‚¤ãƒ¤é§†å‹•è„šã®ç­‹é…ç½®ç”Ÿæˆ, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 3I3-07, 2023</li>
<li>ä¸‰æœ¨ ç« å¯›, ä½åŸ ä¾‘å¤ª, æ·±å±± å’Œæµ©, å‰æ‘ é§¿ä¹‹ä»‹, ææ— å˜‰å…ƒ, é•·è°·å· å³», <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>äººé–“ã®é–¢ç¯€å¯å‹•åŸŸã‚’æº€ãŸã™æ¨¡æ“¬é­å¸¯æ§‹æˆæ³•ã®åŸºç¤çš„æ¤œè¨, in <i>ç¬¬41å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ23J</b>)</i>, 1B3-03, 2023</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, çœŸå£ ä½‘, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤šç›®çš„ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æœ€é©åŒ–ã«åŸºã¥ãä½œæ¥­æ”¯æ´ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ãƒ­ãƒœãƒƒãƒˆè¨­è¨ˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1P1-G13, 2023</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>åˆ¶ç´„ä»˜ãæ¨¡å€£å­¦ç¿’ã«ã‚ˆã‚‹ãƒ­ãƒœãƒƒãƒˆã®è…¹è…”é¡æ‰‹è¡“ã®åŸºæœ¬æŠ€èƒ½è¨“ç·´, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 2P2-B22, 2023</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, éˆ´æœ¨ å¤©é¦¬, æ¿æ± æ­£ç¥, å‹‡å´ é¢¯å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è„šã¨å°»å°¾ã‚’æœ‰ã™ã‚‹ã‚«ãƒ³ã‚¬ãƒ«ãƒ¼ãƒ­ãƒœãƒƒãƒˆã®æ§‹æˆæ³•ã¨è·³èºå‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1A1-E19, 2023, <b><font color='red'>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šè‹¥æ‰‹å„ªç§€è¬›æ¼”ãƒ•ã‚§ãƒ­ãƒ¼è³</font></b></li>
<li>æ·±å±± å’Œæµ©, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>äº”æŒ‡ã‚’æœ‰ã™ã‚‹è¡¨çš®éª¨æ ¼ä¸€ä½“å‹ãƒ­ãƒœãƒƒãƒˆãƒãƒ³ãƒ‰ã®è£½ä½œ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1A1-F23, 2023</li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Object size based fingertip workspace processing for acceleration of grasp pose generation, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1A1-F24, 2023</li>
<li>å‹‡å´ é¢¯å¤ª, ä¸‰æœ¨ ç« å¯›, æ¿æ± æ­£ç¥, å‰æ‘ é§¿ä¹‹ä»‹, éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç’°å¢ƒã‚’åˆ©ç”¨ã—ãŸèº«ä½“èƒ½åŠ›æ‹¡å¼µè¡Œå‹•ã®ãŸã‚ã®å¯å‹•ã‚«ãƒ©ãƒ“ãƒŠãƒ¯ã‚¤ãƒ¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­è¨ˆã¨å‹•ä½œå®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1A1-I11, 2023</li>
<li>å¸‚å€‰ æ„›å­, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ­ãƒœãƒƒãƒˆã®ãŠæ•£æ­©ä½“é¨“æ—¥è¨˜ - è¨˜è¿°å†…å®¹ã®é•ã„ã«ã‚ˆã‚‹èª­è€…ã®æ„Ÿæƒ³æ¯”è¼ƒ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1A2-C26, 2023</li>
<li>éˆ´æœ¨ å¤©é¦¬, æ¿æ± æ­£ç¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>3æ¬¡å…ƒå—å‹•ãƒ¯ã‚¤ãƒ¤æ•´åˆ—è£…ç½®ã®è£½ä½œã¨7è‡ªç”±åº¦ãƒãƒ‹ãƒ¥ãƒ”ãƒ¬ãƒ¼ã‚¿ã¸ã®é©ç”¨, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1A1-H16, 2023</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, çŸ³ç”° å¯›å’Œ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>åå¾©è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›†ã‚’ç”¨ã„ãŸæ¨¡å€£å­¦ç¿’ã«ã‚ˆã‚‹ç’°å¢ƒè¨­å‚™æ“ä½œã‚¿ã‚¹ã‚¯ã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1P1-D05, 2023</li>
<li>å¤§æ—¥æ–¹ æ…¶æ¨¹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é‡‘æ²¢ ç›´æ™ƒ, å±±å£ ç›´ä¹Ÿ, å¡šæœ¬ ç›´äºº, çŸ¢é‡å€‰ ä¼Šç¹”, åŒ—å· æ™‹å¾, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤§è¦æ¨¡è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ç”¨ã„ãŸç”Ÿæ´»ç’°å¢ƒã®åˆ†é¡ã¨ãƒ­ãƒœãƒƒãƒˆã‚¿ã‚¹ã‚¯ãƒãƒƒãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ , in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 1P1-D06, 2023</li>
<li>å°å¡š é™½å¸Œ, è¶™ æ¼ å±…, è¥¿å°¾ å“ç´”, å” å®‰å—, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>æ±ç”¨çš„ãªãƒãƒ«ãƒãƒ­ãƒ¼ã‚¿ã«é©å¿œå¯èƒ½ãªå­¦ç¿’æ–¹ç­–ã«ã‚ˆã‚‹éšœå®³ç‰©å›é¿å‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 2A2-D10, 2023, <b><font color='red'>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šç¬¬2å›è‹¥æ‰‹è¬›æ¼”è³</font></b></li>
<li>ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¿æ± æ­£ç¥, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>è„±ç€å¯èƒ½ãªãƒ¯ã‚¤ãƒ¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”¨ã„ãŸç’°å¢ƒç‰©è‡ªåœ¨æ“ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 2P1-C25, 2023</li>
<li>ææ— å˜‰å…ƒ, æ·±å±± å’Œæµ©, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ãƒ¯ã‚¤ãƒ¤å·»å–å¼ç­‹è…±è¤‡åˆä½“é§†å‹•ã®è£½ä½œã¨äºŒæ¬¡å…ƒçš„ãƒ­ãƒœãƒƒãƒˆæ§‹æˆã«ãŠã‘ã‚‹æ¤œè¨¼, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'23 (<b>ROBOMECH23J</b>)</i>, 2P2-D19, 2023</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>æ—¥å¸¸ç”Ÿæ´»æ”¯æ´ãƒ­ãƒœãƒƒãƒˆã«å‘ã‘ãŸå¤§è¦æ¨¡è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã¨é€²åŒ–çš„è¨ˆç®—ã«åŸºã¥ãçŠ¶æ…‹èªè­˜, in <i>ç¬¬37å›äººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼š (<b>JSAI23J</b>)</i>, 3G1-OS-24a-04, 2023</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ã«ã‚ˆã‚‹æ–™ç†ãƒ¬ã‚·ãƒ”è¨˜è¿°ã‹ã‚‰ã®é£ŸæçŠ¶æ…‹å¤‰åŒ–ã‚’è€ƒæ…®ã—ãŸèª¿ç†èªè­˜è¨ˆç”»è¡Œå‹•ãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ , in <i>ç¬¬37å›äººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼š (<b>JSAI23J</b>)</i>, 3G1-OS-24a-02, 2023</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, é‡‘æ²¢ ç›´æ™ƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ä½å‰›æ€§ãƒ­ãƒœãƒƒãƒˆã®èº«ä½“å¤‰åŒ–ã‚’è€ƒæ…®ã—ãŸè‡ªå¾‹çš„è¦–è¦šã‚µãƒ¼ãƒœå­¦ç¿’, in <i>ç¬¬23å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI22J</b>)</i>, 3P2-H07, 2022</li>
<li>æ¥ å±± å¤§æ¨¹, çœŸå£ ä½‘, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ’ãƒˆãƒ»ãƒ­ãƒœãƒƒãƒˆã‚’é‹æ¬å¯èƒ½ãªãƒ¢ãƒ“ãƒªãƒ†ã‚£ã®ãƒãƒ©ãƒ³ã‚¹åˆ¶å¾¡, in <i>ç¬¬23å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI22J</b>)</i>, 1A2-D02, 2022</li>
<li>ææ— å˜‰å…ƒ, æ·±å±± å’Œæµ©, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ¯ã‚¤ãƒ¤å·»å–å¼ç­‹è…±è¤‡åˆä½“é§†å‹•ã«ã‚ˆã‚‹ãƒ­ãƒœãƒƒãƒˆæ§‹æˆã®åŸºç¤çš„æ¤œè¨, in <i>ç¬¬23å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI22J</b>)</i>, 1P3-E09, 2022</li>
<li>é‡‘ æ·³æš, åŒ—å· æ™‹å¾, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>RGB ç”»åƒã«ã‚ˆã‚‹é«ªã®ä¹±é›‘é ˜åŸŸèªè­˜ã¨åœ§åŠ›ã‚»ãƒ³ã‚µã‚’ä»˜ã‘ãŸæ«›ã«ã‚ˆã‚‹é ­çš®æ¥è§¦èªè­˜ã‚’ç”¨ã„ãŸãƒ­ãƒœãƒƒãƒˆæ•´é«ªã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶, in <i>ç¬¬23å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI22J</b>)</i>, 3A2-B08, 2022</li>
<li>ä¸‰æœ¨ ç« å¯›, æ¿æ± æ­£ç¥, æ°¸æ¾ ç¥å¼¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, å¹³å²¡ ç›´æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è»¸é§†å‹•, è…±é§†å‹•, å°è»Šå‹, æ—¢è£½å“ã‚’å«ã‚€å¤šæ§˜ãªãƒ­ãƒœãƒƒãƒˆã‚’æ‰±ã†ãŸã‚ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŠ½è±¡åŒ–ãƒ‡ãƒã‚¤ã‚¹åˆ¶å¾¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–‹ç™º, in <i>ç¬¬23å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI22J</b>)</i>, 3A2-E16, 2022</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ä¸€èˆ¬åŒ–å¤šæ„Ÿè¦šç›¸é–¢ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«åŸºã¥ãèº«ä½“å›³å¼ã®ç²å¾—ã¨èªè­˜åˆ¶å¾¡, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 1F1-03, 2022</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ã‚¤ãƒ¤é§†å‹•ä¸€æœ¬è„šè·³èºãƒ­ãƒœãƒƒãƒˆRAMIELã®å¼·åŒ–å­¦ç¿’ã«åŸºã¥ãé€£ç¶šè·³èºå‹•ä½œã®å®Ÿç¾, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 2F3-05, 2022</li>
<li>çœŸå£ ä½‘, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ°¸æ¾ ç¥å¼¥, å®‰æ– æ™ºç´€, è…äº• æ–‡ä», å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ã‚»ãƒ«ãƒ•ãƒ­ãƒƒã‚¯æ¸›é€Ÿæ©Ÿæ§‹ã¨å†—é•·ã‚»ãƒ³ã‚µã‚’å‚™ãˆãŸã‚µãƒ¼ãƒœãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­è¨ˆé–‹ç™ºã¨å¤šé–¢ç¯€ã‚¢ãƒ¼ãƒ ã«ãŠã‘ã‚‹å¿œç”¨, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 2K1-06, 2022</li>
<li>å‹‡å´ é¢¯å¤ª, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å®¶åº­ç”¨3Dãƒ—ãƒªãƒ³ã‚¿ã§è‡ªä½œå¯èƒ½ãªå¤§å‹ãƒ™ã‚¢ãƒªãƒ³ã‚°ãƒ»ã‚µã‚¤ã‚¯ãƒ­ã‚¤ãƒ‰æ¸›é€Ÿæ©Ÿã‚µãƒ¼ãƒœãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é–‹ç™º, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 2K1-07, 2022</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, çŸ³ç”° å¯›å’Œ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ­ãƒœãƒƒãƒˆã®åå¾© pick-and-place è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›†ã«ã‚ˆã‚‹One-Shot æ•™ç¤ºæŠŠæŒå‹•ä½œã‚¹ã‚­ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ , in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 3F1-03, 2022</li>
<li>éˆ´æœ¨ å¤©é¦¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ·±å±± å’Œæµ©, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç„¡æ¸›é€Ÿãƒ¯ã‚¤ãƒ¤å¹²æ¸‰é§†å‹•ã‚’ç”¨ã„ãŸè»½é‡ãƒ»ãƒãƒƒã‚¯ãƒ‰ãƒ©ã‚¤ãƒãƒ–ãƒ«ãªãƒ­ãƒœãƒƒãƒˆã‚¢ãƒ¼ãƒ ã®é–‹ç™º, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 3E2-03, 2022</li>
<li>çŸ³ç”° å¯›å’Œ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>åˆ†ç¯€åŒ–å‹Behavioral Cloningã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ€§ã«ç€ç›®ã—ãŸãã®æœ‰åŠ¹æ¡ä»¶ã®èª¬æ˜, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 3F2-02, 2022</li>
<li>å‰æ‘ é§¿ä¹‹ä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>3Dãƒ—ãƒªãƒ³ã‚¿ã¨ã‚µãƒ¼ãƒœãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§è£½ä½œå¯èƒ½ãªã‚¢ãƒ¼ãƒ ã§ä½“é‡ã‚’æ”¯æŒã—ç§»å‹•ã™ã‚‹è»Šè¼ªå‹è…±é§†å‹•ãƒ­ãƒœãƒƒãƒˆã®é–‹ç™º, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 4E1-07, 2022</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>Parametric Bias ã‚’ç”¨ã„ãŸé£Ÿæç‰¹å¾´ã‚’è€ƒæ…®å¯èƒ½ãªèª¿ç†ãƒ­ãƒœãƒƒãƒˆã®åŒ…ä¸åˆ‡æ–­æ“ä½œå­¦ç¿’, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 4I1-06, 2022</li>
<li>æ·±å±± å’Œæµ©, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è¡¨çš®ã¨éª¨æ ¼ã‚’ä¸€ä½“ã§3Dãƒ—ãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹è…±é§†å‹•ã‚½ãƒ•ãƒˆãƒ­ãƒœãƒƒãƒˆãƒãƒ³ãƒ‰ã®é–‹ç™º, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 4K2-08, 2022</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>Parametric Bias ã‚’ç”¨ã„ãŸé£Ÿæç‰¹å¾´ã‚’è€ƒæ…®å¯èƒ½ãªèª¿ç†ãƒ­ãƒœãƒƒãƒˆã®åŒ…ä¸åˆ‡æ–­æ“ä½œå­¦ç¿’, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 4I1-06, 2022</li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Taxonomy-aware workspace-based grasp pose generation, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 1J1-04, 2022</li>
<li>ä¸‰æœ¨ ç« å¯›, æ¿æ± æ­£ç¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ææ— å˜‰å…ƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹å‹•ä½œå‘¨æœŸã®æ¢ç´¢ã«åŸºã¥ããƒ­ãƒ¼ãƒ—æŠ•ã’æ“ä½œã®å®Ÿç¾, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 4E1-05, 2022</li>
<li>ææ— å˜‰å…ƒ, ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è…±é§†å‹•ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹ã‚¹ãƒ†ã‚£ãƒƒã‚¯æŠŠæŒçŠ¶æ…‹ã¨å‰›æ€§ã®å¤‰åŒ–ã‚’åˆ©ç”¨ã—ãŸãƒ‰ãƒ©ãƒ ãƒ­ãƒ¼ãƒ«å®Ÿç¾, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 4E1-06, 2022</li>
<li>æ–°åŸ å…‰æ¨¹, å¤§æ—¥æ–¹ æ…¶æ¨¹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç§»å‹•ãƒ­ãƒœãƒƒãƒˆã®ãƒ•ãƒ­ã‚¢é–“ç§»å‹•ã®ãŸã‚ã®ãƒãƒ«ãƒã‚»ãƒ³ã‚µãƒ»IoTã‚¹ã‚¤ãƒƒãƒã«ã‚ˆã‚‹ã‚¨ãƒ¬ãƒ™ãƒ¼ã‚¿çŠ¶æ…‹èªè­˜ãƒ»æ“ä½œã‚·ã‚¹ãƒ†ãƒ , in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 1D1-05, 2022</li>
<li>å°å¡š é™½å¸Œ, è¶™ æ¼ å±…, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å” å®‰å—, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸå‹•çš„éšœå®³ç‰©ç’°å¢ƒä¸‹ã§ã®ãƒãƒ«ãƒãƒ­ãƒ¼ã‚¿é«˜é€Ÿç§»å‹•, in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ22J</b>)</i>, 1G1-02, 2022</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>Parametric Biasã‚’å«ã‚€æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨å¤šæ§˜ãªå®Ÿãƒ­ãƒœãƒƒãƒˆã¸ã®å¿œç”¨, in <i>ç¬¬36å›äººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼š (<b>JSAI22J</b>)</i>, 2M5-OS-19c-01, 2022</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ä¸‰æœ¨ ç« å¯›, åˆ©å…‰ æ³°å¾³, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹ç­‹å¢—åŠ ã‚’è€ƒæ…®å¯èƒ½ãªé©å¿œçš„èº«ä½“å›³å¼å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ , in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2A2-I10, 2022</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ä¸‰æœ¨ ç« å¯›, æ¿æ± æ­£ç¥, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹å¯å¤‰å‰›æ€§ã¨ç´ æå¤‰åŒ–ã‚’è€ƒæ…®ã—ãŸå‹•çš„æŸ”è»Ÿå¸ƒæ“ä½œ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2A1-O05, 2022, <b><font color='red'>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ™ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è³</font></b></li>
<li>åˆ©å…‰ æ³°å¾³, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ä¸‰æœ¨ ç« å¯›, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å¯†ç”»åƒãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ã®æ¨å®šæ³•DIJEã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚µãƒ¼ãƒœåˆ¶å¾¡ã¸ã®å¿œç”¨, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2A2-I09, 2022</li>
<li>è‹¥æ— éš¼å¹³, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>æ“ä½œæ•™ç¤ºã«åŸºã¥ãè£œåŠ©å¿…è¦åº¦ã‚’è€ƒæ…®ã—ãŸé£Ÿå™¨é¡ã®æ¿¯ãã¨æ“¦ã‚Šå‹•ä½œå­¦ç¿’, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2A1-O06, 2022</li>
<li>æ¿æ± æ­£ç¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ä¸‰æœ¨ ç« å¯›, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>åŒè…•ãƒ­ãƒœãƒƒãƒˆã«ã‚ˆã‚‹ãƒ­ãƒ¼ãƒ—å›ã—å‹•ä½œã®ç›®æ¨™æ‰‹å…ˆè»Œé“ç”Ÿæˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2A1-N08, 2022</li>
<li>æ·±å±± å’Œæµ©, é•·è°·å· å³», <b><u>æ²³åŸå¡š å¥äºº</u></b>, å±±å£ ç›´ä¹Ÿ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç¥çµŒå†…åŒ…æŸ”è»Ÿè¡¨çš®ã‚’æœ‰ã—é“å…·ä½¿ç”¨ã‚’è¡Œã†äº”æŒ‡ãƒãƒ³ãƒ‰ã®é–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2A1-K02, 2022</li>
<li>ææ— å˜‰å…ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, æ¥ å±± å¤§æ¨¹, ä¸‰æœ¨ ç« å¯›, æ–°åŸ å…‰æ¨¹, æ¿æ± æ­£ç¥, éˆ´æœ¨ å¤©é¦¬, å°æ¤å°¾ ä¾‘å¤š, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å´é¢åŠ›è¦šã‚’æœ‰ã™ã‚‹ãƒ­ãƒœãƒƒãƒˆãƒ•ãƒƒãƒˆã«ã‚ˆã‚‹æ¤…å­ç€åº§çŠ¶æ…‹ã«ãŠã‘ã‚‹å›è»¢å‹•ä½œåˆ¶å¾¡, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 1P1-T07, 2022</li>
<li>ææ— å˜‰å…ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, æ¥ å±± å¤§æ¨¹, ä¸‰æœ¨ ç« å¯›, æ–°åŸ å…‰æ¨¹, æ¿æ± æ­£ç¥, éˆ´æœ¨ å¤©é¦¬, å°æ¤å°¾ ä¾‘å¤š, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>äººä½“ã®è¶³è£å¤–å‘¨ç¸æ¥è§¦åœ§åˆ†å¸ƒè¨ˆæ¸¬è£…ç½®ã‚’ç”¨ã„ãŸãƒ­ãƒœãƒƒãƒˆè„šã«ã‚ˆã‚‹æ¨¡å€£è¡Œå‹•ã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 1P1-T08, 2022</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>Parametric Biasã‚’ç”¨ã„ãŸèª¿ç†ãƒ­ãƒœãƒƒãƒˆã®åŒ…ä¸åˆ‡æ–­æ“ä½œã«ãŠã‘ã‚‹é£Ÿæç‰¹å¾´å­¦ç¿’, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 1A1-T11, 2022</li>
<li>éˆ´æœ¨ å¤©é¦¬, åˆ©å…‰ æ³°å¾³, æ°¸æ¾ ç¥å¼¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ä¸‰æœ¨ ç« å¯›, ææ— å˜‰å…ƒ, æ¿æ± æ­£ç¥, å°å³¶ é‚¦ç”Ÿ, å£å†… æ´‹å¹³, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ã‚¤ãƒ¤å‹ä¸€æœ¬è„šè·³èºãƒ­ãƒœãƒƒãƒˆRAMIELã®è¨­è¨ˆã¨è·³èºå‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2P1-L10, 2022, <b><font color='red'>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ™ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è³</font></b></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>é€æ¬¡çš„ãªæŠŠæŒçŠ¶æ…‹å¤‰åŒ–ã‚’è€ƒæ…®ã—ãŸé©å¿œçš„é“å…·å…ˆç«¯æ“ä½œå­¦ç¿’, in <i>ç¬¬22å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI21J</b>)</i>, 1D2-04, 2021</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ–°åŸ å…‰æ¨¹, æ²³æ‘ æ´‹ä¸€éƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç¢ºç‡çš„æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹åˆ†æ•£æœ€å°åŒ–ã‚’å«ã‚€ç’°å¢ƒé©å¿œå‹åˆ¶å¾¡ - å°è»Šå‹ãƒ­ãƒœãƒƒãƒˆã¸ã®é©ç”¨ -, in <i>ç¬¬22å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI21J</b>)</i>, 1H3-02, 2021, <b><font color='red'>å„ªç§€è¬›æ¼”è³</font></b></li>
<li>ä¸‰æœ¨ ç« å¯›, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ¿æ± æ­£ç¥, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å°è»Šå‹ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹å¸ƒæ“ä½œã‚’å«ã‚“ã ä¸€é€£ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒƒãƒ†ã‚£ãƒ³ã‚°å‹•ä½œã®å®Ÿç¾, in <i>ç¬¬22å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI21J</b>)</i>, 1D2-03, 2021</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ²³æ‘ æ´‹ä¸€éƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>Parametric Biasã‚’ç”¨ã„ãŸå‹•ä½œã‚¹ã‚¿ã‚¤ãƒ«ã‚’åˆ¶ç´„å¯èƒ½ãªæ¨¡å€£å­¦ç¿’, in <i>ç¬¬39å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ21J</b>)</i>, 1I3-01, 2021</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, è¥¿æµ¦ å­¦, å¤§æ‘ æŸšä»‹, å¤è³€ æ‚ çŸ¢, åˆ©å…‰ æ³°å¾³, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>æ©Ÿèƒ½çš„ãƒ»ç©ºé–“çš„æ¥ç¶šã‚’åˆ©ç”¨ã—ãŸå†—é•·ãªã‚»ãƒ³ã‚µãƒ»ã‚¢ã‚¯ãƒãƒ¥ã‚¨ãƒ¼ã‚¿ã®è‡ªå‹•åˆ†å‰²: ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®ç­‹åˆ†å‰²ã¸ã®é©ç”¨, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 1A1-D06, 2021</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, è¥¿æµ¦ å­¦, å¤è³€ æ‚ çŸ¢, å¤§æ‘ æŸšä»‹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹ç ´æ–­ã‚’è£œå„Ÿã™ã‚‹å†—é•·æ€§ã‚’æœ€å¤§é™æ´»ç”¨ã—ãŸç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®è¨­è¨ˆæœ€é©åŒ–, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 2P3-H04, 2021</li>
<li>å¤è³€ æ‚ çŸ¢, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, è¥¿æµ¦ å­¦, å¤§æ‘ æŸšä»‹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®è‚©è¤‡åˆä½“ã«ãŠã‘ã‚‹å†—é•·æ€§ã‚’æ´»ã‹ã—ãŸå§¿å‹¢ç”Ÿæˆã¨ç‰©ä½“æ“ä½œã‚’ç›®çš„ã¨ã—ãŸè‡ªå·±èº«ä½“åƒã®å®Ÿæ©Ÿå­¦ç¿’, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 1A1-D07, 2021</li>
<li>è‹¥æ— éš¼å¹³, åŒ—å· æ™‹å¾, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å®¤å²¡ è²´ä¹‹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è¦–è¦šæƒ…å ±ã«åŸºã¥ãé£Ÿå™¨é¡ã®æŠŠæŒã®å†—é•·æ€§ã‚’è€ƒæ…®ã—ãŸè‡ªå·±æ•™å¸«ã‚ã‚ŠæŠŠæŒå­¦ç¿’, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 1A1-F09, 2021</li>
<li>å¤§æ‘ æŸšä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ°¸æ¾ ç¥å¼¥, å¤è³€ æ‚ çŸ¢, è¥¿æµ¦ å­¦, åˆ©å…‰ æ³°å¾³, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹äººä½“æ¨¡å€£ä¸¡è€³è´ã‚’ç”¨ã„ãŸè¦–é‡å¤–ç’°å¢ƒèªè­˜è¡Œå‹•, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 2A1-I15, 2021</li>
<li>è¥¿æµ¦ å­¦, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>æ¥è§¦çŠ¶æ…‹ã‚’å«ã‚€èº«ä½“ãƒ¢ãƒ‡ãƒ«ã¨å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹ç’°å¢ƒæ¥è§¦è¡Œå‹•, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 2A1-I16, 2021</li>
<li>åˆ©å…‰ æ³°å¾³, <b><u>æ²³åŸå¡š å¥äºº</u></b>, è¥¿æµ¦ å­¦, å¤è³€ æ‚ çŸ¢, å¤§æ‘ æŸšä»‹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰è…•éƒ¨ã®ç­‹ãƒ»é–¢ç¯€å†—é•·æ€§ã‚’æ´»ç”¨ã—ãŸã‚¿ã‚¹ã‚¯ç©ºé–“ã«ãŠã‘ã‚‹åˆ¶å¾¡, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'21 (<b>ROBOMECH21J</b>)</i>, 2P2-G15, 2021</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å°å· å¾¹, é‹å¶Œ åšå¤ª<br>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®èª¤å·®é€†ä¼æ’­ã«ã‚ˆã‚‹é“å…·å½¢çŠ¶æœ€é©åŒ–, in <i>ç¬¬21å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI20J</b>)</i>, 3D3-05, 2020, <b><font color='red'>å„ªç§€è¬›æ¼”è³</font></b></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¹³å²¡ ç›´æ¨¹, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>æ¸©åº¦ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚’ç”¨ã„ãŸãƒ¢ãƒ¼ã‚¿ã‚³ã‚¢æ¸©åº¦æ¨å®šã¨åˆ¶å¾¡: ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã¸ã®é©ç”¨, in <i>ç¬¬21å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI20J</b>)</i>, 2F3-14, 2020</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤è³€ æ‚ çŸ¢, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>æ‹®æŠ—ç­‹æŠ‘åˆ¶åˆ¶å¾¡ã¨æ‹®æŠ—ç­‹äºˆè¦‹ä¼¸é•·åˆ¶å¾¡ã«ã‚ˆã‚‹å†—é•·ãªç­‹ã‚’æœ‰ã™ã‚‹ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®æœ€å¤§é–¢ç¯€é€Ÿåº¦ã‚’çªç ´ã™ã‚‹å‹•ä½œæˆ¦ç•¥, in <i>ç¬¬21å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI20J</b>)</i>, 2D2-08, 2020</li>
<li>å¤§æ‘ æŸšä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ°¸æ¾ ç¥å¼¥, å¤è³€ æ‚ çŸ¢, è¥¿æµ¦ å­¦, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>äººä½“å¤–è€³æ©Ÿæ§‹ã‚’æ¨¡ã—ãŸãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®ä¸¡è€³é–“ã‚¹ãƒšã‚¯ãƒˆãƒ«å·®å­¦ç¿’ã«åŸºã¥ãç©ºé–“éŸ³æºæ–¹å‘æ¨å®šã‚·ã‚¹ãƒ†ãƒ , in <i>ç¬¬21å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI20J</b>)</i>, 1C3-17, 2020</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>Parametric Biasã‚’å«ã‚€å†å¸°å‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸæŸ”è»Ÿãƒãƒ³ãƒ‰ã®ç‰©ä½“èªè­˜ãƒ»å‹•çš„æ¥è§¦åˆ¶å¾¡/æ¤œçŸ¥/ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³, in <i>ç¬¬38å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ20J</b>)</i>, 2A1-05, 2020</li>
<li>é¬¼å¡š ç››å®‡, è¥¿æµ¦ å­¦, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éƒ½ç¯‰ æ•¬, åˆ©å…‰ æ³°å¾³, å¤§æ‘ æŸšä»‹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>é¢çŠ¶éª¨æ ¼é–“æ§‹é€ ã‚’åˆ©ç”¨ã—åºƒã„å¯å‹•åŸŸã«ãŠã„ã¦ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚¢ãƒ¼ãƒ ã‚’ç¢ºä¿ã—é«˜å‡ºåŠ›ã§ã®ç’°å¢ƒæ¥è§¦å‹•ä½œãŒå¯èƒ½ãªç­‹éª¨æ ¼è„šã®é–‹ç™º, in <i>ç¬¬38å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ20J</b>)</i>, 2G2-08, 2020</li>
<li>åˆ©å…‰ æ³°å¾³, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, è¥¿æµ¦ å­¦, å¤è³€ æ‚ çŸ¢, å¤§æ‘ æŸšä»‹, å†¨ç”° å¹¹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>Motor Directional Tuningç¾è±¡ã«åŸºã¥ãç­‹å¼µåŠ›åˆ¶å¾¡ã«ã‚ˆã‚‹ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®ä¸Šè‚¢å‹•ä½œ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'20 (<b>ROBOMECH20J</b>)</i>, 1P1-G05, 2020</li>
<li>å¤§æ‘ æŸšä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æ°¸æ¾ ç¥å¼¥, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, å¤è³€ æ‚ çŸ¢, è¥¿æµ¦ å­¦, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>å¤–è€³æ§‹é€ ã‚’æœ‰ã—éŸ³éŸ¿å‡¦ç†ã‚’è¡Œã†äººä½“æ¨¡å€£ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®è€³æ©Ÿæ§‹ã®è¨­è¨ˆé–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'20 (<b>ROBOMECH20J</b>)</i>, 1A1-E12, 2020</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>Musculoskeletal AutoEncoder: ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®çŠ¶æ…‹æ¨å®šãƒ»åˆ¶å¾¡ãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ±ä¸€çš„ã«æ‰±ã†ç­‹éª¨æ ¼ã‚»ãƒ³ã‚µé–“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç²å¾—æ‰‹æ³•, in <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 3B3-06, 2019, <b><font color='red'>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šç¬¬35å›ç ”ç©¶å¥¨åŠ±è³</font></b></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å°å· å¾¹, ç”°æ‘ æ·³å¤ªéƒ, é‹å¶Œ åšå¤ª<br>æ·±å±¤å­¦ç¿’ã‚’ç”¨ã„ãŸé–¢ç¯€ãƒˆãƒ«ã‚¯å…¥åŠ›ã«ã‚ˆã‚‹å‹•çš„ãªæŸ”è»Ÿç‰©ä½“æ“ä½œ, in <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 1A2-06, 2019, <b><font color='red'>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šç¬¬35å›ç ”ç©¶å¥¨åŠ±è³</font></b></li>
<li>ä¸­å³¶ æ…ä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æµ…é‡ æ‚ ç´€, å£å†… æ´‹å¹³, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>è‡ªå·±ä¿®å¾©å¼µåŠ›ä¼é”ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‚™ãˆã‚‹è…±é§†å‹•è„šãƒ­ãƒœãƒƒãƒˆã®é–‹ç™º, in <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 1K3-01, 2019</li>
<li>è¥¿æµ¦ å­¦, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹ç’°å¢ƒç‰©ä½“ã«å¿œã˜ãŸé©å¿œçš„å‰›æ€§ãƒ¬ãƒ³ã‚¸é¸æŠã¨ãã®å¯å¤‰å‰›æ€§åˆ¶å¾¡æˆ¦ç•¥ã®ç²å¾—, in <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 1K3-06, 2019</li>
<li>æµ…é‡ æ‚ ç´€, éƒ½ç¯‰ æ•¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é¬¼å¡š ç››å®‡, å¤è³€ æ‚ çŸ¢, å¤§æ‘ æŸšä»‹, æ°¸æ¾ ç¥å¼¥, çœŸå£ ä½‘, è—¤äº• ç¶ºé¦™, æ–°åŸ å…‰æ¨¹, ä¸­å³¶ æ…ä»‹, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>è…±é§†å‹•ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹èªè­˜åˆ¤æ–­æ“ä½œçµ±åˆã«åŸºã¥ãè‡ªå‹•è»Šé‹è»¢ã®å®Ÿè¨¼å®Ÿé¨“, in <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 3L2-06, 2019</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, éƒ½ç¯‰ æ•¬, é¬¼å¡š ç››å®‡, æ°¸æ¾ ç¥å¼¥, æ–°åŸ å…‰æ¨¹, çœŸå£ ä½‘, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>å­¦ç¿’åˆ¶å¾¡æ¨¡ç´¢ã®ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼å‹ç­‹éª¨æ ¼ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®è¨­è¨ˆé–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 2P1-C06, 2019</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, éƒ½ç¯‰ æ•¬, ç‰§é‡ å°†å¾, é¬¼å¡š ç››å®‡, æ–°åŸ å…‰æ¨¹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã—ãŸå‹•çš„è‡ªå·±èº«ä½“åˆ¶å¾¡ã®ç²å¾— - è‡ªå‹•é‹è»¢ã«ãŠã‘ã‚‹ãƒšãƒ€ãƒ«æ“ä½œã¸ã®å¿œç”¨ -, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 1A1-L08, 2019</li>
<li>çœŸå£ ä½‘, ç™½äº• æ‹“ç£¨, æ°¸æ¾ è£•å¼¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, è…äº• æ–‡ä», å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç”¨é€”é©å¿œå‹ãƒ­ãƒœãƒƒãƒˆã®ãŸã‚ã®ã€é§†å‹•æ™‚äºŒæ®µå¯å¤‰æ¸›é€Ÿéé§†å‹•æ™‚ãƒ­ãƒƒã‚¯æ©Ÿæ§‹ã‚’æŒã¤é–¢ç¯€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­è¨ˆé–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 2A2-F08, 2019</li>
<li>éƒ½ç¯‰ æ•¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, çœŸå£ ä½‘, é¬¼å¡š ç››å®‡, ç‰§é‡ å°†å¾, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>å¯å‹•çœ¼çƒã¨è‡ªå·±èº«ä½“ã‚’ç”¨ã„ãŸè·é›¢èªè­˜æ©Ÿèƒ½ã®ç²å¾—, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 1A1-M10, 2019</li>
<li>å¤§æ‘ æŸšä»‹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, é¬¼å¡š ç››å®‡, æ–°åŸ å…‰æ¨¹, éƒ½ç¯‰ æ•¬, å¤è³€ æ‚ çŸ¢, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹æ™‚ç³»åˆ—è´è¦šæƒ…å ±ã‚’ç”¨ã„ãŸæ‰“éŸ³èªè­˜ã«åŸºã¥ãå‹•ä½œç²å¾—, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K03, 2019</li>
<li>å¤è³€ æ‚ çŸ¢, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, é¬¼å¡š ç››å®‡, çœŸå£ ä½‘, éƒ½ç¯‰ æ•¬, å¤§æ‘ æŸšä»‹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯å‹•ä½œã«ãŠã‘ã‚‹ç­‹ã®æ‹®æŠ—é–¢ä¿‚ã¨æ‰‹å…ˆè»Œé“ã®ä¿®æ­£, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K02, 2019</li>
<li>æ–°åŸ å…‰æ¨¹, <b><u>æ²³åŸå¡š å¥äºº</u></b>, æµ…é‡ æ‚ ç´€, ä¸­å³¶ æ…ä»‹, ç‰§é‡ å°†å¾, é¬¼å¡š ç››å®‡, éƒ½ç¯‰ æ•¬, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ã‚³ã‚¢ãƒ»ã‚·ã‚§ãƒ«æ§‹é€ ã‚’æœ‰ã™ã‚‹6è»¸åŠ›è¨ˆæ¸¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã¤ã¾å…ˆãƒ»è¸µã«æŒã¤è¶³éƒ¨ãƒ¦ãƒ‹ãƒƒãƒˆã‚’ç”¨ã„ãŸç­‰èº«å¤§ç­‹éª¨æ ¼è…±é§†å‹•ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹ãƒšãƒ€ãƒ«è¸ã¿ãƒ»å¾©å¸°å‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K01, 2019</li>
<li>é¬¼å¡š ç››å®‡, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, æ–°åŸ å…‰æ¨¹, éƒ½ç¯‰ æ•¬, ä¸­å³¶ æ…ä»‹, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹é¢çŠ¶ç‰½å¼•æ§‹é€ ã‚’æœ‰ã™ã‚‹é–¢ç¯€ã®é–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'19 (<b>ROBOMECH19J</b>)</i>, 1A1-J02, 2019</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, éƒ½ç¯‰ æ•¬, ç‰§é‡ å°†å¾, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼æ§‹é€ ã«ãŠã‘ã‚‹é•·æœŸçš„è‡ªå·±èº«ä½“åƒç²å¾—ã¨å¯å¤‰å‰›æ€§åˆ¶å¾¡ã®å®Ÿç¾, in <i>ç¬¬36å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ18J</b>)</i>, 1J2-02, 2018</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, çœŸå£ ä½‘, ç‰§é‡ å°†å¾, éƒ½ç¯‰ æ•¬, æ°¸æ¾ ç¥å¼¥, æµ…é‡ æ‚ ç´€, ç™½äº• æ‹“ç£¨, è…äº• æ–‡ä», å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç’°å¢ƒæ¥è§¦ã‚’ä¼´ã†å­¦ç¿’å‹åˆ¶å¾¡ç ”ç©¶ã®ãŸã‚ã®ç­‹éª¨æ ¼å‹å€’ç«‹äºŒè¼ªãƒ­ãƒœãƒƒãƒˆã®é–‹ç™º, in <i>ç¬¬36å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ18J</b>)</i>, 1P2-02, 2018</li>
<li>éƒ½ç¯‰ æ•¬, <b><u>æ²³åŸå¡š å¥äºº</u></b>, é¬¼å¡š ç››å®‡, çœŸå£ ä½‘, ç‰§é‡ å°†å¾, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ã‚ˆã‚‹è‡ªå‹•è»Šé‹è»¢å‹•ä½œã®å®Ÿç¾ã«å‘ã‘ãŸãƒšãƒ€ãƒ«æ“ä½œæˆ¦ç•¥, in <i>ç¬¬36å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ18J</b>)</i>, 2P1-05, 2018</li>
<li>é¬¼å¡š ç››å®‡, çœŸå£ ä½‘, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹è„šå…¨ä½“ã®ç­‹ã«åŸºã¥ãç­‹å¼µåŠ› ZMP ã‚’ç”¨ã„ãŸå¹³è¡¡å‹•ä½œ, in <i>ç¬¬36å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ18J</b>)</i>, 1J2-05, 2018</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, é™³ ç›¸ç¾½, è—¤äº• ç¶ºé¦™, å·æ‘ å°†çŸ¢, çœŸå£ ä½‘, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>æ“¬ä¼¼çƒé–¢ç¯€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ˆã‚Šå†—é•·ãªéç·šå½¢å¼¾æ€§è¦ç´ ã‚’åˆ¶å¾¡å¯èƒ½ãªç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®ä¸Šè‚¢è¨­è¨ˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G09, 2018</li>
<li>ç‰§é‡ å°†å¾, <b><u>æ²³åŸå¡š å¥äºº</u></b>, è—¤äº• ç¶ºé¦™, å·æ‘ å°†çŸ¢, çœŸå£ ä½‘, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>çµ„ã¿åˆã‚ã›åˆ‡å‰Šã°ã­ã«ã‚ˆã‚‹åºƒå¯å‹•åŸŸé–¢ç¯€æ¯æŒ‡é–¢ç¯€ã¨å¯å¤‰å‰›æ€§æŒ‡é–¢ç¯€ã‚’ã‚‚ã¤äººä½“æ¨¡å€£å‹äº”æŒ‡ãƒãƒ³ãƒ‰ã®é–‹ç™º, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'18 (<b>ROBOMECH18J</b>)</i>, 1P1-H16, 2018</li>
<li>çœŸå£ ä½‘, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, å·æ‘ å°†çŸ¢, è—¤äº• ç¶ºé¦™, é¬¼å¡š ç››å®‡, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹å¯å‹•çœ¼çƒã®é–‹ç™ºã¨è»Šä¸¡è¦‹å›ã—ç™ºé€²å‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G11, 2018</li>
<li>æµ…é‡ æ‚ ç´€, å·æ‘ å°†çŸ¢, <b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, è—¤äº• ç¶ºé¦™, çœŸå£ ä½‘, é¬¼å¡š ç››å®‡, å²¡ç”° æ…§, å·å´ å®æ²», ç¨²è‘‰ é›…å¹¸<br>äººä½“æ¨¡å€£ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹ç­‹å¼µåŠ›ã‚’ç”¨ã„ãŸé–¢ç¯€ç©ºé–“ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ã«ã‚ˆã‚‹è»Šä¸¡ãƒšãƒ€ãƒ«æ“ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G07, 2018</li>
<li>è—¤äº•ç¶ºé¦™, ä¸­å³¶æ…ä»‹, å·æ‘å°†çŸ¢, <b><u>æ²³åŸå¡šå¥äºº</u></b>, ç‰§é‡å°†å¾, æµ…é‡æ‚ ç´€, å²¡ç”°æ…§, ç¨²è‘‰é›…å¹¸<br>äººä½“ã®é–¢ç¯€åŒ…æ§‹é€ ã«ç¤ºå”†ã‚’å¾—ãŸæŸ”è»Ÿã§ä¼¸ç¸®å¤‰å½¢å¯èƒ½ãªè†œæ§‹é€ ã‚’å‚™ãˆãŸé–‹æ”¾å‹çƒé–¢ç¯€ã®é–‹ç™º, in <i>ç¬¬18å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI17J</b>)</i>, 3B4-02, 2017</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, å·æ‘ å°†çŸ¢, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã«ãŠã‘ã‚‹è¦–è¦šã‚’åˆ©ç”¨ã—ãŸé–¢ç¯€-ç­‹ç©ºé–“ãƒãƒƒãƒ—ã®é€æ¬¡çš„å†å­¦ç¿’, in <i>ç¬¬35å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ17J</b>)</i>, 2L1-01, 2017</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, ç‰§é‡ å°†å¾, å·æ‘ å°†çŸ¢, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>éª¨æ§‹é€ ä¸€ä½“å°å‹ç­‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ˆã‚Šæ§‹æˆã•ã‚ŒãŸæ©ˆéª¨å°ºéª¨æ§‹é€ ã‚’æœ‰ã™ã‚‹å‰è…•éƒ¨ã®è¨­è¨ˆ, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'17 (<b>ROBOMECH17J</b>)</i>, 1A1-O11, 2017</li>
<li>ç‰§é‡ å°†å¾, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å·æ‘ å°†çŸ¢, æµ…é‡ æ‚ ç´€, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®ãŸã‚ã®åˆ‡å‰Šã°ã­ã«ã‚ˆã‚‹æŸ”è»Ÿé–¢ç¯€ã‚’å‚™ãˆãŸäº”æŒ‡ãƒãƒ³ãƒ‰ã®é–‹ç™ºã¨è‡ªå·±èº«ä½“è² è·ä¿æŒå‹•ä½œã®å®Ÿç¾, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'17 (<b>ROBOMECH17J</b>)</i>, 2P1-B08, 2017, <b><font color='red'>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šè‹¥æ‰‹å„ªç§€è¬›æ¼”ãƒ•ã‚§ãƒ­ãƒ¼è³</font></b></li>
</ol>
<h3> Invited Talks, Books, etc.</h3>
<ol>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ­ãƒœãƒƒãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ç ”ç©¶ã®ç¾çŠ¶ã¨ä»Šå¾Œ, æ‹›å¾…è¬›æ¼”, in <i>æƒ…å ±å‡¦ç†å­¦ä¼šé€£ç¶šã‚»ãƒŸãƒŠãƒ¼</i>, 2025.9.25<br> <a href=https://www.ipsj.or.jp/event/seminar/2025/program06.html target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ­ãƒœãƒƒãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ç ”ç©¶ã®æœ€å‰ç·š, æ‹›å¾…è¬›æ¼”, in <i>MIRU2025ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«</i>, 2025.7.29<br> <a href=https://cvim.ipsj.or.jp/MIRU2025/tutorial.html target='_blank'>[Website]</a> <a href=https://speakerdeck.com/haraduka/miru2025-tiyutoriarujiang-yan-robotutoji-pan-moderunozui-qian-xian target='_blank'>[Slide]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å››è„šãƒ­ãƒœãƒƒãƒˆMEVIUSã¨ãã®ç™ºå±•, æ‹›å¾…è¬›æ¼”, in <i>ROBOMECH2025ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ— æ©Ÿæ¢°å­¦ç¿’ã¨äººå‹ãƒ»å¤šè„šãƒ»å¤šé–¢ç¯€ãƒ­ãƒœãƒƒãƒˆï½ç ”ç©¶ï¼†ãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰æœ€å‰ç·šï½</i>, 2025.6.4<br> <a href=https://rt-net.jp/robomech2025ws/ target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã®èåˆ, æ‹›å¾…è¬›æ¼”, in <i>æ±åŒ—å¤§å­¦ ã‚¿ãƒ•ï½¥ã‚µã‚¤ãƒãƒ¼ãƒ•ã‚£ã‚¸ã‚«ãƒ«AIç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ 2025</i>, 2025.6.3<br> <a href=http://tcpai.tohoku.ac.jp/sympo2025/ target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ•ã‚£ã‚¸ã‚«ãƒ«AIã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶é–‹ç™ºï½èº«ä½“æ€§ã«åŸºã¥ãçŸ¥èƒ½ã®ç ”ç©¶ï½, ãƒ‘ãƒãƒªã‚¹ãƒˆ, in <i>JSAI2025ä¼ç”»ã‚»ãƒƒã‚·ãƒ§ãƒ³</i>, 2025.5.28<br> <a href=https://www.jst.go.jp/crds/sympo/JSAI2025_physicalai/index.html target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ç”ŸæˆAIã®ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å¿œç”¨, ã‚»ãƒŸãƒŠãƒ¼è¬›å¸«, in <i>IEICEå…ˆç«¯ã‚»ãƒŸãƒŠãƒ¼</i>, 2025.5.1<br> <a href=https://www.ieice.org/jpn_r/activities/advanced_seminar.html target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids for Human-like Embodied Intelligence, Short Talk and Panelist, in <i>2025 International Conference on Embodied Intelligence (EI)</i>, 2025.4.2<br> <a href=https://embodied-intelligence.org/embodied-intelligence-conference25/ target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ç§‘å­¦æŠ€è¡“æœªæ¥æˆ¦ç•¥ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—å ±å‘Šæ›¸ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«AIã‚·ã‚¹ãƒ†ãƒ ã€, ãƒ‘ãƒãƒªã‚¹ãƒˆ, in <i>JST CRDS ç ”ç©¶é–‹ç™ºæˆ¦ç•¥ã‚»ãƒ³ã‚¿ãƒ¼</i>, 2025.3.28<br> <a href=https://www.jst.go.jp/crds/report/CRDS-FY2024-WR-07.html target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨, æ‹›å¾…è¬›æ¼”, in <i>ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢ç†è§£ç ”ç©¶ä¼š (PRMU)</i>, 2025.3.18<br> <a href=https://ken.ieice.org/ken/paper/20250318ac9c/ target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã¨åŸºç›¤ãƒ¢ãƒ‡ãƒ«, è©±é¡Œæä¾›, in <i>LLM-jp å®Ÿç’°å¢ƒã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³WG</i>, 2025.2.14</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ­ãƒœãƒƒãƒˆã«ãŠã‘ã‚‹Data-centric AI, in <i>ç¬¬13å› Data-Centric AIå‹‰å¼·ä¼š -Data-centric AIå…¥é–€ è‘—è€…LTå¤§ä¼š-</i>, 2025.2.12<br> <a href=https://dcai-jp.connpass.com/event/342802/ target='_blank'>[Website]</a></li>
<li>ç‰‡å²¡ è£•é›„ (ç›£ä¿®), é½‹è—¤é‚¦ç« , æ¸…é‡èˆœ, å°æ—æ»‰æ²³, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å®®æ¾¤ ä¸€ä¹‹, éˆ´æœ¨ é”å“‰<br>Data-centric AIå…¥é–€, in <i>æŠ€è¡“è©•è«–ç¤¾</i>, 2025.01.08<br> <a href=https://gihyo.jp/book/2025/978-4-297-14663-4 target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>The Point of Tendon-driven Musculoskeletal Humanoids, Invited Talk, in <i>VANJ (Vietnamese Academic Network in Japan) Conference</i>, 2024.12.07<br> <a href=https://conf.vanj.jp/2024/speakers/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>History and Future of Tendon-driven Musculoskeletal Humanoids, in <i>TAI AHR #03 - AI in Hardware and Robotics</i>, 2024.12.06<br> <a href=https://lu.ma/ppgh4amz target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>History and Future of Tendon-driven Musculoskeletal Humanoids, Plenary Talk, in <i>2024 IEEE International Conference on Humanoid Robots (Humanoids)</i>, 2024.11.23<br> <a href=https://2024.ieee-humanoids.org/plenaries/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Building Intelligent Robots: From Musculoskeletal Humanoids to Foundation Models, in <i>Seminar at KIT, Karlsruhe</i>, 2024.11.20</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>IROS/ICRAã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—é–‹å‚¬ã®çµŒé¨“ã¨å±•æœ› ~ Cooking Robotics Workshop@ICRA 2024ã‚’ä¸»å‚¬ã—ã¦ ~, in <i>ç¬¬42å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š å­¦è¡“ãƒ©ãƒ³ãƒãƒ§ãƒ³ã‚»ãƒŸãƒŠãƒ¼</i>, 2024.9.5<br> <a href=https://speakerdeck.com/haraduka/rsj2024xue-shu-rantiyonsemina-ruo-shou-zhong-jian-niyoruguo-ji-hua-ridasitupunixiang-kete-zi-liao-he-yuan-zhong target='_blank'>[Slide]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at DLR, Oberpfaffenhofen</i>, 2024.7.31</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at TUM, Munich</i>, 2024.7.30</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at Max Planck Institute, Tubingen</i>, 2024.7.29</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at EPFL, Lausanne</i>, 2024.7.5</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>CRL Seminar at ETH Zurich</i>, 2024.6.28</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Postdoc Seminar at IIT, Genova</i>, 2024.6.20</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Robotic Imitation Learning for Biomedical Applications, in <i>Symposium on Robotics in Biomedical Applications</i>, 2024.6.17<br> <a href=https://sites.google.com/view/srbm/home target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>LLMãƒ»VLMã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ä¾‹ã¨ãã®åˆ†é¡, è¬›å¸«, in <i>ç¬¬152å›ãƒ­ãƒœãƒƒãƒˆå·¥å­¦ã‚»ãƒŸãƒŠãƒ¼ã€Œãƒ­ãƒœãƒƒãƒˆã®ãŸã‚ã®LLMãƒ»VLM åˆ©æ´»ç”¨ã€</i>, 2024.5.23<br> <a href=https://www.rsj.or.jp/event/seminar/news/2024/s152.html target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ­ãƒœãƒƒãƒˆã®å‹•ä½œè¨ˆç”»ã¨åˆ¶å¾¡, æ‹›å¾…è¬›æ¼”, in <i>ROS Japan UG #55 Plannerç‰¹é›†ï¼</i>, 2024.5.21<br> <a href=https://rosjp.connpass.com/event/313794/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>What is Necessary to Cook Curry with a Robot?, Workshop on "Cooking Robotics: Perception and motion planning", in <i>2024 IEEE International Conference on Robotics and Automation (ICRA)</i>, 2024.5.17<br> <a href=https://sites.google.com/view/icra2024cookingrobotics/home target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Tendon-driven Musculoskeletal Humanoids and Beyond, Workshop on "From Layers to Limbs! Exploring the Interface of 3D Printing and Bio-Inspired Musculoskeletal Robotics", in <i>2024 IEEE International Conference on Soft Robotics (RoboSoft)</i>, 2024.4.14<br> <a href=https://printed-musculoskeletal-robots.ethz.ch/ target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ãƒ­ãƒœãƒƒãƒˆç ”ç©¶ã«ãŠã‘ã‚‹LLMã®å®Ÿä¸–ç•Œå¿œç”¨, æ‹›å¾…è¬›æ¼”, in <i>NLP2024ä½µè¨­ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å®Ÿä¸–ç•Œå¿œç”¨ã€</i>, 2024.3.15<br> <a href=https://sites.google.com/grp.riken.jp/langrobonlp2024 target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ç­‹éª¨æ ¼ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã¨èº«ä½“å›³å¼å­¦ç¿’, æ‹›å¾…è¬›æ¼”, in <i>ç¬¬19å›èº«ä½“æ€§èªçŸ¥ç§‘å­¦ã¨å®Ÿä¸–ç•Œå¿œç”¨ã«é–¢ã™ã‚‹è‹¥æ‰‹ç ”ç©¶ä¼š(ECSRA)</i>, 2023.10.29<br> <a href=https://sites.google.com/site/ecsrawebsite/%E8%BA%AB%E4%BD%93%E6%80%A7%E8%AA%8D%E7%9F%A5%E7%A7%91%E5%AD%A6%E3%81%A8%E5%AE%9F%E4%B8%96%E7%95%8C%E5%BF%9C%E7%94%A8%E3%81%AB%E9%96%A2%E3%81%99%E3%82%8B%E8%8B%A5%E6%89%8B%E7%A0%94%E7%A9%B6%E4%BC%9A-ecsra target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ä¾‹, æ‹›å¾…è¬›æ¼”, in <i>ç¬¬5å›LLMå‹‰å¼·ä¼š(LLM-jp)</i>, 2023.10.18<br> <a href=https://llm-jp.nii.ac.jp/llm/2023/10/18/meeting-5.html target='_blank'>[Website]</a></li>
<li><b><u>K. Kawaharazuka</u></b><br>Learning-based manipulation and grasping with flexible arms and hands, Workshop on "Learning Meets Model-based Methods for Manipulation and Grasping", in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2023.10.5<br> <a href=https://sites.google.com/view/learning-meets-models-iros2023/speakers?authuser=0 target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆã‚¿ã‚¹ã‚¯å¿œç”¨, æ‹›å¾…ã‚»ãƒƒã‚·ãƒ§ãƒ³, in <i>NLPè‹¥æ‰‹ã®ä¼š ç¬¬18å›ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ  (YANS2023)</i>, 2023.8.31<br> <a href=https://yans.anlp.jp/entry/yans2023invitesession target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>è„±åŠ›å¯èƒ½ãªãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã®èº«ä½“ã¨åˆ¶å¾¡, ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š2023ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ã€Œ"ã„ã„ã‹ã’ã‚“"ã‚’ç§‘å­¦ã—ã¦æœªæ¥ã‚’å‰µã‚‹ã‚½ãƒ•ãƒˆãƒ­ãƒœãƒƒãƒˆå­¦4ã€, in <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š</i>, 2023.6.28<br> <a href=https://softrobot.jp/events/2023/06161205082540/ target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>èº«ä½“å›³å¼ã®è‡ªå¾‹ç²å¾—æ©Ÿèƒ½ã‚’æœ‰ã™ã‚‹çŸ¥èƒ½ãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã¨ã‚µã‚¤ã‚¨ãƒ³ã‚¹é–‹æ‹“, è‹¥æ‰‹ç ”ç©¶è€…ãŒæã2050å¹´ã®AIãƒ­ãƒœãƒƒãƒˆãƒ“ã‚¸ãƒ§ãƒ³ (ã‚ªãƒ¼ãƒ—ãƒ³ãƒ•ã‚©ãƒ¼ãƒ©ãƒ : ãƒ ãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå‹ç ”ç©¶ã§ç›®æŒ‡ã™AIãƒ­ãƒœãƒƒãƒˆ), in <i>ç¬¬40å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š</i>, 2022.9.9<br> <a href=https://ac.rsj-web.org/2022/openforum.html#OF5 target='_blank'>[Website]</a></li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>èº«ä½“å›³å¼ã®é€æ¬¡å­¦ç¿’æ©Ÿèƒ½ã‚’æœ‰ã™ã‚‹çŸ¥èƒ½ãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶, in <i>åšå£«è«–æ–‡</i>, <b><font color='red'>ç ”ç©¶ç§‘é•·è³</font></b>, 2022.3.24</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>æ·±å±¤äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹ãƒ­ãƒœãƒƒãƒˆã®æ™‚é–“çš„ãƒ»ç©ºé–“çš„æŸ”è»Ÿæ€§æ”»ç•¥, ã‚­ãƒ¼ãƒãƒ¼ãƒˆè¬›æ¼” (OS: ç¢ºç‡ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿å·¥å­¦ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ï½èªè­˜ãƒ»è¡Œå‹•å­¦ç¿’ãƒ»è¨˜å·å‰µç™ºï½), in <i>ç¬¬39å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š</i>, 2021.9.6</li>
</ol>
        <!-- publication_replace_by_python -->

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Awards (Publication) </h2>
        </div>

<ol>
<li>S. Kim, N. Kanazawa, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Best Student Paper Finalist, <i>2025 IEEE/SICE International Symposium on System Integration (<b>SII2025</b>)</i>, 2025.1.24</li>
<li>äº•ä¸Š ä¿¡å¤šéƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, éˆ´æœ¨ å¤©é¦¬, å‹‡å´ é¢¯å¤ª, ææ— å˜‰å…ƒ, ä½åŸ ä¾‘å¤ª, å²¡ç”° æ…§<br>å„ªç§€è¬›æ¼”è³, <i>ç¬¬25å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI24J</b>)</i>, 2024.12.20</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, é‡‘æ²¢ ç›´æ™ƒ, å¡šæœ¬ ç›´äºº, å²¡ç”° æ…§<br>å„ªç§€è¬›æ¼”è³, <i>ç¬¬25å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI24J</b>)</i>, 2024.12.20</li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, Y. Ribayashi, Y. Sahara, K. Okada<br>Mike Stillman Award, <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, 2024.11.24</li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada<br>Excellent Practice Award, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, (<b>Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects</b>), 2024.10.14</li>
<li>Open X-Embodiment Collaboration<br>Finalists of Best Paper Award in Robot Manipulation, <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, 2024.5.16</li>
<li>Open X-Embodiment Collaboration<br>Best Conference Paper Award, <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, 2024.5.16</li>
<li>é‡‘æ²¢ ç›´æ™ƒ, <b><u>æ²³åŸå¡š å¥äºº</u></b>, å¤§æ—¥æ–¹ æ…¶æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å„ªç§€è¬›æ¼”è³, <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 2023.12.16</li>
<li>ä¸‰æœ¨ ç« å¯›, ä½åŸ ä¾‘å¤ª, æ·±å±± å’Œæµ©, ææ— å˜‰å…ƒ, é•·è°·å· å³», <b><u>æ²³åŸå¡š å¥äºº</u></b>, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å„ªç§€è¬›æ¼”è³, <i>ç¬¬24å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI23J</b>)</i>, 2023.12.15</li>
<li>ä¸‰æœ¨ ç« å¯›, æ¿æ± æ­£ç¥, æ°¸æ¾ ç¥å¼¥, <b><u>æ²³åŸå¡š å¥äºº</u></b>, åˆ©å…‰ æ³°å¾³, å¹³å²¡ ç›´æ¨¹, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>ç¬¬3å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢å„ªç§€ç ”ç©¶ãƒ»æŠ€è¡“è³, <i>ç¬¬28å›ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚·ãƒ³ãƒã‚¸ã‚¢ (<b>ROBOSYM23J</b>)</i>, 2023.9.13</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ™ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è³, <i>æ—¥æœ¬æ©Ÿæ¢°å­¦ä¼šãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãƒ»ãƒ¡ã‚«ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹è¬›æ¼”ä¼š'22 (<b>ROBOMECH22J</b>)</i>, 2023.6.29</li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, T. Suzuki, Y. Ribayashi, Y. Toshimitsu, Y. Nagamatsu, K. Okada, M. Inaba<br>Best Interactive Paper Award Finalist, <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, 2022.11.30</li>
<li><b><u>K. Kawaharazuka</u></b><br>SICE International Young Authors Award (SIYA-IROS2022), <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, 2022.10.26</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>ç ”ç©¶ç§‘é•·è³, <i>åšå£«è«–æ–‡</i>, 2022.3.24</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, æ–°åŸ å…‰æ¨¹, æ²³æ‘ æ´‹ä¸€éƒ, å²¡ç”° æ…§, ç¨²è‘‰ é›…å¹¸<br>å„ªç§€è¬›æ¼”è³, <i>ç¬¬22å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI21J</b>)</i>, 2021.12.24</li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Finalists of Mike Stilman Paper Award, <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, 2021.7.21</li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Best Oral Paper Award, <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, 2021.7.21</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b>, å°å· å¾¹, é‹å¶Œ åšå¤ª<br>å„ªç§€è¬›æ¼”è³, <i>ç¬¬21å›SICEã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨é–€è¬›æ¼”ä¼š (<b>SI20J</b>)</i>, 2020.12.25</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šç¬¬35å›ç ”ç©¶å¥¨åŠ±è³, <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 2020.10.9</li>
<li><b><u>æ²³åŸå¡š å¥äºº</u></b><br>æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šç¬¬35å›ç ”ç©¶å¥¨åŠ±è³, <i>ç¬¬37å›æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼šå­¦è¡“è¬›æ¼”ä¼š (<b>RSJ19J</b>)</i>, 2020.10.9</li>
<li><b><u>K. Kawaharazuka</u></b><br>Company of Biologists Early Career Researcher Grant (500 GBP), <i>9th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2019</b>)</i>, 2019.8.20</li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, A. Fujii, T. Makabe, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>IROS ICROS Best Application Paper Award 2018 Finalists, <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, 2018.10.2</li>
<li><b><u>K. Kawaharazuka</u></b><br>IEEE RAS Japan Joint Chapter Young Award (2017), <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, 2017.9.24</li>
<li>Y. Asano, T. Kozuki, S. Ookubo, M. Kawamura, S. Nakashima, T. Katayama, Y. Iori, H. Toshinori, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Kakiuchi, K. Okada, M. Inaba<br>Best Interactive Paper Award Finalist, <i>2016 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2016</b>)</i>, 2016.11.17</li>
</ol>
          <!-- award_replace_by_python -->

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Awards and Experiences (Others) </h2>
        </div>
        <ol>
          <li>First Place (GPSR task in DSPL), RoboCup@Home JapanOpen2022, 2023.3.6 - 2023.3.9</li>
          <li>First Prize (state-based category), <a href="https://uzh-rpg.github.io/icra2022-dodgedrone/" target='_blank'>ICRA 2022 DodgeDrone Challenge</a>, 2022.5.26</li>
          <li>Part-time Enginner at <a href="https://www.preferred-networks.jp/en/" target='_blank'>Preferred Networks</a>, 2018.10 - 2020.3</li>
          <li>Internship at <a href="https://www.preferred-networks.jp/en/" target='_blank'>Preferred Networks</a>, 2018.8 - 2018.9</li>
          <li>Oral Presentation Award (Second Prize), <a href="http://deeplearning.jp/deeplearningday2018/" target='_blank'>Deep Learning Day 2018</a>, 2018.1.20</li>
          <li>Code Thanks Festival 2017, 2017.12.2</li>
          <li>Jaxa Award (Second Prize), <a href="http://moonhack.jp.klab.com/" target='_blank'>Moon Hack Hackathon 2017</a>, 2017.11.11 - 2017.11.12</li>
          <li>Final Round of Code Festival 2016, 2016.11.26 - 2016.11.27</li>
          <li>2nd RUNNER-UP and ABU ROBOCON AWARD, <a href="http://aburobocon.net/" target='_blank'>ABU Robot Contest 2016</a>, Clean Energy Recharging the World, 2016.8.21</li>
          <li>First Prize <a href="https://official-robocon.com/history/gakusei/about/history/twentyfive/" target='_blank'>NHK Student Robot Contest 2016</a>, Clean Energy Recharging the World, 2016.7.10</li>
          <li>Outstanding Performance Award, Internship at <a href="http://www.worksap.com/" target='_blank'>Works Applications Co., Ltd.</a>, 2016.3.4 - 2016.3.31</li>
          <li>Internship at <a href="http://www.futurestandard.co.jp/about/" target='_blank'>Future Standard Co., Ltd.</a>, 2016.1 - 2016.4</li>
          <li>Third Prize (Senior Division), <a href="http://www.lsse.kyutech.ac.jp/~sociorobo/ja/tomato-robot2015" target='_blank'>Tomato Robot Challenge</a>, 2015.12.18 - 2015.12.20</li>
          <li>Final Round of CODE RUNNER 2015, 2015.12.12</li>
          <li>Final Round of Code Festival 2015, 2015.11.14 - 2015.11.15</li>
          <li>Internship at <a href="https://www.hioki.com/en/" target='_blank'>HIOKI E.E. CORPORATION</a>, 2015.8.17 - 2015.8.28</li>
          <li>Technical Award, <a href="https://official-robocon.com/history/gakusei/about/history/twenty-fourth/" target='_blank'>NHK Student Robot Contest 2015</a>, ROBOMINTON:BADMINTON ROBO GAME (Pit Member), 2015.6.7</li>
          <li>Dowango Award (11/372), <a href="https://icpc.iisf.or.jp/2015-tsukuba/domestic/?lang=en" target='_blank'>ICPC Domestic Preliminary Contest</a>, 2015.6.26</li>
          <li>Final Round of <a href="http://www.ipsj.or.jp/event/samuraicoding/2014-15/index.html" target='_blank'>SamurAI Coding 2014-2015</a>, 2015.3.18</li>
          <li>Final Round of CODE RUNNER 2014, 30, November, 2014</li>
          <li>Technical Award, <a href="http://f3rcontest.web.fc2.com/index.html" target='_blank'>Freshman's Robot Contest 2013 (F^3RC)</a>, 2013.9.29</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Grants-in-Aid and Scholarship </h2>
        </div>
        <ol>
          <li> <b>CRONOS (åˆ†æ‹…)</b>, ç§‘å­¦æŠ€è¡“æŒ¯èˆˆæ©Ÿæ§‹ (JST), 2024.10 - 2030.3 </li>
          <li> <b>å‰µç™ºçš„ç ”ç©¶æ”¯æ´äº‹æ¥­ (ä»£è¡¨)</b>, ç§‘å­¦æŠ€è¡“æŒ¯èˆˆæ©Ÿæ§‹ (JST), 2024.10 - 2032.3 </li>
          <li> <b>åŸºç›¤ç ”ç©¶B (ä»£è¡¨)</b>, æ—¥æœ¬å­¦è¡“æŒ¯èˆˆä¼š (JSPS), 2023.4 - 2027.3 </li>
          <li> <b>æŒ‘æˆ¦çš„èŒèŠ½ (ä»£è¡¨)</b>, æ—¥æœ¬å­¦è¡“æŒ¯èˆˆä¼š (JSPS), 2023.4 - 2026.3 </li>
          <li> <b>ACT-XåŠ é€Ÿãƒ•ã‚§ãƒ¼ã‚º (ä»£è¡¨)</b>, ç§‘å­¦æŠ€è¡“æŒ¯èˆˆæ©Ÿæ§‹ (JST), 2023.4 - 2024.3 </li>
          <li> <b>ç ”ç©¶æ´»å‹•ã‚¹ã‚¿ãƒ¼ãƒˆæ”¯æ´ (ä»£è¡¨)</b>, æ—¥æœ¬å­¦è¡“æŒ¯èˆˆä¼š (JSPS), 2022.4 - 2024.3 </li>
          <li> <b>ACT-X (ä»£è¡¨)</b>, ç§‘å­¦æŠ€è¡“æŒ¯èˆˆæ©Ÿæ§‹ (JST), 2020.12 - 2023.3 </li>
          <li> <b>ç‰¹åˆ¥ç ”ç©¶å“¡ (DC1)</b>, æ—¥æœ¬å­¦è¡“æŒ¯èˆˆä¼š (JSPS), 2019.4 â€“ 2022.3 </li>
          <li> <b>ãƒˆãƒ¨ã‚¿ãƒ»ãƒ‰ãƒ¯ãƒ³ã‚´é«˜åº¦äººå·¥çŸ¥èƒ½äººæå¥¨å­¦é‡‘</b>, 2021.4 - 2022.3 </li>
          <li> <b>ãƒˆãƒ¨ã‚¿ãƒ»ãƒ‰ãƒ¯ãƒ³ã‚´é«˜åº¦äººå·¥çŸ¥èƒ½äººæå¥¨å­¦é‡‘</b>, 2020.4 - 2021.3 </li>
          <li> <b>è‹¥æ‰‹ç ”ç©¶è€…æµ·å¤–æŒ‘æˆ¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ </b>, æ—¥æœ¬å­¦è¡“æŒ¯èˆˆä¼š (JSPS), 2020.4 â€“ 2020.8 (Covid-19ã«ã‚ˆã‚Šè¾é€€) </li>
          <li> <b>ãƒˆãƒ¨ã‚¿ãƒ»ãƒ‰ãƒ¯ãƒ³ã‚´é«˜åº¦äººå·¥çŸ¥èƒ½äººæå¥¨å­¦é‡‘</b>, 2018.4 - 2019.3 </li>
          <li> <b>ãƒˆãƒ¨ã‚¿ãƒ»ãƒ‰ãƒ¯ãƒ³ã‚´é«˜åº¦äººå·¥çŸ¥èƒ½äººæå¥¨å­¦é‡‘</b>, 2017.4 - 2018.3 </li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Media </h2>
        </div>
        <ol>
          <li><a href="https://karapaia.com/archives/525837.html" target='_blank'>ã“ã„ã¤ã€é€Ÿã„ãï¼æ±äº¬å¤§å­¦ãŒé–‹ç™ºã—ãŸå£ç™»ã‚Šãƒ­ãƒœãƒƒãƒˆãŒä¸–ç•Œæœ€é€Ÿè¨˜éŒ²ã‚’æ›´æ–°ï¼</a>, ã‚«ãƒ©ãƒ‘ã‚¤ã‚¢, 2025.07.18</li>
          <li><a href="https://newatlas.com/robotics/jsk-kleiyn-quadruped-waist-climb/" target='_blank'>Robodog chimneys better than you, ready to send a V5</a>, New Atlas, 2025.07.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-reachy-mini" target='_blank'>Reachy Mini Brings the Cute: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.07.11</li>
          <li><a href="https://interestingengineering.com/innovation/kleiyn-chimney-climbing-robot-dog" target='_blank'>Watch worldâ€™s fastest chimney-climbing robot dog scale 50 times faster than rivals</a>, Interesting Engineering, 2025.07.14</li>
          <li><a href="https://newswitch.jp/p/46244" target='_blank'>æ±å¤§ãŒé–‹ç™ºã€ãƒŸã‚¹ãƒŸé€šè²©ã§éƒ¨å“èª¿é”ã§ãã‚‹ã€Œ4è„šãƒ­ãƒœãƒƒãƒˆã€ã®åˆ©ç‚¹</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2025.07.06</li>
          <li><a href="https://spectrum.ieee.org/video-friday-hopping-robot-insect" target='_blank'>Tiny Robot Bug Hops and Jumps: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.04.11</li>
          <li><a href="https://jp.meviy.misumi-ec.com/info/ja/news/48510/" target='_blank'>ç¬¬10å›ã€€è¨­è¨ˆãƒ»è£½é€ ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³å±•ï¼ˆDMSåå¤å±‹ï¼‰2025</a>, meviy, 2025.03.25</li>
          <li><a href="https://xtech.nikkei.com/atcl/nxt/column/18/03118/00005/" target='_blank'>è„šå¼ãƒ­ãƒœã®æ­©è¡Œé¨’éŸ³å•é¡Œã€ã‚½ãƒ‹ãƒ¼ãŒç‹¬è‡ªå¼·åŒ–å­¦ç¿’ã§aiboé™ã‹ã«</a>, æ—¥çµŒã‚¯ãƒ­ã‚¹ãƒ†ãƒƒã‚¯, 2025.03.21</li>
          <li><a href="https://techxplore.com/news/2025-03-sony-aibo-dog-quietly-elaborate.html" target='_blank'>Sony's aibo dog could soon walk quietly and perform elaborate dance routines</a>, Tech Xplore, 2025.03.04</li>
          <li><a href="https://spectrum.ieee.org/video-friday-good-over-all-terrains" target='_blank'>Good Over All Terrains: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.02.28</li>
          <li><a href="https://spectrum.ieee.org/video-friday-aibo-foster-parents" target='_blank'>Aibo Foster Parents: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.31</li>
          <li><a href="https://spectrum.ieee.org/video-friday-agile-upgrade" target='_blank'>Agile Upgrade: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-hottest-on-the-ice" target='_blank'>Hottest on the Ice: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.24</li>
          <li><a href="https://prtimes.jp/main/html/rd/p/000000060.000069918.html" target='_blank'>ã‚¢ãƒ¼ãƒ«ãƒ†ã‚£ãŒæŒ‘ã‚€ã€å›½ç”£4è¶³æ­©è¡Œãƒ­ãƒœãƒƒãƒˆã®æœªæ¥</a>, PR TIMES, 2024.12.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-multiple-magicbots" target='_blank'>Multiple MagicBots: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.12.06</li>
          <li><a href="https://www.yomiuri.co.jp/science/20241120-OYT1T50012/" target='_blank'>ã€Œé ­è„³ã€æ‰‹ã«å…¥ã‚Œã€Œå¸¸è­˜ã€å‚™ãˆãŸã‹ã«è¦‹ãˆã‚‹ãƒ­ãƒœãƒƒãƒˆâ€¦ç§ãŸã¡ã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‹ã€å€«ç†è¦³ãªãå±é™ºãªå­˜åœ¨ã‹</a>, èª­å£²æ–°è, 2024.11.20</li>
          <li><a href="https://newswitch.jp/p/43682" target='_blank'>ãƒ­ãƒœãƒƒãƒˆã«æŒ‡ç¤ºãƒ»æ„å›³ã©ã†ä¼ãˆã‚‹ï¼Ÿâ€¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æœ€é©åŒ–ã¸æ–°æ‰‹æ³•æ¢ã‚‹</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2024.11.24</li>
          <li><a href="https://spectrum.ieee.org/video-friday-quadruped-ladder-climbing" target='_blank'>Quadruped Ladder Climbing: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.10.04</li>
          <li><a href="https://interestingengineering.com/innovation/mini-muscle-power-new-robotic-forearm" target='_blank'>Game-changing mini-muscle motors power new robotic forearm like humans</a>, Interesting Engineering, 2024.09.02</li>
          <li><a href="https://www.dw.com/en/a-robot-at-the-wheel/video-69903705" target='_blank'>A robot at the wheel</a>, Deutsche Welle, 2024.08.31</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robots-table-tennis" target='_blank'>Robots Solving Table Tennis: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.30</li>
          <li><a href="https://spectrum.ieee.org/video-friday-disney-robot-dance" target='_blank'>Disney Robot Dance: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.23</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robot-dog-jump" target='_blank'>Silly Robot Dog Jump: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.16</li>
          <li><a href="https://newswitch.jp/p/42280" target='_blank'>ã€Œå¸¸è­˜ã€ã€Œãƒ‡ãƒ¼ã‚¿ã€ä½¿ã„åˆ‡ã‚Œâ€¦åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãƒ»LLMã€ãƒ­ãƒœãƒƒãƒˆã«å¿œç”¨</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2024.07.19</li>
          <li><a href="https://www.gizmodo.jp/2024/06/musashi-humanoid-driving.html" target='_blank'>äººå‹ãƒ­ãƒœã¯é‹è»¢ã‚‚ã“ãªã™ã€‚ã‚¯ãƒ«ãƒã¾ã‹ã›ã®è‡ªå‹•é‹è»¢ã‚ˆã‚Šã‚‚å®‰å¿ƒæ„Ÿã‚¢ãƒƒãƒ—</a>, GIZMODO JAPAN, 2024.06.18</li>
          <li><a href="https://www.newscientist.com/article/2435826-watch-a-humanoid-robot-driving-a-car-extremely-slowly/" target='_blank'>Watch a humanoid robot driving a car extremely slowly</a>, New Scientist, 2024.06.17</li>
          <li><a href="https://newatlas.com/robotics/musashi-humanoid-autonomous-driving/" target='_blank'>Video: Humanoid chauffeur put in the driving seat for robotaxi future</a>, New Atlas, 2024.06.13</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robots-with-knives" target='_blank'>Robots With Knives: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.05.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-racer-heavy" target='_blank'>RACER Heavy: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.26</li>
          <li><a href="https://abema.tv/video/episode/89-106_s1_p2428" target='_blank'>ã€ã™ãšã‚ã®æˆ¸ç· ã‚Šã€æ¤…å­ã‚’ãƒ­ãƒœãƒƒãƒˆã«</a>, ABEMAã€é€±åˆŠBUZZå‹•ç”»ã€‘SNSã§è©±é¡Œã®å‹•ç”»ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—!, 2024.04.20</li>
          <li><a href="https://spectrum.ieee.org/video-friday-spacehopper" target='_blank'>SpaceHopper: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.19</li>
          <li><a href="https://www.itmedia.co.jp/aiplus/articles/2404/17/news048.html" target='_blank'>ã€Œã™ãšã‚ã®æˆ¸ç· ã¾ã‚Šã€ã«ç™»å ´ã®â€œ3æœ¬è„šã®æ¤…å­â€ã‚’å†ç¾ã—ãŸãƒ­ãƒœãƒƒãƒˆã€€æ±å¤§ãŒé–‹ç™ºã€€æ­©è¡Œã—å€’ã‚Œã¦ã‚‚èµ·ãä¸ŠãŒã‚‹</a>, ITmedia AI+, 2024.04.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robot-dog-can-t-fall" target='_blank'>Robot Dog Can't Fall: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.12</li>
          <li><a href="https://spectrum.ieee.org/video-friday-co-expression" target='_blank'>Co-Expression: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.29</li>
          <li><a href="https://spectrum.ieee.org/video-friday-many-quadrupeds" target='_blank'>Many Quadrupeds: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.15</li>
          <li><a href="https://spectrum.ieee.org/video-friday-human-to-humanoid" target='_blank'>Human to Humanoid: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.08</li>
          <li><a href="https://spectrum.ieee.org/video-friday-tap-finger-move-mountain" target='_blank'>Tap Finger, Move Mountain: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2023.12.01</li>
          <li><a href="https://newswitch.jp/p/39450" target='_blank'>AIãƒ»ãƒ­ãƒœã‚‚è¿·ã†â€¦â€œæˆ‘ãŒå®¶ã®å†·è”µåº«å•é¡Œâ€ãŒè§£ã‘ãŸã‚‰å€¤åƒé‡‘ãªç†ç”±</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2023.12.01</li>
          <li><a href="https://newswitch.jp/p/39285" target='_blank'>ç”Ÿæ´»æ”¯æ´ãƒ­ãƒœãƒƒãƒˆã€ï¼¡ï¼©ã§å¤‰é©ã—ãŸç¾åœ¨åœ°ã¨å±•æœ›</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2023.11.30</li>
          <li><a href="https://spectrum.ieee.org/video-friday-punch-out" target='_blank'>Punch-Out: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2023.11.24</li>
          <li><a href="https://newswitch.jp/p/38378" target='_blank'>è…¹è…”é¡æ‰‹è¡“ã®è¨“ç·´æ‰‹æŠ€ã‚’ãƒ­ãƒœãƒƒãƒˆã«ã€æ±å¤§ãŒåˆ¶ç´„ä»˜ãæ¨¡å€£å­¦ç¿’é–‹ç™º</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2023.09.06</li>
          <li><a href="https://www.asahi.com/articles/ASLCJ3412LCJOBJB002.html" target='_blank'>äººå‹ãƒ­ãƒœãƒƒãƒˆã€Œãƒ ã‚µã‚·ã€ã€è»Šã‚‚é‹è»¢ã§ãã‚‹ã‚ˆã€€æ±å¤§ãŒæŠ«éœ²</a>, æœæ—¥æ–°è, 2018.11.16</li>
          <li><a href="https://newswitch.jp/p/13673" target='_blank'>æ±å¤§ã®ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ã€Œè…±æ‚Ÿéƒã€ã€è»Šã®é‹è»¢ã«æˆåŠŸ</a>, æ—¥åˆŠå·¥æ¥­æ–°è, 2018.07.13</li>
          <li><a href="https://www.nikkei.com/article/DGXMZO25019580U7A221C1TJM000/" target='_blank'>æ±å¤§ã€æ—¥æœ¬äººã®ç­‹éª¨æ ¼å†ç¾ã—ãŸãƒ­ãƒœãƒƒãƒˆé–‹ç™º</a>, æ—¥æœ¬çµŒæ¸ˆæ–°è, 2017.12.24</li>
          <li><a href="https://www.todaishimbun.org/seisakuten20161118/" target='_blank'>åˆæ—¥ã‹ã‚‰300äººæ¥å ´ï¼ã„ã¾è©±é¡Œã®ã€Œæ±äº¬å¤§å­¦åˆ¶ä½œå±•ã€FAKE FUTUREã€ã€ã§ã¯ã©ã‚“ãªä½“é¨“ãŒã§ãã‚‹ã®ã‹ï¼Ÿ</a>, æ±å¤§æ–°èã‚ªãƒ³ãƒ©ã‚¤ãƒ³, 2016.11.18</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Academic Activities </h2>
        </div>
        <ol>
          <li>Organizer, <a href="https://sites.google.com/g.ecc.u-tokyo.ac.jp/iros2025-ws-roboticdesign/" target='_blank'>Workshop on Foundation Models for Robotic Design</a>, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025), 2025</li>
          <li>Organizer, <a href="TODO" target='_blank'>Workshop on Open Hardware in the Era of Robot Learning</a>, Conference on Robot Learning (CoRL2025), 2025</li>
          <li>Associate Editor, 2025 IEEE-RAS International Conference on Humanoid Robots (Humanoids2025), 2025</li>
          <li>Associate Editor, 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025), 2025</li>
          <li>Associate Editor, 2025 IEEE International Conference on Robotics and Automation (ICRA2025), 2025</li>
          <li>Associate Editor, 2024 IEEE-RAS International Conference on Humanoid Robots (Humanoids2024), 2024</li>
          <li>Organizer, Organized Session on Real-World Robot Applications of Foundation Models, The 42nd Annual Conference of the Robotics Society of Japan (RSJ2024), 2024</li>
          <li>Organizer, <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Workshop on Cooking Robotics: Perception and motion planning</a>, IEEE International Conference on Robotics and Automation (ICRA2024), 2024</li>
          <li>Associate Editor, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024), 2024</li>
          <li>Section Editor, Special Section on Cognitive Development and Symbol Emergence, Advanced Robotics, 2024</li>
          <li>Guest Editor, <a href="https://www.rsj.or.jp/content/files/pub/ar/CFP/CFP_38_17.pdf" target='_blank'>Special Issue on Real-World Robot Applications of the Foundation Models</a>, Advanced Robotics, 2024</li>
          <li>Organizer, <a href="https://sites.google.com/grp.riken.jp/langrobonlp2024" target='_blank'>Workshop on Real-World Applications of Large Language Models</a>, The 30th Annual Meeting of the Association of Natural Language Processing (NLP2024), 2024</li>
          <li>Associate Editor, 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids2023), 2023</li>
          <li>Organizer, <a href="https://sites.google.com/view/robotics-foundation-models/organized-session-on-rsj2023?authuser=0" target='_blank'>Organized Session on Real-World Robot Applications of Foundation Models</a>, The 41st Annual Conference of the Robotics Society of Japan (RSJ2023), 2023</li>
          <li>Associate Editor, 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids2022), 2022</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> CV </h2>
        </div>
        <a href="static/kawaharazuka-cv.pdf">Download</a>
      </main>
    </div>
  </body>
</html>
