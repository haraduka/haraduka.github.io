<!-- This file is automatically generated. Do not modify -->
<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title> Kento Kawaharazuka </title>
    <link rel="shortcut icon" href="static/favicon.ico">
    <link rel="canonical" href="https://haraduka.github.io">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1XJ0NHR591"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-1XJ0NHR591');
    </script>

    <meta property="twitter:card" content="summary" />
    <meta property="twitter:title" content="Kento Kawaharazuka" />
    <meta property="twitter:image" content="https://haraduka.github.io/static/kawaharazuka.png" />

    <meta property="og:title" content="Kento Kawaharazuka" />
    <meta property="og:url" content="https://haraduka.github.io" />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://haraduka.github.io/static/kawaharazuka.png" />

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
  </head>

  <body>
    <div class="container py-3">

      <nav class="navbar navbar-expand-lg navbar-light fixed-top" style="background-color: #f8f9fa; border-bottom: 1px solid #ddd;">
        <div class="container">
          <a class="navbar-brand mx-auto align-items-center" href="https://haraduka.github.io" style="font-size: 24px; display: flex;">Kento Kawaharazuka</a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse justify-content-end" id="navbarSupportedContent">
            <ul class="navbar-nav" style="font-size: 24px;">
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="robots.html">Robots</a>
              </li>
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="projects.html">Projects</a>
              </li>
              <li class="nav-item" style="margin-bottom: 0;">
                <a class="nav-link px-3" href="videos.html">Videos</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <script>
        let lastScrollTop = 0;
        const navbar = document.querySelector('.navbar');

        window.addEventListener('scroll', () => {
          let currentScroll = window.pageYOffset || document.documentElement.scrollTop;

          if (currentScroll > lastScrollTop) {
            // ‰∏ãÊñπÂêë„Å´„Çπ„ÇØ„É≠„Éº„É´‰∏≠
            navbar.classList.add('navbar-hide');
            navbar.classList.remove('navbar-show');
          } else {
            // ‰∏äÊñπÂêë„Å´„Çπ„ÇØ„É≠„Éº„É´‰∏≠
            navbar.classList.add('navbar-show');
            navbar.classList.remove('navbar-hide');
          }

          lastScrollTop = currentScroll;
        });
      </script>

      <script>
        document.addEventListener("DOMContentLoaded", function () {
          document.querySelectorAll("h1, h2, h3, h4, h5, h6").forEach(function (heading) {
            // Êó¢„Å´ id „Åå„ÅÇ„Çå„Å∞‰Ωø„ÅÑ„ÄÅ„Å™„Åë„Çå„Å∞ÁîüÊàê
            if (!heading.id) {
              let baseId = heading.textContent.trim().toLowerCase()
                .replace(/[^\w\s\-]/g, '') // Ë®òÂè∑ÂâäÈô§
                .replace(/\s+/g, '-');     // Á©∫ÁôΩ„Çí„Éè„Ç§„Éï„É≥„Å´
              let uniqueId = baseId;
              let counter = 1;
              while (document.getElementById(uniqueId)) {
                uniqueId = baseId + '-' + counter++;
              }
              heading.id = uniqueId;
            }

            // „Ç¢„Ç§„Ç≥„É≥ÁîüÊàê
            const anchor = document.createElement("a");
            anchor.href = "#" + heading.id;
            anchor.className = "anchor-link";
            anchor.textContent = "üîó";
            heading.appendChild(anchor);
          });
        });
      </script>


      <main>
        <div class="row py-3">
          <div class="col-md-4 text-center">
            <div style="max-width: 400px">
              <img src="static/kawaharazuka.png" class="img-fluid mx-auto d-block" alt="Image" style="max-width: 100%; height: auto;">
            </div>
          </div>

          <div class="col-md-8 py-3">
            <h2> Kento Kawaharazuka </h2>
            <h3> Lecturer (Junior Associate Professor) </h3>
            Next Generation Artificial Intelligence Research Center (AI Center), <br>
            + Department of Mechano-Informatics, <br>
            Graduate School of Information Science and Technology, <br>
            The University of Tokyo, Japan <br>
            <div class="d-inline-flex mt-4 ms-md-auto">
              <a href="https://scholar.google.co.jp/citations?user=E75YHyUAAAAJ&hl=en" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" height="36" width="36"fill="currentColor" viewBox="0 0 512 512">
                  <path d="M390.9 298.5c0 0 0 .1 .1 .1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7c4.4-7.6 9.4-14.7 15-21.3c27.4-32.6 68.5-53.3 114.4-53.3c33.6 0 64.6 11.1 89.6 29.9c9.1 6.9 17.4 14.7 24.8 23.5c5.6 6.6 10.6 13.8 15 21.3c2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/>
                </svg>
              </a>
              <a href="https://twitter.com/KKawaharazuka" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-twitter-x" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
                </svg>
              </a>
              <a href="https://www.youtube.com/channel/UC3iq44Y7vsriPyFiU02Bcyw" target='_blank' class='me-3'>
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-youtube" viewBox="0 0 16 16">
                  <path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.007 2.007 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.007 2.007 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31.4 31.4 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.007 2.007 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A99.788 99.788 0 0 1 7.858 2h.193zM6.4 5.209v4.818l4.157-2.408z"/>
                </svg>
              </a>
              <a href="https://github.com/haraduka" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
                  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
                </svg>
              </a>
              <a href="mailto:kawaharazuka@jsk.imi.i.u-tokyo.ac.jp" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24">
                  <path fill="currentColor" d="M20 18h-2V9.25L12 13L6 9.25V18H4V6h1.2l6.8 4.25L18.8 6H20m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"/></svg>
                </svg>
              </a>
              <a href="https://www.linkedin.com/in/kento-kawaharazuka-099372285/" target='_blank' class="me-3">
                <svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
                  <path fill="currentColor" d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"/></svg>
                </svg>
              </a>
            </div>
          </div>
        </div>
        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Biography </h2>
        </div>
        Kento Kawaharazuka is a lecturer (junior associate professor) in UTokyo AI Center and JSK Robotics Laboratory at the University of Tokyo.
        His research interests are mainly in humanoids, including biomimetics, tendon-driven robots, and machine learning.
        He designs tendon-driven humanoids and develops learning control systems to move them.
        <h3> Career </h3>
        <ul>
          <li> Lecturer (Junior Associate Professor) in UTokyo AI Center and Mechano-Informatics, 2025.2- (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> Visiting Researcher, 2024.6-2024.8 (Robotics and Systems Laboratory, ETH Zurich) </li>
          <li> Project Assistant Professor in Mechano-Informatics, 2022.4-2025.1 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> Ph.D. in Mechano-Informatics, 2019.4-2022.3 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> M.S. in Mechano-Informatics, 2017.4-2019.3 (Graduate School of Information Science and Technology, The University of Tokyo) </li>
          <li> B.S. in Mechano-Informatics, 2013.4-2017.3 (Faculty of Engineering, The University of Tokyo) </li>
        </ul>

        <div class="row py-3">
          <div class="col-lg-8 offset-lg-2 text-center">
            <img src="static/robots.jpeg" class="img-fluid mx-auto d-block" alt="Image" style="max-width: 100%; height: auto;">
          </div>
        </div>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> News </h2>
        </div>
        <ul>
          <li><b> 2025.07.31 - We are organizing a IROS2025 workshop on <a href="https://sites.google.com/g.ecc.u-tokyo.ac.jp/iros2025-ws-roboticdesign/" target='_blank'>foundation models for robotic design</a>!</b></li>
          <li><b> 2025.07.29 - MIRU2025„Å´„Å¶„Äå„É≠„Éú„ÉÉ„ÉàÂü∫Áõ§„É¢„Éá„É´„ÅÆÊúÄÂâçÁ∑ö„Äç„Å®„ÅÑ„ÅÜ„ÉÅ„É•„Éº„Éà„É™„Ç¢„É´Ë¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åó„Åü.</b></li>
          <li><b> 2025.07.23 - Three papers including one first-authored paper were accepted to Humanoids2025!</b></li>
          <li><b> 2025.07.22 - We are organizing a CoRL2025 workshop on <a href="https://open-hardware-robots.github.io/CoRL2025/" target='_blank'>open-source hardware</a>!</b></li>
          <li><b> 2025.07.16 - Ë¨õË´áÁ§æÊßò„Çà„ÇäÊõ∏Á±ç„ÄåÂü∫Áõ§„É¢„Éá„É´„Å®„É≠„Éú„ÉÉ„Éà„ÅÆËûçÂêà„Äç„ÅåÂá∫Áâà„Åï„Çå„Åæ„ÅôÔºÅ„Åú„Å≤<a href="https://www.amazon.co.jp/dp/4065395852" target='_blank'>‰∫àÁ¥Ñ</a>„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºÅ</b></li>
          <li><b> 2025.06.16 - Four papers including one first-authored paper were accepted to IROS2025!</b></li>
          <li><b> 2025.06.10 - Our paper on PIMBS (physics-informed musculoskeletal body schema) was accepted to IEEE RA-L!</b></li>
          <li><b> 2025.06.04 - „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö2025„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ9‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2025.06.03 - ROBOMECH2025„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„Éó„ÄåÊ©üÊ¢∞Â≠¶Áøí„Å®‰∫∫Âûã„ÉªÂ§öËÑö„ÉªÂ§öÈñ¢ÁØÄ„É≠„Éú„ÉÉ„Éà„Äç„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åó„Åü.</b></li>
          <li><b> 2025.06.02 - Êù±ÂåóÂ§ßÂ≠¶„Çø„ÉïÔΩ•„Çµ„Ç§„Éê„Éº„Éï„Ç£„Ç∏„Ç´„É´AIÁ†îÁ©∂„Çª„É≥„Çø„Éº„Ç∑„É≥„Éù„Ç∏„Ç¶„É†„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åó„Åü.</b></li>
          <li><b> 2025.05.28 - JSAI2025‰ºÅÁîª„Çª„ÉÉ„Ç∑„Éß„É≥„Äå„Éï„Ç£„Ç∏„Ç´„É´AI„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ†îÁ©∂ÈñãÁô∫„Äç„Å´„Å¶„Éë„Éç„É™„Çπ„Éà„ÇíÂãô„ÇÅ„Åæ„Åó„Åü.</b></li>
          <li><b> 2025.05.24 - Our paper on reinforcement learning-based obstacle avoidance for aerial robots was accepted to Advanced Robotics!</b></li>
          <li><b> 2025.05.09 - Our workshop on Foundation Models for Robotic Design was accepted to IROS2025!</b></li>
          <li><b> 2025.05.06 - Our paper on self-healing tendon-driven robot was accepted to Advanced Intelligent Systems!</b></li>
          <li><b> 2025.05.01 - IEICEÂÖàÁ´Ø„Çª„Éü„Éä„Éº„ÅÆ„ÄåÁîüÊàêAI„ÅÆÂøúÁî®„ÄçË¨õÂ∫ß„Å´„Å¶Ë¨õÂ∏´„ÇíÂãô„ÇÅ„Åæ„Åó„Åü.</b></li>
          <li><b> 2025.04.09 - Our paper on mobile tendon-driven CubiX was accepted to Advanced Robotic Research!</b></li>
          <li><b> 2025.04.02 - I gave a short talk and joined a panel discussion at the Embodied Intelligence Conference (EI2025).</b></li>
        </ul>
        <div onclick="obj=document.getElementById('open').style; obj.display=(obj.display=='none')?'block':'none';">
          <a style="cursor:pointer;">‚ñº click here to expand</a>
        </div>
        <div id="open" style="display:none;clear:both;">
          <ul>
          <li><b> 2025.03.28 - JST CRDS Á†îÁ©∂ÈñãÁô∫Êà¶Áï•„Çª„É≥„Çø„Éº„Åã„Çâ, ÁßëÂ≠¶ÊäÄË°ìÊú™Êù•Êà¶Áï•„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„ÉóÂ†±ÂëäÊõ∏„Äå„Éï„Ç£„Ç∏„Ç´„É´AI„Ç∑„Çπ„ÉÜ„É†„Äç„ÅåÂÖ¨Èñã„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2025.03.18 - „Éë„Çø„Éº„É≥Ë™çË≠ò„Éª„É°„Éá„Ç£„Ç¢ÁêÜËß£Á†îÁ©∂‰ºö (PRMU)„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åô.</b></li>
          <li><b> 2025.02.01 - Kento Kawaharazuka has promoted to Lecturer (Junior Associate Professor) in UTokyo AI Center and Department of Mechano-Informatics!</b></li>
          <li><b> 2025.01.28 - Two papers including one first-authored paper were accepted at ICRA2025!</b></li>
          <li><b> 2025.01.24 - Our front hair styling robot was selected as a Best Student Paper Award Finalist at SII2025!</b></li>
          <li><b> 2025.01.08 - ÂÖ±ÂêåÂü∑Á≠Ü„Åó„ÅüÊõ∏Á±ç„ÄåData-Centric AIÂÖ•ÈñÄ„Äç„ÅåÊäÄË°ìË©ïË´ñÁ§æ„Åã„ÇâÂá∫Áâà„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2024.12.07 - I gave an inivited talk at VANJ Conference 2024!</b></li>
          <li><b> 2024.12.06 - I gave an inivited talk at Tokyo AI (TAI)!</b></li>
          <li><b> 2024.11.24 - CubiXMusashi won the Mike Stillman Award at Humanoids2024!</b></li>
          <li><b> 2024.11.23 - I gave a plenary talk at Humanoids2024.</b></li>
          <li><b> 2024.11.20 - I gave an invited talk at KIT, Karlsruhe.</b></li>
          <li><b> 2024.11.08 - One paper was accepted to SII2025</b></li>
          <li><b> 2024.09.09 - Eight papers including three first-authored papers were accepted to Humanoids2024.</b></li>
          <li><b> 2024.09.04 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2024„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ10‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2024.08.01 - I gave a talk at Professor Sven Behnke's Lab at University of Bonn.</b></li>
          <li><b> 2024.07.31 - I gave an invited talk at DLR, Oberpfaffenhofen.</b></li>
          <li><b> 2024.07.30 - I gave a talk at Professor Gordon Cheng's Lab at TUM, Munich.</b></li>
          <li><b> 2024.07.29 - I gave an invited talk at Max Planck Institute, Tubingen.</b></li>
          <li><b> 2024.07.05 - I gave a talk at CREATE lab at EPFL, Lausanne.</b></li>
          <li><b> 2024.06.30 - Six papers including two first-authored papers were accepted to IROS2024.</b></li>
          <li><b> 2024.06.28 - I gave an invited talk at CRL Seminar at ETH Zurich.</b></li>
          <li><b> 2024.06.25 - ÂâµÁô∫ÁöÑÁ†îÁ©∂ÊîØÊè¥‰∫ãÊ•≠„Å´Êé°Êäû„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2024.06.20 - I gave an invited talk at postdoc seminar at IIT, Genova.</b></li>
          <li><b> 2024.06.17 - I gave an invited talk at symposium on robotics in biomedical applications at KTH, Stockholm.</b></li>
          <li><b> 2024.06.03 - I will be conducting research as a visiting researcher at ETH for two and a half months.</b></li>
          <li><b> 2024.05.30 - „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö2024„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ10‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2024.05.28 - ‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºö2024„Å´„Å¶1‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2024.05.17 - I gave an organizer talk at ICRA2024 workshop on <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Cooking Robotics: Perception and Motion Planning</a>.</b></li>
          <li><b> 2024.05.16 - RT-X project won the Best Conference Paper Award at ICRA2024!</b></li>
          <li><b> 2024.04.15 - I gave an invited talk at RoboSoft2024 workshop on <a href="https://printed-musculoskeletal-robots.ethz.ch/" target='_blank'>From Layers to Limbs! Exploring the Interface of 3D Printing and Bio-Inspired Musculoskeletal Robotics</a>.</b></li>
          <li><b> 2024.03.05 - Our paper "Continuous Object State Recognition for Cooking Robots" was accepted to RA-L!</b></li>
          <li><b> 2024.03.05 - Our paper "SAQIEL: Ultra-Light and Safe Manipulator" was accepted to RA-L!</b></li>
          <li><b> 2024.02.09 - Our new survey paper "Real-World Robot Applications of Foundation Models: A Review" is now on arXiv!</b></li>
          <li><b> 2024.02.09 - "ÂçµÊñôÁêÜ„ÅÆÂÆü‰∏ñÁïåË™øÁêÜÂÆüË°å"„Å®"Ê∂≤‰ΩìÊª≤Âá∫ËªüÈ™®Ê©üÊßã„ÅÆÊßãÊàêÊ≥ï"„Å´Èñ¢„Åô„ÇãÁ†îÁ©∂„ÅåË®àÊ∏¨Ëá™ÂãïÂà∂Âæ°Â≠¶‰ºö2023„Å´„Å¶ÂÑ™ÁßÄË¨õÊºîË≥û„Å´ÈÅ∏„Å∞„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2024.02.04 - I have been staying at Robotic Systems Lab at ETH in Switzerland for the past two weeks. I appreciate the insightful discussions!</b></li>
          <li><b> 2024.02.02 - We organize <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Cooking Robotics Workshop</a> at ICRA2024!</b></li>
          <li><b> 2024.01.30 - We have extended the deadline of Advanced Robotics Special Issue on Real-World Robot Applications of Foundation Models to 29th February.</b></li>
          <li><b> 2024.01.29 - Five papers including two first-authored papers were accepted to ICRA2024.</b></li>
          <li><b> 2024.01.19 - Two papers  were accepted to RoboSoft2024.</b></li>
          <li><b> 2023.12.15 - We visited RoMeLa at UCLA and GITAI.</b></li>
          <li><b> 2023.12.12 - We presented five papers at Humanoids2023.</b></li>
          <li><b> 2023.10.29 - Á¨¨19ÂõûË∫´‰ΩìÊÄßË™çÁü•ÁßëÂ≠¶„Å®ÂÆü‰∏ñÁïåÂøúÁî®„Å´Èñ¢„Åô„ÇãËã•ÊâãÁ†îÁ©∂‰ºö(ECSRA)„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åô.</b></li>
          <li><b> 2023.10.24 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™åVol.41, No.8„Å´"ÊÉÖÂ†±ÂåñË∫´‰Ωì„ÅÆÂ≠¶ÁøíÁêÜË´ñ„Å´Âü∫„Å•„ÅèÊàêÈï∑„É≠„Éú„ÉÉ„Éà„ÅÆÈù©Êñ∞„Å®ÂâµÊàê"„Å´Èñ¢„Åô„ÇãËß£Ë™¨Ë®ò‰∫ã„ÅåÊé≤Ëºâ„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2023.10.18 - Á¨¨5ÂõûLLMÂãâÂº∑‰ºö(LLM-jp)„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åô.</b></li>
          <li><b> 2023.10.06 - We visited Stanford University.</b></li>
          <li><b> 2023.10.05 - I gave an invited talk at IROS2023 workshop on <a href="https://sites.google.com/view/learning-meets-models-iros2023/speakers?authuser=0" target='_blank'>Learning Meets Model-based Methods for Manipulation and Grasping</a>.</b></li>
          <li><b> 2023.09.30 - Five papers including two first-authored papers were accepted to Humanoids2023.</b></li>
          <li><b> 2023.09.12 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2023„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ12‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2023.08.31 - NLPËã•Êâã„ÅÆ‰ºö(YANS2023)„ÅÆÊãõÂæÖ„Çª„ÉÉ„Ç∑„Éß„É≥„ÅßÁô∫Ë°®„Åó„Åæ„Åô.</b></li>
          <li><b> 2023.06.29 - "ÂãïÁöÑÊüîËªüÂ∏ÉÊìç‰Ωú"„ÅÆÁ†îÁ©∂„Åå„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö2022„Å´„Å¶„Éô„Çπ„Éà„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥Ë≥û„Å´ÈÅ∏„Å∞„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2023.06.29 - „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö2023„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ13‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2023.06.28 - „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö2023„Ç∑„É≥„Éù„Ç∏„Ç¶„É†„Äå"„ÅÑ„ÅÑ„Åã„Åí„Çì"„ÇíÁßëÂ≠¶„Åó„Å¶Êú™Êù•„ÇíÂâµ„Çã„ÇΩ„Éï„Éà„É≠„Éú„ÉÉ„ÉàÂ≠¶4„Äç„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åô.</b></li>
          <li><b> 2023.06.22 - Five papers including one first-authored paper were accepted to IROS2023.</b></li>
          <li><b> 2023.06.06 - ‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºö2023„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ2‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2023.06.02 - One paper was accepted to ROMAN2023.</b></li>
          <li><b> 2023.05.30 - Four papers were accepted to IAS18.</b></li>
          <li><b> 2023.05.17 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2023„Å´„Å¶OS4„ÄåÂü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî®„Äç„Çí‰∏ªÂÇ¨„Åó„Åæ„Åô.</b></li>
          <li><b> 2023.04.10 - One paper was accepted to AMAM2023.</b></li>
          <li><b> 2023.04.05 - Êñ∞Â≠¶Êúü„Åã„Çâ3‰∫∫„ÅÆB4„ÅåËá™ÂàÜ„ÅÆ„Ç∞„É´„Éº„Éó„Å´Âä†„Çè„Çä„Åæ„Åó„Åü.</b></li>
          <li><b> 2023.04.01 - JST ACT-X„ÄåAIÊ¥ªÁî®„ÅßÊåë„ÇÄÂ≠¶Âïè„ÅÆÈù©Êñ∞„Å®ÂâµÊàê„Äç„ÅÆÂä†ÈÄü„Éï„Çß„Éº„Ç∫„Å´Êé°Êäû„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2023.01.19 - Two first-authored papers (including one RAM paper) were accepted to ICRA2023.</b></li>
          <li><b> 2022.12.16 - „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢2023„Å´‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ6‰ª∂„ÅÆÁô∫Ë°®„ÅåÊé°Êäû„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2022.12.14 - Ë®àÊ∏¨Ëá™ÂãïÂà∂Âæ°Â≠¶‰ºö2022„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ5‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2022.11.30 - "Hardware and Software Design of Musashi-W" was selected as Best Interactive Paper Award Finalist at Humanoids2022.</b></li>
          <li><b> 2022.11.21 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™åVol.40, No.9„Å´"„Éë„É©„É°„Éà„É™„ÉÉ„ÇØ„Éê„Ç§„Ç¢„Çπ„ÇíÂê´„ÇÄÊ∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí"„Å´Èñ¢„Åô„ÇãËß£Ë™¨Ë®ò‰∫ã„ÅåÊé≤Ëºâ„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2022.10.26 - "Self-Supervised Learning of Visual Servoing" was selected as SICE International Young Authors Award at IROS2022.</b></li>
          <li><b> 2022.10.26 - "Parallel-Wire Driven Monopedal Robot RAMIEL" was selected as SICE International Young Authors Award at IROS2022.</b></li>
          <li><b> 2022.09.09 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2022 "Ëã•ÊâãÁ†îÁ©∂ËÄÖ„ÅåÊèè„Åè2050Âπ¥„ÅÆAI„É≠„Éú„ÉÉ„Éà„Éì„Ç∏„Éß„É≥"OF„Å´„Å¶ÊãõÂæÖË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åô.</b></li>
          <li><b> 2022.09.05 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2022„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ14‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2022.09.26 - Five papers including three first-authored papers were accepted to Humanoids2022.</b></li>
          <li><b> 2022.06.30 - Seven papers including four first-authored papers (including one RA-L paper) were accepted to IROS2022.</b></li>
          <li><b> 2022.06.17 - "Human-mimetic Binaural Ear Design" was accepted to Robomech Journal.</b></li>
          <li><b> 2022.06.15 - ‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºö2022„Å´„Å¶‰∏ªËëó1‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2022.06.03 - Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö2022„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ10‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2022.06.01 - "Roboust Continous Motion Against Muscle Rupture" was accepted to Robotics and Autonomous Systems.</b></li>
          <li><b> 2022.05.27 - We won the first prize of state-based category at DodgeDrone Challenge at ICRA2022.</b></li>
          <li><b> 2022.05.23 - "Dynamic Cloth Manipulation" was accepted to Frontiers in Neurorobotics.</b></li>
          <li><b> 2022.04.05 - Êñ∞Â≠¶Êúü„Åã„Çâ2‰∫∫„ÅÆB4„Å®1‰∫∫„ÅÆM1„ÅåËá™ÂàÜ„ÅÆ„Ç∞„É´„Éº„Éó„Å´Âä†„Çè„Çä„Åæ„Åó„Åü.</b></li>
          <li><b> 2022.04.01 - I received Ph.D. and became a project assistant professor at JSK Roboics Laboratory.</b></li>
          <li><b> 2022.03.24 - ÂçöÂ£´Ë´ñÊñá„ÅåÁ†îÁ©∂ÁßëÈï∑Ë≥û„Å´ÈÅ∏„Å∞„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2022.02.01 - Two papers including one first-authored paper (including one RA-L paper) were accepted to ICRA2022.</b></li>
          <li><b> 2022.01.21 - "Á¢∫ÁéáÁöÑÊ∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí"„Å´Èñ¢„Åô„ÇãÁ†îÁ©∂„ÅåSI2021„Å´„Åä„ÅÑ„Å¶ÂÑ™ÁßÄË¨õÊºîË≥û„Å´ÈÅ∏„Å∞„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2021.12.15 - Ë®àÊ∏¨Ëá™ÂãïÂà∂Âæ°Â≠¶‰ºö2021„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ3‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2021.09.09 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2021„Å´„Å¶"Ê∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí"„Å´„Å§„ÅÑ„Å¶„Ç≠„Éº„Éé„Éº„ÉàË¨õÊºî„ÇíË°å„ÅÑ„Åæ„Åô.</b></li>
          <li><b> 2021.09.06 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2021„Å´„Å¶‰∏ªËëó1‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2021.07.22 - "Design of MusashiOLegs" was selected as Best Oral Paper Award at Humanoids2020.</b></li>
          <li><b> 2021.07.01 - Five papers including four first-authored papers (including three RA-L papers) were accepted to IROS2021.</b></li>
          <li><b> 2021.06.06 - Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö2021„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ7‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2021.05.01 - Three papers including two first-authored papers were accepted to Humanoids2020.</b></li>
          <li><b> 2021.03.01 - Four papers including two first-authored papers (including one RA-L and one RAM papers) were accepted to ICRA2021.</b></li>
          <li><b> 2021.02.10 - One first-authored paper was accepted to RoboSoft2021.</b></li>
          <li><b> 2021.01.27 - "ÈÅìÂÖ∑ÂΩ¢Áä∂ÊúÄÈÅ©Âåñ"„Å´Èñ¢„Åô„ÇãÁ†îÁ©∂„ÅåË®àÊ∏¨Ëá™ÂãïÂà∂Âæ°Â≠¶‰ºö2020„Å´„Å¶ÂÑ™ÁßÄË¨õÊºîË≥û„Å´ÈÅ∏„Å∞„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2020.12.16 - Ë®àÊ∏¨Ëá™ÂãïÂà∂Âæ°Â≠¶‰ºö2020„Å´„Å¶‰∏ªËëó3‰ª∂„ÇíÂê´„ÇÄ4‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2020.11.24 - "ÊàêÈï∑„É≠„Éú„ÉÉ„Éà"„Å´Èñ¢„Åô„ÇãË™≤È°å„ÅåJST ACT-X„ÄåAIÊ¥ªÁî®„ÅßÊåë„ÇÄÂ≠¶Âïè„ÅÆÈù©Êñ∞„Å®ÂâµÊàê„ÄçÈ†òÂüü„Å´Êé°Êäû„Åï„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2020.10.10 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2020„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ2‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2020.10.09 - "ÊüîËªüÁâ©‰ΩìÊìç‰Ωú"„Å®"Musculoskeletal AutoEncoder"„Å´Èñ¢„Åô„ÇãÁ†îÁ©∂„ÅåÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2019„Å´„Å¶Á†îÁ©∂Â•®Âä±Ë≥û„Å´ÈÅ∏„Å∞„Çå„Åæ„Åó„Åü.</b></li>
          <li><b> 2020.07.03 - Six papers including five first-authored papers (including two RA-L papers) were accepted to IROS2020.</b></li>
          <li><b> 2020.05.27 - Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö2020„Å´„Å¶2‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2020.05.13 - "Autonomous Driving by Musculoskeletal Humanoids" was accepted to Robotics and Autonomous Magazine.</b></li>
          <li><b> 2020.04.20 - "Human Mimetic Forearm and Hand Design" was accepted to Journal of Robotics and Mechatronics.</b></li>
          <li><b> 2020.01.22 - Three papers including two first-authored papers (including one RA-L paper) were accepted to ICRA2020.</b></li>
          <li><b> 2019.10.09 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2019„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ5‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2019.08.26 - Three papers including one first-authored paper were accepted to Humanoids2019.</b></li>
          <li><b> 2019.06.21 - Seven papers including four first-authored paper (including one RA-L paper)were accepted to IROS2019.</b></li>
          <li><b> 2019.06.05 - Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö2019„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ8‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2019.04.13 - One first-authored paper was accepted to AMAM2019.</b></li>
          <li><b> 2019.01.22 - One first-authored paper was accepted to ICRA2019.</b></li>
          <li><b> 2018.10.02 - "Five-Fingered Hand Design" was selected as IROS ICROS Best Application Paper Award 2018 Finalists at IROS2018.</b></li>
          <li><b> 2018.09.21 - Three papers including two first-authored papers were accepted to Humanoids2018.</b></li>
          <li><b> 2018.09.05 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2018„Å´„Å¶‰∏ªËëó2‰ª∂„ÇíÂê´„ÇÄ4‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2018.06.29 - Two papers including one first-authored paper were accepted to IROS2018.</b></li>
          <li><b> 2018.06.02 - Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö2018„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ4‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2018.03.06 - One first-authored paper (RA-L paper) was accepted to IROS2018.</b></li>
          <li><b> 2017.09.24 - "Human Mimetic Forearm Design" was selected as IEEE RAS Japan Joint Chapter Young Award at IROS2017.</b></li>
          <li><b> 2017.09.11 - Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö2017„Å´„Å¶‰∏ªËëó1‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          <li><b> 2017.06.29 - Three papers including two first-authored paper (including one RA-L paper) were accepted to IROS2017.</b></li>
          <li><b> 2017.05.10 - Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö2017„Å´„Å¶‰∏ªËëó1‰ª∂„ÇíÂê´„ÇÄ2‰ª∂„ÅÆÁô∫Ë°®„Åå„ÅÇ„Çä„Åæ„Åô.</b></li>
          </ul>
        </div>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Publications </h2>
        </div>
<h3> International Journal Papers </h3>
<ol>
<li>L. Wu, H. Jia, <b><u>K. Kawaharazuka</u></b>, H. Ishida, K. Okada<br>Dexterous Grasp Dataset Augmentation based on Grasp Synthesis with Fingertip Workspace Cloud and Contact-Aware Sampling, <i>Advanced Robotics (<b>AR</b>)</i>, 2025</li>
<li><b><u>K. Kawaharazuka</u></b>, T. Hattori, K. Yoneda, K. Okada<br>PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 10, no. 7, pp. 7611-7618, 2025, (<b>presented at ICRA2026</b>)<br> <a href=https://doi.org/10.1109/LRA.2025.3577525 target='_blank'>[Paper Link]</a> <a href=https://haraduka.github.io/pinn-body-schema/ target='_blank'>[Project Page]</a></li>
<li>S. Nakashima, <b><u>K. Kawaharazuka</u></b>, Y. Nagamatsu, K. Shinjo, A. Miki, Y. Asano, Y. Kakiuchi, K. Okada, M. Inaba<br>Liquid Metal Sloshing for High-load Active Self-healing System: An Application to Tendon-driven Legged Robot, <i>Advanced Intelligent Systems (<b>AISY</b>)</i>, 2025<br> <a href=https://doi.org/10.1002/aisy.202500040 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=6ZZuyH0jLhA target='_blank'>[Video]</a></li>
<li>H. Kozuka, M. Zhao, A. Tang, T. Nishio, I. Yanokura, <b><u>K. Kawaharazuka</u></b>, J. Sugihara, K. Sugihara, K. Okada, M. Inaba<br>GenAerialNav: Obstacle Avoidance in Real Flight for Generalized Multirotors by Reinforcement Learning with Variable Acc-Properties in Dynamics, <i>Advanced Robotics (<b>AR</b>)</i>, 2025<br> <a href=https://doi.org/10.1080/01691864.2025.2506091 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=exHWNdzYHaM target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, K. Okada, M. Inaba<br>Overcoming Physical Limitations Utilizing the Surrounding Environment with a Wire-Driven Multipurpose Robot, <i>Advanced Robotics Research (<b>ADRR</b>)</i>, vol. 1, no. 1, pp. 202400021, 2025<br> <a href=https://doi.org/10.1002/adrr.202400021 target='_blank'>[Paper Link]</a> <a href=https://shin0805.github.io/cubix-overcoming/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=Vn5Kx3mq41g target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Matsushima, A. Gambardella, J. Guo, C. Paxton, A. Zeng<br>Real-World Robot Applications of Foundation Models: A Review, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1232-1254, 2024, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.1080/01691864.2024.2408593 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2402.05741 target='_blank'>[Arxiv Link]</a></li>
<li>N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>Real-world cooking robot system from recipes based on food state recognition using foundation models and PDDL, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1318-1334, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2407136 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.02874 target='_blank'>[Arxiv Link]</a> <a href=https://kanazawanaoaki.github.io/cook-from-recipe-pddl/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=3bQRTAKV0wM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada, M. Inaba<br>Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1307-1317, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2393409 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.11380 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/omnidirectional-vlm/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=T2Uezkpu5u4 target='_blank'>[Video]</a></li>
<li>S. Wakabayashi, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Behavioral Learning of Dish Rinsing and Scrubbing based on Interruptive Direct Teaching Considering Assistance Rate, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 15, pp. 1052-1065, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2379393 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09360 target='_blank'>[Arxiv Link]</a> <a href=https://shmpwk.github.io/projects/dish_wash/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=db4OcVsz3YY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, 2024, (<b>presented at ICRA2025</b>)<br> <a href=https://doi.org/10.1109/MRA.2024.3415111 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.06427 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic Environmental State Recognition with Pre-Trained Vision-Language Models and Black-Box Optimization, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1255-1264, 2024<br> <a href=https://doi.org/10.1080/01691864.2024.2366995 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.17519 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/vlm-bbo/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=aOoQcEdVb6M target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, Y. Obinata, K. Okada, M. Inaba<br>Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 5, pp. 4059-4066, 2024, (<b>presented at Humanoids2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2024.3375257 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.08239 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/continuous-state-recognition/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=480caUHXrE0 target='_blank'>[Video]</a></li>
<li>T. Suzuki, M. Bando, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>SAQIEL: Ultra-Light and Safe Manipulator with Passive 3D Wire Alignment Mechanism, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 4, pp. 3720-3727, 2024, (<b>presented at IROS2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2024.3371219 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.01803 target='_blank'>[Arxiv Link]</a> <a href=https://tenrobo18.github.io/saqiel-ral2023-webpage/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=QEluGqmj-k8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Yoshimura, T. Suzuki, K. Okada, M. Inaba<br>Design Optimization of Wire Arrangement With Variable Relay Points in Numerical Simulation for Tendon-Driven Robots, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 9, no. 2, pp. 1388-1395, 2024, (<b>presented at IROS2024</b>)<br> <a href=https://doi.org/10.1109/LRA.2023.3342667 target='_blank'>[Paper Link]</a> <a href=http://arxiv.org/abs/2401.02730 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/muscle-arrange-optimization/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=Uq9Ympi7KMw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Deep Predictive Model Learning with Parametric Bias: Handling Modeling Difficulties and Temporal Model Changes, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, vol. 31, no. 4, pp. 81-99, 2023, (<b>presented at ICRA2023</b>)<br> <a href=https://doi.org/10.1109/MRA.2022.3217744 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.15726 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada, M. Inaba<br>Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 7, no. 3, pp. 7881-7887, 2022, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2022)</font></b>, (<b>presented at IROS2022</b>)<br> <a href=https://doi.org/10.1109/LRA.2022.3186074 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11798 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=ulWgQTVDGQA target='_blank'>[Video]</a></li>
<li>Y. Omura, <b><u>K. Kawaharazuka</u></b>, Y. Nagamatsu, Y. Koga, M. Nishiura, Y. Toshimitsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Human-mimetic binaural ear design and sound source direction estimation for task realization of musculoskeletal humanoids, <i>Robomech Journal</i>, vol. 9, no. 17, pp. 1-15, 2022<br> <a href=https://doi.org/10.1186/s40648-022-00231-x target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.06427 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=d8YB1UJfDCM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, K. Okada, M. Inaba<br>Dynamic Cloth Manipulation Considering Variable Stiffness and Material Change Using Deep Predictive Model With Parametric Bias, <i>Frontiers in Neurorobotics</i>, vol. 16, pp. 1-16, 2022<br> <a href=https://doi.org/10.3389/fnbot.2022.890695 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.15635 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=wDJmIL0ZkbE target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Toshimitsu, Y. Omura, Y. Koga, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Robust Continuous Motion Strategy Against Muscle Rupture using Online Learning of Redundant Intersensory Networks for Musculoskeletal Humanoids, <i>Robotics and Autonomous Systems (<b>RAS</b>)</i>, vol. 152, pp. 1-14, 2022<br> <a href=https://doi.org/10.1016/j.robot.2022.104067 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.14951 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=deRDl2zI_0c target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, Y. Toshimitsu, K. Okada, M. Inaba<br>Adaptive Body Schema Learning System Considering Additional Muscles for Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 7, no. 2, pp. 3459-3466, 2022, (<b>presented at ICRA2022</b>)<br> <a href=https://doi.org/10.1109/LRA.2022.3147457 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06322 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=cc0223BgKlA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Adaptive Robotic Tool-Tip Control Learning Considering Online Changes in Grasping State, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 3, pp. 5992-5999, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3088807 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08052 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=cpimgpBHgxY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Kawamura, K. Okada, M. Inaba<br>Imitation Learning with Additional Constraints on Motion Style using Parametric Bias, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 3, pp. 5897-5904, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3087423 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08057 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=dunhjxYzvUA target='_blank'>[Video]</a></li>
<li>Y. Koga, <b><u>K. Kawaharazuka</u></b>, Y, Toshimitsu, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Self-Body Image Acquisition and Posture Generation with Redundancy using Musculoskeletal Humanoid Shoulder Complex for Object Manipulation, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 4, pp. 6686-6692, 2021, (<b>presented at IROS2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3095318 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06320 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=YS_shMahQSQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Koga, Y. Omura, Y. Toshimitsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Automatic Grouping of Redundant Sensors and Actuators Using Functional and Spatial Connections: Application to Muscle Grouping for Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 6, no. 2, pp. 1981-1988, 2021, (<b>presented at ICRA2021</b>)<br> <a href=https://doi.org/10.1109/LRA.2021.3060715 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.00678 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=TWJqvRVSVFk target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Koga, Y. Omura, T. Makabe, K. Shinjo, M. Onitsuka, Y. Nagamatsu, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Toward Autonomous Driving by Musculoskeletal Humanoids: Study of Developed Hardware and Learning-Based Software, <i>IEEE Robotics and Automation Magazine (<b>RAM</b>)</i>, vol. 27, no. 3, pp. 84-96, 2020, (<b>presented at ICRA2021</b>)<br> <a href=https://doi.org/10.1109/MRA.2020.2987805 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.05573 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=qQqv2pFMhmo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Object Recognition, Dynamic Contact Simulation, Detection, and Control of the Flexible Musculoskeletal Hand Using a Recurrent Neural Network With Parametric Bias, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 3, pp. 4580-4587, 2020, (<b>presented at IROS2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.3002199 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08050 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=c4mhS5BvkPw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Hiraoka, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Estimation and Control of Motor Core Temperature with Online Learning of Thermal Model Parameters: Application to Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 3, pp. 4273-4280, 2020, (<b>presented at IROS2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.2990889 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.08055 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Musculoskeletal AutoEncoder: A Unified Online Acquisition Method of Intersensory Networks for State Estimation, Control, and Simulation of Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 5, no. 2, pp. 2411-2418, 2020, (<b>presented at ICRA2020</b>)<br> <a href=https://doi.org/10.1109/LRA.2020.2972841 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.17134 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=E510TsXRTf8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, S. Nakashima, Y. Asano, K. Okada, M. Inaba<br>Human Mimetic Forearm and Hand Design with a Radioulnar Joint and Flexible Machined Spring Finger for Human Skillful Motions, <i>Journal of Robotics and Mechatronics (<b>JRM</b>)</i>, vol. 32, no. 2, pp. 445-458, 2020, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.20965/jrm.2020.p0445 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09934 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=h1sEw56zCwo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Long-time Self-body Image Acquisition and its Application to the Control of Musculoskeletal Structures, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 4, no. 3, pp. 2965-2972, 2019, (<b>presented at IROS2019</b>)<br> <a href=https://doi.org/10.1109/LRA.2019.2923968 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05293 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=P5Z4XRYXYzA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>Online Learning of Joint-Muscle Mapping using Vision in Tendon-driven Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 3, no. 2, pp. 772-779, 2018, (<b>presented at ICRA2018</b>)<br> <a href=https://doi.org/10.1109/LRA.2018.2789849 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05295 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=8_A6--bzAeQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Kawamura, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Antagonist Inhibition Control in Redundant Tendon-driven Structures Based on Human Reciprocal Innervation for Wide Range Limb Motion of Musculoskeletal Humanoids, <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, vol. 2, no. 4, pp. 2119-2126, 2017, (<b>presented at IROS2017</b>)<br> <a href=https://doi.org/10.1109/LRA.2017.2720854 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.00705 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=nFMRb1SCs1Q target='_blank'>[Video]</a></li>
</ol>
<h3> International Conference Proceedings (Peer Reviewed) </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, S. Sawaguchi, A. Iwata, K. Yoneda, T. Suzuki, K. Okada<br>MEVITA: Open-Source Bipedal Robot Assembled from E-Commerce Components via Sheet Metal Welding, in <i>Humanoids2025</i>, 2025, (<b>The first two authors contributed equally to this work</b>)</li>
<li>T. Suzuki, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>A Universal Wire Testing Machine for Enhancing the Performance of Wire-Driven Robots, in <i>Humanoids2025</i>, 2025</li>
<li>T. Hattori, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Design and Development of a Remotely Wire-Driven Walking Robot, in <i>Humanoids2025</i>, 2025</li>
<li><b><u>K. Kawaharazuka</u></b>, S. Inoue, Y. Sahara, K. Yoneda, T. Suzuki, K. Okada<br>Design Optimization of Three-Dimensional Wire Arrangement Considering Wire Crossings for Tendon-driven Robots, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025<br> <a href=https://arxiv.org/abs/2507.04235 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/muscle-3d-opt/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cy510s-kOaY target='_blank'>[Video]</a></li>
<li>K. Yoneda, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, T. Hattori, K. Okada<br>KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025<br> <a href=https://arxiv.org/abs/2507.06562 target='_blank'>[Arxiv Link]</a> <a href=https://keitayoneda.github.io/kleiyn-chimney-climbing/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cLfUhyNFOeY target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, K. Yoneda, S. Yuzaki, Y. Sahara, T. Suzuki, K. Okada<br>An RGB-D Camera-Based Multi-Small Flying Anchors Control for Wire-Driven Robots Connecting to the Environment, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025</li>
<li>S. Yoshimura, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing, in <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2025</b>)</i>, 2025</li>
<li>R. Watanabe, T. Miki, F. Shi, Y. Kadokawa, F. Bjelonic, <b><u>K. Kawaharazuka</u></b>, A. Cramariuc, M. Hutter<br>Learning Quiet Walking for a Small Home Robot, in <i>2025 IEEE International Conference on Robotics and Automation (<b>ICRA2025</b>)</i>, 2025<br> <a href=https://arxiv.org/abs/2502.10983 target='_blank'>[Arxiv Link]</a> <a href=https://sony.github.io/QuietWalk/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=6RjkBHSYEcc target='_blank'>[Video]</a></li>
<li>S. Kim, N. Kanazawa, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Front Hair Styling Robot System Using Path Planning for Root-Centric Strand Adjustment, in <i>2025 IEEE/SICE International Symposium on System Integration (<b>SII2025</b>)</i>, 2025, <b><font color='red'>Best Student Paper Finalist</font></b><br> <a href=https://arxiv.org/abs/2501.10991 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=AUBmOXsnqbg target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Inoue, T. Suzuki, S. Yuzaki, S. Sawaguchi, K. Okada, M. Inaba<br>MEVIUS: A Quadruped Robot Easily Constructed through E-Commerce with Sheet Metal Welding and Machining, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 631-636, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769853 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.14721 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/mevius-hardware/ target='_blank'>[Project Page]</a> <a href=https://github.com/haraduka/mevius target='_blank'>[Source Code]</a> <a href=https://www.youtube.com/watch?v=XXJ4EK3Y4zQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 934-940, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769848 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.22707 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=4LzAM_bGBAI target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, Y. Ribayashi, Y. Sahara, K. Okada<br>CubiXMusashi: Fusion of Wire-Driven CubiX and Musculoskeletal Humanoid Musashi toward Unlimited Performance, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 274-279, 2024, <b><font color='red'>Mike Stillman Award</font></b><br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769840 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.23682 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/cubixmusashi/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=IvzP98-r_mo target='_blank'>[Video]</a></li>
<li>Y. Iwata, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Integrative Wrapping System for a Dual-Arm Humanoid Robot, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 84-90, 2024, <b><font color='red'>Kanako Miura Award</font></b><br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769922 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.08389 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Obinata, H. Jia, <b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada<br>Remote Life Support Robot Interface System for Global Task Planning and Local Action Expansion Using Foundation Models, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 738-743, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769852 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.10038 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=bM0w69k0LM8 target='_blank'>[Video]</a></li>
<li>S. Sawaguchi, T. Suzuki, A. Miki, <b><u>K. Kawaharazuka</u></b>, S. Yuzaki, S. Yoshimura, Y. Ribayashi, K. Okada, M. Inaba<br>Vlimb: A Wire-Driven Wearable Robot for Bodily Extension, Balancing Powerfulness and Reachability, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 851-857, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769893 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.09565 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=JIRoCHnsVrw target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, Y. Sahara, S. Sawaguchi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Fundamental Three-Dimensional Configuration of Wire-Wound Muscle-Tendon Complex Drive, in <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, pp. 980-987, 2024<br> <a href=https://doi.org/10.1109/Humanoids58906.2024.10769901 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.03838 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=EDeAqg7aAb4 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Robot Design Optimization with Rotational and Prismatic Joints Using Black-Box Multi-Objective Optimization, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 4571-4577, 2024<br> <a href=https://doi.org/10.1109/IROS58592.2024.10802642 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2409.20038 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/prismatic-joint-opt/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=XTihjUsbkNw target='_blank'>[Video]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, K. Okada, M. Inaba<br>CubiX: Portable Wire-Driven Parallel Robot Connecting to and Utilizing the Environment, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 1296-1301, 2024, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2024)</font></b>, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2024)</font></b><br> <a href=https://doi.org/10.1109/IROS58592.2024.10802299 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.05933 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/cubix-hardware/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=R5ZrzMPEFZs target='_blank'>[Video]</a></li>
<li>S. Yoshimura, A. Miki, K. Miyama, Y. Sahara, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Patterned Structure Muscle : Arbitrary Shaped Wire-Driven Artificial Muscle Utilizing Anisotropic Flexible Structure for Musculoskeletal Robots, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 13930-13937, 2024, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2024)</font></b>, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2024)</font></b><br> <a href=https://doi.org/10.1109/IROS58592.2024.10801899 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.07682 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Sahara, A. Miki, Y. Ribayashi, S. Yoshimura, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Construction of Musculoskeletal Simulation for Shoulder Complex with Ligaments and Its Validation via Model Predictive Control, in <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, pp. 327-333, 2024<br> <a href=https://doi.org/10.1109/IROS58592.2024.10802465 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.05931 target='_blank'>[Arxiv Link]</a> <a href=https://sahara-yuta.github.io/projects/shoulder-complex-simulation target='_blank'>[Project Page]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Robotic Constrained Imitation Learning for the Peg Transfer Task in Fundamentals of Laparoscopic Surgery, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 606-612, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610059 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.03440 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/fls-imitation/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=cg7bFTj_hPo target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Adaptive Whole-body Robotic Tool-use Learning on Low-rigidity Plastic-made Humanoids Using Vision and Tactile Sensors, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 583-589, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610913 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.04826 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/wholebody-tooluse/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=auCYNiMiXXE target='_blank'>[Video]</a></li>
<li>A. Tang, T. Hiraoka, N. Hiraoka, F. Shi, <b><u>K. Kawaharazuka</u></b>, K. Kojima, K. Okada, M. Inaba<br>HumanMimic: Learning Natural Locomotion and Transitions for Humanoid Robot via Wasserstein Adversarial Imitation, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 13107-13114, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10610449 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.14225 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=sdM11yHpzi8 target='_blank'>[Video]</a></li>
<li>K. Shirai, C. C. Beltran-Hernandez, M. Hamaya, A. Hashimoto, S. Tanaka, <b><u>K. Kawaharazuka</u></b>, K. Tanaka, Y. Ushiku, S. Mori<br>Vision-Language Interpreter for Robot Task Planning, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 2051-2058, 2024<br> <a href=https://doi.org/10.1109/ICRA57147.2024.10611112 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2311.00967 target='_blank'>[Arxiv Link]</a> <a href=https://kskshr.github.io/vilain/ target='_blank'>[Project Page]</a> <a href=https://github.com/omron-sinicx/vilain target='_blank'>[Source Code]</a></li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, in <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, pp. 6892-6903, 2024, <b><font color='red'>Best Conference Paper Award</font></b>, <b><font color='red'>Finalists of Best Paper Award in Robot Manipulation</font></b><br> <a href=https://doi.org/10.1109/ICRA57147.2024.10611477 target='_blank'>[Paper Link]</a> <a href=https://robotics-transformer-x.github.io/paper.pdf target='_blank'>[Arxiv Link]</a> <a href=https://robotics-transformer-x.github.io/ target='_blank'>[Project Page]</a></li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Body Design and Gait Generation of Chair-Type Asymmetrical Tripedal Low-rigidity Robot, in <i>2024 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2024</b>)</i>, pp. 593-600, 2024<br> <a href=https://doi.org/10.1109/RoboSoft60065.2024.10522029 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05932 target='_blank'>[Arxiv Link]</a> <a href=https://shin0805.github.io/chair-type-tripedal-robot/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=-f8LDlhmdBg target='_blank'>[Video]</a></li>
<li>A. Miki, Y. Sahara, K. Miyama, Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, S. Hasegawa, K. Okada, M. Inaba<br>Designing Fluid-Exuding Cartilage for Biomimetic Robots Mimicking Human Joint Lubrication Function, in <i>2024 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2024</b>)</i>, pp. 452-459, 2024<br> <a href=https://doi.org/10.1109/RoboSoft60065.2024.10521920 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.06740 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 458-465, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375211 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2303.05674 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, Y. Obinata, K. Okada, M. Inaba<br>Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via Large-Scale Vision-Language Model, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 452-457, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375239 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2312.07451 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=WIJLf-KmvM0 target='_blank'>[Video]</a></li>
<li>S. Yoshimura, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Optimization of Muscle Arrangement Extraction from Human Waist Structure for Biomimetic Humanoid Implementation, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 583-590, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375213 target='_blank'>[Paper Link]</a></li>
<li>Y. Ribayashi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Wire-Wound Muscle-Tendon Complex Drive and Its Application to a Two-Dimensional Robot Configuration, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 758-764, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375220 target='_blank'>[Paper Link]</a></li>
<li>S. Yuzaki, A. Miki, M. Bando, S. Yoshimura, T. Suzuki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Fusion of Body and Environment with Movable Carabiners for Wire-Driven Robots Toward Expansion of Physical Capabilities, in <i>2023 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2023</b>)</i>, pp. 679-685, 2023<br> <a href=https://doi.org/10.1109/Humanoids57100.2023.10375200 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Makabe, K. Okada, M. Inaba<br>Daily Assistive Modular Robot Design Based on Multi-Objective Black-Box Optimization, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 9970-9977, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10342041 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.14226 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/auto-modular-design/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=ztcq0P92mJI target='_blank'>[Video]</a></li>
<li>Y. Matsuura, <b><u>K. Kawaharazuka</u></b>, N. Hiraoka, K. Kojima, K. Okada, M. Inaba<br>Development of a Whole-Body Work Imitation Learning System by a Biped and Bi-Armed Humanoid, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 10374-10381, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10342502 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.15756 target='_blank'>[Arxiv Link]</a> <a href=https://haraduka.github.io/jaxon-tablis-imitation/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=RsoI0W8SPPA target='_blank'>[Video]</a></li>
<li>Y. Obinata, <b><u>K. Kawaharazuka</u></b>, N. Kanazawa, N. Yamaguchi, N. Tsukamoto, I. Yanokura, S. Kitagawa, K. Shinjo, K. Okada, M. Inaba<br>Semantic Scene Difference Detection in Daily Life Patroling by Mobile Robots Using Pre-Trained Large-Scale Vision-Language Model, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 3228-3233, 2023, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2023)</font></b>, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2023)</font></b><br> <a href=https://doi.org/10.1109/IROS55552.2023.10342467 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.16552 target='_blank'>[Arxiv Link]</a></li>
<li>K. Miyama, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Five-Fingerd Biomimetic Soft Robotic Hand by 3D Printing the Skin and Skeleton As One Unit, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 6624-6630, 2023, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2023)</font></b><br> <a href=https://doi.org/10.1109/IROS55552.2023.10341570 target='_blank'>[Paper Link]</a></li>
<li>S. Yoshimura, T. Suzuki, M. Bando, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Design Method of a Kangaroo Robot with High Power Legs and an Articulated Soft Tail, in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2023</b>)</i>, pp. 6631-6638, 2023<br> <a href=https://doi.org/10.1109/IROS55552.2023.10341756 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.07742 target='_blank'>[Arxiv Link]</a></li>
<li>A. Ichikura, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>A Method for Selecting Scenes and Emotion-Based Descriptions for a Robot's Diary, in <i>32nd IEEE International Conference on Robot and Human Interactive Communication (<b>ROMAN2023</b>)</i>, pp. 1683-1688, 2023<br> <a href=https://doi.org/10.1109/RO-MAN57019.2023.10309432 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01951 target='_blank'>[Arxiv Link]</a></li>
<li>A. Miki, <b><u>K. Kawaharazuka</u></b>, M. Bando, K. Okada, K. Kawasaki, M. Inaba<br>System Architecture and Real-World Task Realization of Musculoskeletal Wheeled Robot Musashi-W with Various Hardware Components, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 109-122, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_9 target='_blank'>[Paper Link]</a></li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, S. Hasegawa, K. Okada, M. Inaba<br>Workspace-Based Precision Grasp Pose Generator for Multi-Fingered Robotic Hands, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 379-392, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_29 target='_blank'>[Paper Link]</a></li>
<li>N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, Y. Obinata, K. Okada, M. Inaba<br>Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 547-560, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44851-5_42 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01528 target='_blank'>[Arxiv Link]</a></li>
<li>A. Ichikura, <b><u>K. Kawaharazuka</u></b>, Y. Obinata,, K. Shinjo, K. Okada, M. Inaba<br>Automatic Diary Generation System Including Information on Joint Experiences between Humans and Robots, in <i>18th International Conference on Intelligent Autonomous Systems (<b>IAS2023</b>)</i>, pp. 399-412, 2023<br> <a href=https://doi.org/10.1007/978-3-031-44981-9_33 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2309.01948 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>VQA-based Robotic State Recognition Optimized with Genetic Algorithm, in <i>2023 IEEE International Conference on Robotics and Automation (<b>ICRA2023</b>)</i>, pp. 8306-8311, 2023<br> <a href=https://doi.org/10.1109/ICRA48891.2023.10160390 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2303.05052 target='_blank'>[Arxiv Link]</a></li>
<li>H. Sato, <b><u>K. Kawaharazuka</u></b>, T. Makabe, K. Okada, M. Inaba<br>Online Estimation of Self-Body Deflection with Various Sensor Data Based on Directional Statistics, in <i>2023 IEEE/SICE International Symposium on System Integration (<b>SII2023</b>)</i>, pp. 1-8, 2023<br> <a href=https://doi.org/10.1109/SII55687.2023.10039450 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2306.03616 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, T. Suzuki, Y. Ribayashi, Y. Toshimitsu, Y. Nagamatsu, K. Okada, M. Inaba<br>Hardware Design and Learning-Based Software Architecture of Musculoskeletal Wheeled Robot Musashi-W for Real-World Applications, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 413-419, 2022, <b><font color='red'>Best Interactive Paper Award Finalist</font></b><br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000123 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11729 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=VhBfpYB-QxI target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Suzuki, K. Okada, M. Inaba<br>Continuous Jumping of a Parallel Wire-Driven Monopedal Robot RAMIEL Using Reinforcement Learning, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 759-764, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000182 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11205 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=y8YqJt3HZvY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Kanazawa, K. Okada, M. Inaba<br>Learning-Based Wiping Behavior of Low-Rigidity Robots Considering Various Surface Materials and Task Definitions, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 919-924, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000172 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.11198 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=N47IXZ6Q0io target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, D. Kusuyama, A. Miki, K. Shinjo, M. Bando, T. Suzuki, Y. Kojio, K. Okada, M. Inaba<br>Design of Robot Foot with Outer Edge Measurement Structure and Chair Rotation Motion by Friction Control, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 314-321, 2022, (<b>Top 7 Best Oral Paper Presentation</b>)<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000127 target='_blank'>[Paper Link]</a></li>
<li>K. Miyama, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, N. Yamaguchi, K. Okada, M. Inaba<br>Design of a Five-Fingered Hand with Full-Fingered Tactile Sensors Using Conductive Filaments and Its Application to Bending after Insertion Motion, in <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, pp. 780-785, 2022<br> <a href=https://doi.org/10.1109/Humanoids53995.2022.10000181 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.00732 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Realization of Seated Walk by a Musculoskeletal Humanoid with Buttock-Contact Sensors From Human Constrained Teaching, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5774-5780, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9982103 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.00892 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=r1vhMWBkiHU target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Online Learning Feedback Control Considering Hysteresis for Musculoskeletal Structures, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5767-5773, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981052 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11808 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=8exSF0LB4t8 target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Ribayashi, A. Miki, Y. Toshimitsu, T. Suzuki, K. Okada, M. Inaba<br>Learning of Balance Controller Considering Changes in Body State for Musculoskeletal Humanoids, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5809-5816, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981051 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2405.11803 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=OZh__9a4OTQ target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, A. Miki, K. Okada, M. Inaba<br>DIJE: Dense Image Jacobian Estimation for Robust Robotic Self-Recognition and Visual Servoing, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 2219-2226, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981868 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=7wFUZGFtjLE target='_blank'>[Video]</a></li>
<li>Y. Ribayashi, <b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, D. Kusuyama, A. Miki, K. Shinjo, M. Bando, T. Suzuki, Y. Kojio, K. Okada, M. Inaba<br>Imitation Behavior of the Outer Edge of the Foot by Humanoids Using a Simplified Contact State Representation, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 4243-4249, 2022<br> <a href=https://doi.org/10.1109/IROS47612.2022.9981673 target='_blank'>[Paper Link]</a></li>
<li>T. Suzuki, Y. Toshimitsu, Y. Nagamatsu, <b><u>K. Kawaharazuka</u></b>, A. Miki, Y. Ribayashi, M. Bando, K. Kojima, Y. Kakiuchi, K. Okada, M. Inaba<br>RAMIEL: A Parallel-Wire Driven Monopedal Robot for High and Continuous Jumping, in <i>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2022</b>)</i>, pp. 5017-5024, 2022, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2022)</font></b><br> <a href=https://doi.org/10.1109/IROS47612.2022.9981963 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2311.04573 target='_blank'>[Arxiv Link]</a> <a href=https://tenrobo18.github.io/ramiel-iros2022/ target='_blank'>[Project Page]</a> <a href=https://www.youtube.com/watch?v=dPmIMdITTwM target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Shinjo, Y. Kawamura, K. Okada, M. Inaba<br>Environmentally Adaptive Control Including Variance Minimization Using Stochastic Predictive Network with Parametric Bias: Application to Mobile Robots, in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2021</b>)</i>, pp. 8381-8387, 2021<br> <a href=https://doi.org/10.1109/IROS51168.2021.9636416 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.08275 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=4LzAM_bGBAI target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Toshimitsu, M. Nishiura, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture, in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2021</b>)</i>, pp. 3204-3210, 2021<br> <a href=https://doi.org/10.1109/IROS51168.2021.9636845 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2502.12803 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=kSkTid0RSQg target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, N. Hiraoka, Y. Koga, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Online Learning of Danger Avoidance for Complex Structures of Musculoskeletal Humanoids and Its Applications, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 349-355, 2021<br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555792 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, M. Nishiura, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Motion Modification Method of Musculoskeletal Humanoids by Human Teaching Using Muscle-Based Compensation Control, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 83-89, 2021<br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555772 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2411.06323 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=e3EBWVx7z90 target='_blank'>[Video]</a></li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Development of Musculoskeletal Legs with Planar Interskeletal Structures to Realize Human Comparable Moving Function, in <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, pp. 17-24, 2021, <b><font color='red'>Best Oral Paper Award</font></b>, <b><font color='red'>Finalists of Mike Stilman Paper Award</font></b><br> <a href=https://doi.org/10.1109/HUMANOIDS47582.2021.9555807 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.00890 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=zF0YdU5bTbg target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Biomimetic Operational Space Control for Musculoskeletal Humanoid Optimizing across Muscle Activation and Joint Nullspace, in <i>2021 IEEE International Conference on Robotics and Automation (<b>ICRA2021</b>)</i>, pp. 1184-1190, 2021<br> <a href=https://doi.org/10.1109/ICRA48506.2021.9561919 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=vthQNaqoXuM target='_blank'>[Video]</a></li>
<li>S. Nakashima, <b><u>K. Kawaharazuka</u></b>, M. Nishiura, Y. Asano, Y. Kakiuchi, K. Okada, K. Kawasaki, M. Inaba<br>Restoring Force Design of Active Self-Healing Tension Transmission System and Application to Tendon-Driven Legged Robot, in <i>2021 IEEE International Conference on Robotics and Automation (<b>ICRA2021</b>)</i>, pp. 7033-7038, 2021<br> <a href=https://doi.org/10.1109/ICRA48506.2021.9561531 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, M. Nishiura, S. Nakashima, Y. Toshimitsu, Y. Omura, Y. Koga, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Stability Recognition with Active Vibration for Bracing Behaviors and Motion Extensions Using Environment in Musculoskeletal Humanoids, in <i>2021 IEEE International Conference on Soft Robotics (<b>ROBOSOFT2021</b>)</i>, pp. 126-133, 2021<br> <a href=https://doi.org/10.1109/RoboSoft51838.2021.9479430 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-driven Structures of Musculoskeletal Humanoids, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 3585-3590, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341510 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2502.12808 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Koga, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 3598-3603, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341488 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2502.12811 target='_blank'>[Arxiv Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, C. Nabeshima<br>Tool Shape Optimization through Backpropagation of Neural Network, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 8387-8393, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9341583 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.12202 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=UjmdjYiUttA target='_blank'>[Video]</a></li>
<li>Y. Toshimitsu, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka M. Nishiura, Y. Koga, Y. Omura, M. Tomita, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Biomimetic Control Scheme for Musculoskeletal Humanoids Based on Motor Directional Tuning in the Brain, in <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2020</b>)</i>, pp. 7784-7791, 2020<br> <a href=https://doi.org/10.1109/IROS45743.2020.9340896 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=fbEi3qmh8pw target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the Predictive Model of Sensor State Transition, in <i>2020 IEEE International Conference on Robotics and Automation (<b>ICRA2020</b>)</i>, pp. 4572-4578, 2020<br> <a href=https://doi.org/10.1109/ICRA40945.2020.9197188 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2406.17136 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=JSK6ljJSIpQ target='_blank'>[Video]</a></li>
<li>T. Nishio, M. Zhao, F. Shi, T. Anzai, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Stable Control in Climbing and Descending Flight under Upper Walls using Ceiling Effect Model based on Aerodynamics, in <i>2020 IEEE International Conference on Robotics and Automation (<b>ICRA2020</b>)</i>, pp. 172-178, 2020<br> <a href=https://doi.org/10.1109/ICRA40945.2020.9197137 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, K. Tsuzuki, M. Onitsuka, Y. Nagamatsu, K. Shinjo, T. Makabe, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Component Modularized Design of Musculoskeletal Humanoid Platform Musashi to Investigate Learning Control Systems, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 7294-7301, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8968068 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2410.22000 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=t2JZraUT3lY target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, M. Onitsuka, K. Shinjo, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Task-specific Self-body Controller Acquisition by Musculoskeletal Humanoids: Application to Pedal Control in Autonomous Driving, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 813-818, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967910 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.08270 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=FPwRuyzzdEc target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, C. Nabeshima<br>Dynamic Task Control Method of a Flexible Manipulator Using a Deep Recurrent Neural Network, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 7689-7695, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967923 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2407.12201 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=WwCNPGUFjho target='_blank'>[Video]</a></li>
<li>K. Shinjo, <b><u>K. Kawaharazuka</u></b>, Y. Asano, S. Nakashima, S. Makino, M. Onitsuka, K. Tsuzuki, K. Okada, K. Kawasaki, M. Inaba<br>Foot with a Core-shell Structural Six-axis Force Sensor for Pedal Depressing and Recovering from Foot Slipping during Pedal Pushing Toward Autonomous Driving by Humanoids, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 3049-3054, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8967519 target='_blank'>[Paper Link]</a></li>
<li>S. Nakashima, T. Shirai, <b><u>K. Kawaharazuka</u></b>, Y. Asano Y. Kakiuchi, K. Okada, M. Inaba<br>An Approach of Facilitated Investigation of Active Self-healing Tension Transmission System Oriented for Legged Robots, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 2567-2572, 2019, <b><font color='red'>SICE International Young Authors Award (SIYA-IROS2019)</font></b><br> <a href=https://doi.org/10.1109/IROS40897.2019.8967949 target='_blank'>[Paper Link]</a></li>
<li>T. Makabe, T. Shirai, Y. Nagamatsu, <b><u>K. Kawaharazuka</u></b>, S. Fumihito, K. Okada, M. Inaba<br>Development of Joint Module with Two-Speed Gear Transmission and Joint Lock Mechanism during Driving for Task Adaptable Robot, in <i>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2019</b>)</i>, pp. 5123-5130, 2019<br> <a href=https://doi.org/10.1109/IROS40897.2019.8968232 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, M. Onitsuka, Y. Koga, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Reflex-based Motion Strategy of Musculoskeletal Humanoids under Environmental Contact Using Muscle Relaxation Control, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 114-119, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9034994 target='_blank'>[Paper Link]</a></li>
<li>Y. Koga, <b><u>K. Kawaharazuka</u></b>, M. Onitsuka, T. Makabe, K. Tsuzuki, Y. Omura, Y. Asano, K. Okada, M. Inaba<br>Modification of Muscle Antagonistic Relations and Hand Trajectory on the Dynamic Motion of Musculoskeletal Humanoid, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 632-637, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9035012 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2412.00737 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=XDGOLhZcUHg target='_blank'>[Video]</a></li>
<li>Y. Asano, S. Nakashima, I. Yanokura, M. Onitsuka, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Koga, Y. Omura, K. Okada, M. Inaba<br>Ankle-Hip-Stepping Stabilizer on Tendon-Driven Humanoid Kengoro by Integration of Muscle-Joint-Work Space Controllers for Knee-Stretched Humanoid Balance, in <i>2019 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2019</b>)</i>, pp. 397-402, 2019<br> <a href=https://doi.org/10.1109/Humanoids43949.2019.9035008 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Ogawa, J. Tamura, C. Nabeshima<br>Dynamic Manipulation of Flexible Objects with Torque Sequence Using a Deep Neural Network, in <i>2019 IEEE International Conference on Robotics and Automation (<b>ICRA2019</b>)</i>, pp. 2139-2145, 2019<br> <a href=https://doi.org/10.1109/ICRA.2019.8793513 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/1901.10142 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=EuB-TWygkNA target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, T. Makabe, S. Makino, K. Tsuzuki, Y. Nagamatsu, Y. Asano, T. Shirai, F. Sugai, K. Okada, K. Kawasaki, M. Inaba<br>TWIMP: Two-Wheel Inverted Musculoskeletal Pendulum as a Learning Control Platform in the Real World with Environmental Physical Contact, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 784-790, 2018, (<b>The first two authors contributed equally to this work</b>)<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8624923 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.14080 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=6Y4FpXx6axQ target='_blank'>[Video]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>A Method of Joint Angle Estimation Using Only Relative Changes in Muscle Lengths for Tendon-driven Humanoids with Complex Musculoskeletal Structures, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 1128-1135, 2018<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8625002 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.14100 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=J0q9q7tWJDU target='_blank'>[Video]</a></li>
<li>T. Makabe, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, K. Wada, S. Makino, M. Kawamura, A. Fujii, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Development of Movable Binocular High-Resolution Eye-Camera Unit for Humanoid and the Evaluation of Looking Around Fixation Control and Object Recognition, in <i>2018 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2018</b>)</i>, pp. 840-845, 2018<br> <a href=https://doi.org/10.1109/HUMANOIDS.2018.8625072 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, A. Fujii, Y. Asano, K. Okada, M. Inaba<br>Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids, in <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, pp. 1711-1717, 2018<br> <a href=https://doi.org/10.1109/IROS.2018.8593428 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2404.05286 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=jdYbMOj84TA target='_blank'>[Video]</a></li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, A. Fujii, T. Makabe, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints, in <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, pp. 4562-4567, 2018, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2018)</font></b>, <b><font color='red'>IROS ICROS Best Application Paper Award 2018 Finalists</font></b><br> <a href=https://doi.org/10.1109/IROS.2018.8594316 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.17452 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=HRwTFfnlCAs target='_blank'>[Video]</a></li>
<li>A. Fujii, S. Nakashima, M. Kawamura, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Development and Functional Evaluation of a Deformable Membrane Capsule for an Open Ball Glenohumeral Joint, in <i>2018 IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics (<b>BIOROB2018</b>)</i>, pp. 853-858, 2018<br> <a href=https://doi.org/10.1109/BIOROB.2018.8488005 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, S. Makino, M. Kawamura, Y. Asano, Y. Kakiuchi, K. Okada, M. Inaba<br>Human Mimetic Forearm Design with Radioulnar Joint using Miniature Bone-muscle Modules and its Applications, in <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, pp. 4956-4962, 2017, <b><font color='red'>IEEE RAS Japan Joint Chapter Young Award (2017)</font></b><br> <a href=https://doi.org/10.1109/IROS.2017.8206377 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2408.09934 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=h1sEw56zCwo target='_blank'>[Video]</a></li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, Y. Asano, K. Okada, M. Inaba<br>High-power, flexible, robust hand: Development of musculoskeletal hand using machined springs and realization of self-weight supporting motion with humanoid, in <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, pp. 1187-1192, 2017<br> <a href=https://doi.org/10.1109/IROS.2017.8202291 target='_blank'>[Paper Link]</a> <a href=https://arxiv.org/abs/2403.17459 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=wDDwQoYPRbA target='_blank'>[Video]</a></li>
<li>Y. Asano, T. Kozuki, S. Ookubo, M. Kawamura, S. Nakashima, T. Katayama, Y. Iori, H. Toshinori, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Kakiuchi, K. Okada, M. Inaba<br>Human Mimetic Musculoskeletal Humanoid Kengoro toward Real World Physically Interactive Actions, in <i>2016 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2016</b>)</i>, pp. 876-883, 2016, <b><font color='red'>Best Interactive Paper Award Finalist</font></b><br> <a href=https://doi.org/10.1109/HUMANOIDS.2016.7803376 target='_blank'>[Paper Link]</a> <a href=https://www.youtube.com/watch?v=RA4u_9FLzso target='_blank'>[Video]</a></li>
</ol>
<h3> International Workshop, Extended Abstract, etc. </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, T. Matsushima, S. Kurita, C. Paxton, A. Zeng, T. Ogata, T. Taniguchi<br>Special issue on real-world robot applications of the foundation models, <i>Advanced Robotics (<b>AR</b>)</i>, vol. 38, no. 18, pp. 1231, 2024, (<b>Preface</b>)<br> <a href=https://doi.org/10.1080/01691864.2024.2408066 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada<br>Reflexive Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, 2024, <b><font color='red'>Excellent Practice Award</font></b>, (<b>Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects</b>)</li>
<li>S. Yoshimura, T. Suzuki, M. Bando, S. Yuzaki, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Development of a Kangaroo-inspired Robot with High-Power Legs and an Articulated Tail, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, 2024, (<b>Workshop on Bio-inspired, Biomimetics, and Biohybrid (Cyborg) Systems</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Neural Information Processing Systems (<b>NeurIPS2023</b>)</i>, 2023, (<b>6th Robot Learning Workshop: Pretraining, Fine-Tuning, and Generalization with Large Scale Models</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Conference on Robot Learning (<b>CoRL2023</b>)</i>, 2023, (<b>2nd Workshop on Language and Robot Learning: Language as Grounding</b>)</li>
<li>Open X-Embodiment Collaboration<br>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, <i>2023 Conference on Robot Learning (<b>CoRL2023</b>)</i>, 2023, (<b>Workshop on Towards Generalist Robots: Learning Paradigms for Scalable Skill Acquisition</b>)</li>
<li>Y. Ribayashi, K. Miyama, A. Miki, <b><u>K. Kawaharazuka</u></b>, K. Okada, K. Kawasaki, M. Inaba<br>Muscle-Tendon Complex-Inspired Deformable Exteriors as a Wire-Drive Extension, <i>11th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2023</b>)</i>, 2023<br> <a href=https://doi.org/10.18910/92308 target='_blank'>[Paper Link]</a></li>
<li><b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, S. Makino, Y. Asano, K. Okada, M. Inaba<br>Modeling and Online Learning of Musculoskeletal Intersensory Networks for Static Controls of Tendon-driven Humanoids, <i>9th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2019</b>)</i>, 2019, <b><font color='red'>Company of Biologists Early Career Researcher Grant (500 GBP)</font></b><br> <a href=https://doi.org/10.5075/epfl-BIOROB-AMAM2019-11 target='_blank'>[Paper Link]</a></li>
</ol>
<h3> arXiv </h3>
<ol>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, K. Okada, M. Inaba<br>Binary State Recognition by Robots using Visual Question Answering of Pre-Trained Vision-Language Model, arXiv preprint arXiv:2310.16405, 2023<br> <a href=https://arxiv.org/abs/2310.16405 target='_blank'>[Arxiv Link]</a></li>
<li>Y. Obinata, N. Kanazawa, <b><u>K. Kawaharazuka</u></b>, I. Yanokura, S. Kim, K. Okada, M. Inaba<br>Foundation Model based Open Vocabulary Task Planning and Executive System for General Purpose Service Robots, arXiv preprint arXiv:2308.03357, 2023<br> <a href=https://arxiv.org/abs/2308.03357 target='_blank'>[Arxiv Link]</a> <a href=https://www.youtube.com/watch?v=fiN4Zibk6Sg target='_blank'>[Video]</a></li>
</ol>
<h3> Domestic Journal Papers </h3>
<ol>
<li>ÂêâÈáé Âπ∏‰∏ÄÈÉé, Ë∞∑Âè£ Âø†Â§ß, ÊåÅÊ©ã Â§ßÂú∞, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùæÂ∂ã ÈÅî‰πü, ÂìÅÂ∑ù ÊîøÂ§™Êúó, Â∞èÊûó ‰∏ÄÈÉé<br>NLP2024 ‰ΩµË®≠„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„Éó„ÄåÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÅÆÂÆü‰∏ñÁïåÂøúÁî®„Äç, <i>Ëá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöË™å (<b>NLP</b>)</i>, vol. 31, no. 2, pp. 809-815, 2024<br> <a href=https://doi.org/10.5715/jnlp.31.809 target='_blank'>[Paper Link]</a></li>
<li>Êñ∞Âüé ÂÖâÊ®π, Â§ßÊó•Êñπ ÊÖ∂Ê®π, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„É≠„Éú„ÉÉ„Éà„ÅÆÈöéÂ±§ÁßªÂãï„ÅÆ„Åü„ÇÅ„ÅÆ„Éû„É´„ÉÅ„Çª„É≥„Çµ„ÉªIoT„Çπ„Ç§„ÉÉ„ÉÅ„ÇíÁî®„ÅÑ„ÅüÁ∞°ÊòìÂèñ‰ªòÂèØËÉΩ„Å™„Ç®„É¨„Éô„Éº„ÇøÁä∂ÊÖãË™çË≠ò„ÉªÊìç‰Ωú„Ç∑„Çπ„ÉÜ„É†, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 43, no. 2, pp. 189-197, 2025<br> <a href=https://doi.org/10.7210/jrsj.43.189 target='_blank'>[Paper Link]</a></li>
<li>‰∏âÊú® Á´†ÂØõ,  Ê∞∏Êùæ Á•êÂº•, ÊùøÊù± Ê≠£Á•ê, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Âπ≥Â≤° Áõ¥Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>È´òÂøúÁ≠îÊÄß„ÇíÂÇô„ÅàÂ§öÊßò„Å™„É≠„Éú„ÉÉ„Éà„ÅÆÊâ±„ÅÑ„ÇíÂèØËÉΩ„Å®„Åô„Çã„Éè„Éº„Éâ„Ç¶„Çß„Ç¢ÊäΩË±°Âåñ„Éá„Éê„Ç§„ÇπÂà∂Âæ°„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÈñãÁô∫, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 43, no. 1, pp. 75-86, 2024<br> <a href=https://doi.org/10.7210/jrsj.43.75 target='_blank'>[Paper Link]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ßË¶èÊ®°Ë¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å®ÈÅ∫‰ºùÁöÑ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´Âü∫„Å•„Åè„É≠„Éú„ÉÉ„Éà„ÅÆ„Åü„ÇÅ„ÅÆÁä∂ÊÖãË™çË≠ò, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 259-265, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.259 target='_blank'>[Paper Link]</a></li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Éë„É©„É¨„É´„ÉØ„Ç§„É§ËÑö„ÅÆË∑≥Ë∫çÊÄßËÉΩ„Å´Èñ¢„Åô„ÇãÂäõÂ≠¶„É¢„Éá„É´„Å´Âü∫„Å•„ÅèÊ§úË®é„Å®ÂÆüÊ©ü„Å´„Åä„Åë„ÇãÊ§úË®º, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 274-282, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.274 target='_blank'>[Paper Link]</a></li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÊñôÁêÜ„É¨„Ç∑„ÉîË®òËø∞Ëß£Êûê„Å®Ë¶ñË¶ö - Ë®ÄË™û„É¢„Éá„É´„ÅÆÊôÇÁ≥ªÂàóÂà©Áî®„Å´„Çà„ÇãÈ£üÊùêÁä∂ÊÖãÂ§âÂåñË™çË≠ò„Å´Âü∫„Å•„Åè„É≠„Éú„ÉÉ„Éà„ÅÆË™øÁêÜ‰ΩúÊ•≠ÂÆüË°å, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 42, no. 3, pp. 266-273, 2024<br> <a href=https://doi.org/10.7210/jrsj.42.266 target='_blank'>[Paper Link]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>ÊÉÖÂ†±ÂåñË∫´‰Ωì„ÅÆÂ≠¶ÁøíÁêÜË´ñ„Å´Âü∫„Å•„ÅèÊàêÈï∑„É≠„Éú„ÉÉ„Éà„ÅÆÈù©Êñ∞„Å®ÂâµÊàê, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 41, no. 8, pp. 669-672, 2023, (<b>Ëß£Ë™¨Ë®ò‰∫ã</b>)<br> <a href=https://doi.org/10.7210/jrsj.41.669 target='_blank'>[Paper Link]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„Éë„É©„É°„Éà„É™„ÉÉ„ÇØ„Éê„Ç§„Ç¢„Çπ„ÇíÂê´„ÇÄÊ∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 40, no. 9, pp. 784-789, 2022, (<b>Ëß£Ë™¨Ë®ò‰∫ã</b>)<br> <a href=https://doi.org/10.7210/jrsj.40.784 target='_blank'>[Paper Link]</a></li>
<li>ÊµÖÈáé ÊÇ†Á¥Ä, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê∞∏Êùæ Á•êÂº•, Âè§Ë≥Ä ÊÇ†Áü¢, Â§ßÊùë Êüö‰ªã, ÁúüÂ£Å ‰Ωë, Ëó§‰∫ï Á∂∫È¶ô, ‰∏≠Â≥∂ ÊÖé‰ªã, Êñ∞Âüé ÂÖâÊ®π, Ë•øÊµ¶ Â≠¶, Âà©ÂÖâ Ê≥∞Âæ≥, ÂÜ®Áî∞ Âππ, Â≤°Áî∞ ÊÖß, Ê∏ÖÊ∞¥ Êô∫Âìâ, ËøëËó§ Ê∑≥, Â∑ùÂ¥é ÂÆèÊ≤ª, Ë±äÂ≥∂ Êµ©‰∫å, Á®≤Ëëâ ÈõÖÂπ∏<br>„É≠„Éú„ÉÉ„ÉàÊäÄË°ì„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Âêë„Åë„ÅüËÖ±ÈßÜÂãï„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„ÇãËá™ÂãïËªäÈÅãËª¢„ÅÆÂÆüË®ºÂÆüÈ®ì„Å®Áæ©Ë∂≥ÈñãÁô∫„Å∏„ÅÆÂ±ïÈñã --ËÖ±ÈßÜÂãï„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„ÇãËá™ÂãïËªäÈÅãËª¢„ÇíÈÄö„Åò„ÅüÁî£ÂÆòÂ≠¶„ÅÆÁ§æ‰ºöÈÄ£Êê∫Ê¥ªÂãï--, <i>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöË™å (<b>JRSJ</b>)</i>, vol. 40, no. 3, pp. 240-250, 2022<br> <a href=https://doi.org/10.7210/jrsj.40.240 target='_blank'>[Paper Link]</a></li>
</ol>
<h3> Domestic Conference Proceedings (Peer Reviewed) </h3>
<ol>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ë¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å®ÈÅ∫‰ºùÁöÑ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´Âü∫„Å•„Åè„É≠„Éú„ÉÉ„Éà„ÅÆ„Åü„ÇÅ„ÅÆÈõ¢Êï£„ÉªÈÄ£Á∂öÁä∂ÊÖãË™çË≠ò, in <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, pp. 34-35, 2023</li>
<li>Â§ßÊó•Êñπ ÊÖ∂Ê®π, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â±±Âè£ Áõ¥‰πü, Â°öÊú¨ Áõ¥‰∫∫, Áü¢ÈáéÂÄâ ‰ºäÁπî, ÂåóÂ∑ù ÊôãÂêæ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫ãÂâçÂ≠¶ÁøíÊ∏à„ÅøË¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„ÇíÁî®„ÅÑ„ÅüÂ∑°Âõû„É≠„Éú„ÉÉ„Éà„ÅÆÈï∑ÊúüË®òÊÜ∂„Å´Âü∫„Å•„ÅèÊó•Â∏∏Áí∞Â¢É„ÅÆÁä∂Ê≥ÅÂàÜÈ°û, in <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, pp. 36-37, 2023</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ë™øÁêÜÊîØÊè¥„É≠„Éú„ÉÉ„Éà„ÅÆË¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´ÊôÇÁ≥ªÂàóÂà©Áî®„Å´„Çà„Çã„É¨„Ç∑„ÉîË®òËø∞„Åã„Çâ„ÅÆÈ£üÊùêÁä∂ÊÖãÂ§âÂåñË™çË≠ò, in <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, pp. 66-67, 2023, <b><font color='red'>„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢Á†îÁ©∂Â•®Âä±Ë≥û</font></b></li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Éë„É©„É¨„É´„ÉØ„Ç§„É§‰∏ÄÊú¨ËÑö„É≠„Éú„ÉÉ„Éà„ÅÆË∑≥Ë∫ç„É¢„Éá„É´„Å®Ë®≠Ë®àÊ≥ï, in <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, pp. 50-51, 2023</li>
<li>Ê∑±Â±± ÂíåÊµ©, ÊùéÊûó ÂòâÂÖÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>È™®Ê†ºË°®ÁöÆ„Çí‰∏Ä‰Ωì„Å´3D„Éó„É™„É≥„Éà„Åó„Åü„É≠„Éú„ÉÉ„Éà„Éè„É≥„Éâ„ÅÆÈñãÁô∫, in <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, pp. 293-294, 2023</li>
<li>‰∏âÊú® Á´†ÂØõ, ÊùøÊù± Ê≠£Á•ê, Ê∞∏Êùæ Á•êÂº•, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Âπ≥Â≤° Áõ¥Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§öÁ®Æ„É≠„Éú„ÉÉ„Éà„ÅÆÊâ±„ÅÑ„Å®È´òÂøúÁ≠îÊÄß„Çí‰∏°Á´ã„Åó„Åü„Éè„Éº„Éâ„Ç¶„Çß„Ç¢ÊäΩË±°Âåñ„Éá„Éê„Ç§„ÇπÂà∂Âæ°„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÈñãÁô∫, in <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, pp. 239-240, 2023, <b><font color='red'>Á¨¨3ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ÂÑ™ÁßÄÁ†îÁ©∂„ÉªÊäÄË°ìË≥û</font></b></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Â∑ùÊùë Â∞ÜÁü¢, Ëó§‰∫ï Á∂∫È¶ô, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãË∫´‰ΩìÁµÑÁπî„ÅÆÊüîËªüÊÄß„Å´„Çà„ÇãÁ≠ãÁµåË∑ØÂ§âÂåñ„ÇíËÄÉÊÖÆ„Åó„ÅüÈÄêÊ¨°ÁöÑËá™Â∑±Ë∫´‰ΩìÂÉè„ÅÆÁç≤Âæó, in <i>Á¨¨23Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM18J</b>)</i>, pp. 306-312, 2018</li>
</ol>
<h3> Domestic Conference Proceedings (No Reviewed) </h3>
<ol>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„Ç™„Éº„Éó„É≥„Éè„Éº„Éâ„Ç¶„Çß„Ç¢„Å®Â≠¶ÁøíÂà∂Âæ° - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´2025, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 3M1-01, 2025</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Êæ§Âè£ ÊòáÂêæ, Â≤©Áî∞ Ê≠©, Á±≥Áî∞ ÊÖ∂Â§™, Èà¥Êú® Â§©È¶¨, Â≤°Áî∞ ÊÖß<br>MEVITA: E-Commerce„Å´„Çà„ÇäË™∞„Åß„ÇÇÁ∞°Âçò„Å´ÊßãÁØâÂèØËÉΩ„Å™„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ‰∫åË∂≥Ê≠©Ë°å„É≠„Éú„ÉÉ„Éà, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 3M1-05, 2025</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, Ë¥æ Êµ©ÂÆá, Â≤°Áî∞ ÊÖß<br>Â§öÁõÆÁöÑ„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÊúÄÈÅ©Âåñ„Å®Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„Çí‰ΩµÁî®„Åó„ÅüÂäπÁéáÁöÑ„Å™„É≠„Éú„ÉÉ„ÉàË∫´‰ΩìË®≠Ë®à, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1M5-01, 2025</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùæÂ∂ã ÈÅî‰πü, ÂÆÆÊæ§ ÂíåË≤¥<br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´2025 (1), in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1M1-01, 2025</li>
<li>ÊùæÂ∂ã ÈÅî‰πü, ÂÆÆÊæ§ ÂíåË≤¥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´2025 (2), in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1M1-02, 2025</li>
<li>ÂÆÆÊæ§ ÂíåË≤¥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùæÂ∂ã ÈÅî‰πü<br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´2025 (3), in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1M1-03, 2025</li>
<li>ÊúçÈÉ® È´òÊãì, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, Á±≥Áî∞ ÊÖ∂Â§™, Â≤°Áî∞ ÊÖß<br>ÈÅ†Èöî„ÉØ„Ç§„É§ÈßÜÂãïÂûãÁßªÂãï‰ΩúÊ•≠„É≠„Éú„ÉÉ„ÉàREWWARM„ÅÆÁâπÊÄßË©ï‰æ°„Å®Âà∂Âæ°, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1H3-01, 2025</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>ÈöéÂ±§ÁöÑ„Ç§„É≥„Éï„Ç£„É´ÊßãÈÄ†„ÇíÊúâ„Åô„Çã„Éû„É´„ÉÅ„Éû„ÉÜ„É™„Ç¢„É´3D„Éó„É™„É≥„ÉàÂúßÂäõ„Çª„É≥„Çµ„ÅÆÈñãÁô∫, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1P3-01, 2025</li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>„ÉØ„Ç§„É§Âπ≤Ê∏âÈßÜÂãï„Éû„Éã„É•„Éî„É¨„Éº„Çø„ÅÆÂèóÂãï„Éó„Éº„É™„Å´„Åä„Åë„ÇãÂºµÂäõÊêçÂ§±„ÅÆË£úÂÑü, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1P3-02, 2025</li>
<li>ÂãáÂ¥é È¢ØÂ§™, ‰∫ï‰∏ä ‰ø°Â§öÈÉé, Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>„ÉØ„Ç§„É§ÈßÜÂãïÁ©∫‰∏≠ÁßªÂãï„É≠„Éú„ÉÉ„ÉàCALVADOS„ÅÆ„Éâ„É≠„Éº„É≥„Å®„ÅÆÈÄ£Êê∫„Å´„Çà„ÇãÈöúÂÆ≥Áâ©ÂõûÈÅøË°åÂãï„ÅÆÂÆüÁèæ, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 1R3-06, 2025</li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™,, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Áí∞Â¢ÉÊé•Á∂öÂèØËÉΩ„Å™„ÉØ„Ç§„É§ÈßÜÂãï„É≠„Éú„ÉÉ„ÉàCubiX„ÅÆÈÅìÂÖ∑Âêà‰ΩìÂà©Áî®„Å´„Çà„ÇãÂ§öÁ®Æ„Çø„Çπ„ÇØÂÆüË°å, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 2E2-04, 2025</li>
<li>‰∏âÊú® Á´†ÂØõ, Èï∑Ë∞∑Â∑ù Â≥ª, ÊùéÊûó ÂòâÂÖÉ, ‰ΩêÂéü ‰æëÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>‰∫∫‰Ωì„ÅÆÊÑüË¶öÂô®ÈÖçÁΩÆ„ÇíÊ®°ÂÄ£„Åó„ÅüÁîü‰ΩìÊ®°ÂÄ£ÁöÆËÜö„ÅÆÊßãÊàê„Å®Ê§úË®º, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 2H2-02, 2025</li>
<li>ÊùéÊûó ÂòâÂÖÉ, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>Á≠ãËÖ±Ë§áÂêà‰ΩìÈßÜÂãï„ÇíÁî®„ÅÑ„ÅüË∫´‰ΩìÊßãÊàê„Å´„Åä„Åë„ÇãÂºæÊÄßÂà©Áî®Âãï‰Ωú, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 2H3-01, 2025</li>
<li>Â≤©Áî∞ Ê≠©, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Á±≥Áî∞ ÊÖ∂Â§™, Â≤°Áî∞ ÊÖß<br>Á≠âË∫´Â§ßÂèåËÖï„É≠„Éú„ÉÉ„Éà„ÅÆÂº∑ÂåñÂ≠¶Áøí„Å´„Çà„ÇãÈâÑÊ£íÂ§ßËªäËº™Âãï‰Ωú„ÅÆÁç≤Âæó, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 3M2-02, 2025</li>
<li>Á±≥Áî∞ ÊÖ∂Â§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊúçÈÉ® È´òÊãì, Â≤°Áî∞ ÊÖß<br>ËÖ∞Èñ¢ÁØÄ„ÇíÊúâ„Åô„ÇãÂõõËÑö„É≠„Éú„ÉÉ„ÉàKLEIYN„Å´„Çà„ÇãÂº∑ÂåñÂ≠¶Áøí„Å´Âü∫„Å•„ÅèÁ´ã„Å°‰∏ä„Åå„ÇäÂãï‰Ωú„Å®‰∫åË∂≥Ê≠©Ë°å„ÅÆÂÆüÁèæ, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 3M2-05, 2025</li>
<li>‰ΩêÂéü ‰æëÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>ËÖ±„ÅÆÂ∑ª„Åç‰ªò„Åç„Å®ÁµåË∑ØÁü≠Áµ°„ÇíËÄÉÊÖÆ„Åó„ÅüËÖ±ÈßÜÂãï„Ç¢„Éº„É†„ÅÆË®≠Ë®àÊúÄÈÅ©Âåñ, in <i>Á¨¨43ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ25J</b>)</i>, 3H3-01, 2025</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂõûËª¢Èñ¢ÁØÄ„Å®Áõ¥ÂãïÈñ¢ÁØÄ„ÇíÂê´„ÇÄ„É≠„Éú„ÉÉ„ÉàË®≠Ë®à„ÅÆÂ§öÁõÆÁöÑ„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÊúÄÈÅ©Âåñ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 1A1-Q01, 2025</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ‰∫ï‰∏ä ‰ø°Â§öÈÉé, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, Êæ§Âè£ ÊòáÂêæ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>MEVIUS: ÈáëÂ±ûÂàáÂâä„Å®ÊùøÈáëÊ∫∂Êé•„Å´„Çà„ÇäE-Commerce„ÅßÂÆπÊòì„Å´ÊßãÁØâÂèØËÉΩ„Å™4ËÑö„É≠„Éú„ÉÉ„Éà, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 2A2-A07, 2025</li>
<li>Á±≥Áî∞ ÊÖ∂Â§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÊúçÈÉ® È´òÊãì, Â≤°Áî∞ ÊÖß<br>ËÖ∞Èñ¢ÁØÄ„ÇíÊúâ„Åô„ÇãÂõõËÑö„É≠„Éú„ÉÉ„ÉàKLEIYN„ÅÆÂº∑ÂåñÂ≠¶Áøí„Å´Âü∫„Å•„ÅèÊ≠©Ë°å„Å®Â£ÅÁôª„ÇäÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 2A2-A08, 2025</li>
<li>ÊúçÈÉ® È´òÊãì, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, Á±≥Áî∞ ÊÖ∂Â§™, Â≤°Áî∞ ÊÖß<br>„ÉØ„Ç§„É§ÈÅ†ÈöîÈßÜÂãïÊ©üÊßã„Å®ÂèØÂ§âÂâõÊÄß‰º∏Á∏ÆÊ©üÊßã„ÇíÊúâ„Åô„ÇãÁ¥∞ÂæÑÁßªÂãï‰ΩúÊ•≠„É≠„Éú„ÉÉ„Éà„ÅÆË®≠Ë®àÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 1P1-E02, 2025</li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>Âº∑ÂåñÂ≠¶Áøí„Å´„Åä„Åë„Çãsim2real„Å´Âêë„Åë„Åü„Éë„É©„É¨„É´„ÉØ„Ç§„É§ÈßÜÂãï‰∏ÄÊú¨ËÑöË∑≥Ë∫ç„É≠„Éú„ÉÉ„ÉàRAMIEL2„ÅÆË®≠Ë®à, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 1P1-E03, 2025</li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Á±≥Áî∞ ÊÖ∂Â§™, ÂãáÂ¥é È¢ØÂ§™, ‰ΩêÂéü ‰æëÂ§™, Èà¥Êú® Â§©È¶¨, Â≤°Áî∞ ÊÖß<br>Áí∞Â¢ÉÊé•Á∂ö„ÉØ„Ç§„É§ÈßÜÂãï„É≠„Éú„ÉÉ„Éà„Å´„Åä„Åë„ÇãRGB-D„Ç´„É°„É©„ÇíÁî®„ÅÑ„Åü„Éû„É´„ÉÅÂ∞èÂûãÈ£õË°å„Ç¢„É≥„Ç´„ÉºÂà∂Âæ°, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 2A2-J03, 2025</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>Â∞éÈõªÊÄßËß¶Ë¶öÊßãÈÄ†„ÇíÊúâ„Åô„ÇãÊüîËªü„É©„ÉÜ„Ç£„ÇπÊßãÈÄ†Á≠ã„ÅßÊßãÊàê„Åï„Çå„Åü‰∫∫‰ΩìÊ®°ÂÄ£ËÑö„ÅÆËß¶Ë¶öÂèçÂøúÂãï‰Ωú, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 2A2-L05, 2025</li>
<li>ÂãáÂ¥é È¢ØÂ§™, ‰∫ï‰∏ä ‰ø°Â§öÈÉé, Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>„ÉØ„Ç§„É§ÈßÜÂãïÁ©∫‰∏≠ÁßªÂãï„É≠„Éú„ÉÉ„ÉàCALVADOS„ÅÆËªåÈÅìË®àÁîª„Å®„Ç∏„É£„É≥„ÉóÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 1A2-Q01, 2025</li>
<li>Xu Dong, Shun Hasegawa, Liqi Wu, <b><u>Kento Kawaharazuka</u></b>, Kunio Kojima, Kei Okada<br>A Dual-Track Pulley Actuation System for the Development of Lightweight and Compact Cable-driven Upper Limb Exosuits, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'25 (<b>ROBOMECH25J</b>)</i>, 2P2-K12, 2025</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â°öÊú¨ Áõ¥‰∫∫, Â≤°Áî∞ ÊÖß<br>ÂÖ®Â§©ÁêÉ„Ç´„É°„É©„Å®‰∫ãÂâçÂ≠¶ÁøíÊ∏à„ÅøË¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å´„Çà„Çã‰∫ãÂâçÁü•Ë≠ò„ÇíÂøÖË¶Å„Å®„Åó„Å™„ÅÑÂèçÂ∞ÑÂûãOpen Vocabulary Navigation, in <i>Á¨¨25ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI24J</b>)</i>, 1F6-04, 2024, <b><font color='red'>ÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, ÊùéÊûó ÂòâÂÖÉ, ‰ΩêÂéü ‰æëÂ§™, Â≤°Áî∞ ÊÖß<br>Áí∞Â¢ÉÊé•Á∂öÂèØËÉΩ„Å™„ÉØ„Ç§„É§ÈßÜÂãï„É≠„Éú„ÉÉ„ÉàCubiX„Å´„Çà„ÇãÁ≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„ÉâMusashi„ÅÆÈÅãÂãïËÉΩÂäõÊã°Âºµ, in <i>Á¨¨25ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI24J</b>)</i>, 3E5-08, 2024, <b><font color='red'>ÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß<br>Â§ßË¶èÊ®°Ë¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å´„Çà„ÇãË™øÁêÜ„É≠„Éú„ÉÉ„Éà„ÅÆÊôÇÁ≥ªÂàóÈ£üÊùêÁä∂ÊÖãË™çË≠ò, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 3D2-03, 2024</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùæÂ∂ã ÈÅî‰πü, ÂÆÆÊæ§ ÂíåË≤¥<br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´A, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 3D1-01, 2024<br> <a href=https://speakerdeck.com/haraduka/rsj2024-ji-pan-moderunoshi-robotutoying-yong-tiyutoriarua-he-yuan-zhong target='_blank'>[Slide]</a></li>
<li>ÊùæÂ∂ã ÈÅî‰πü, ÂÆÆÊæ§ ÂíåË≤¥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´B, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 3D1-02, 2024</li>
<li>ÂÆÆÊæ§ ÂíåË≤¥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùæÂ∂ã ÈÅî‰πü<br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´C, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 3D1-03, 2024</li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Áí∞Â¢ÉÊé•Á∂öÂèØËÉΩ„Å™„ÉØ„Ç§„É§ÈßÜÂãï„É≠„Éú„ÉÉ„ÉàCubiX„Å´„Çà„Çã2Âè∞„ÅÆÈ£õË°å„Ç¢„É≥„Ç´„Éº„ÇíÁî®„ÅÑ„ÅüÈõ≤Ê¢ØÂãï‰Ωú, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 1J5-03, 2024</li>
<li>Á±≥Áî∞ ÊÖ∂Â§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>ÂºæÊÄßËÑö„ÇíÁî®„ÅÑ„ÅüÂÖ≠ËÑö„É≠„Éú„ÉÉ„Éà„ÅÆË®≠Ë®à„Å®Âº∑ÂåñÂ≠¶Áøí„ÇíÁî®„ÅÑ„ÅüÂØæÈù¢Â£ÅÁôª„ÇäÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 2H1-05, 2024</li>
<li>ÊúçÈÉ® È´òÊãì, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>Ë∫´‰Ωì„Å´„Ç¢„ÇØ„ÉÅ„É•„Ç®„Éº„Çø„Çí‰∏ÄÂàáÂê´„Åæ„Å™„ÅÑËÖ±ÈßÜÂãïÊ≠©Ë°å„É≠„Éú„ÉÉ„Éà„ÅÆË®≠Ë®à„Å®Âà∂Âæ°, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 2H1-06, 2024</li>
<li>Â§ßÊó•Êñπ ÊÖ∂Ê®π, Ë≥à Êµ©ÂÆá, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â≤°Áî∞ ÊÖß<br>„ÅÇ„ÅÑ„Åæ„ÅÑ„Å™ÁîüÊ¥ªÊîØÊè¥„É≠„Éú„ÉÉ„ÉàÂãï‰ΩúË®òËø∞„ÅÆVLM„Å®AR„Éá„Éê„Ç§„Çπ„ÇíÁî®„ÅÑ„ÅüÊèêÁ§∫„Å®ÊåáÁ§∫„Å´„Çà„ÇãÂ±ïÈñã, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 3D3-02, 2024</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, Èà¥Êú® Â§©È¶¨, ‰ΩêÂéü ‰æëÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>ÊüîËªü„É©„ÉÜ„Ç£„ÇπÊßãÈÄ†„ÇíÊ¥ªÁî®„Åó„Åü„ÉØ„Ç§„É§ÈßÜÂãï‰∫∫Â∑•Á≠ãËÇâ„ÅßÊßãÊàê„Åï„Çå„Çã‰∫∫‰ΩìÊ®°ÂÄ£ËÑö„ÅÆË£Ω‰Ωú, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 3J1-05, 2024</li>
<li>ÂãáÂ¥é È¢ØÂ§™, Èà¥Êú® Â§©È¶¨, ‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß<br>„ÉØ„Ç§„É§ÈßÜÂãïÁ©∫‰∏≠ÁßªÂãï„É≠„Éú„ÉÉ„Éà„ÅÆÂú∞‰∏ä„Å®Á©∫‰∏≠„ÇíÂê´„ÇÄÂ§öÊßò„Å™„É≠„Ç≥„É¢„Éº„Ç∑„Éß„É≥, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ24J</b>)</i>, 1J5-04, 2024</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÂêâÊùë Èßø‰πã‰ªã, Èà¥Êú® Â§©È¶¨, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂèØÂ§âÁµåÁî±ÁÇπ„ÇíÂê´„ÇÄËÖ±ÈßÜÂãï„É≠„Éú„ÉÉ„Éà„ÅÆ„ÉØ„Ç§„É§ÈÖçÁΩÆË®≠Ë®àÊúÄÈÅ©Âåñ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 1A1-M02, 2024</li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Áí∞Â¢ÉÊé•Á∂öÂèØËÉΩ„Å™„ÉØ„Ç§„É§ÈßÜÂãï„É≠„Éú„ÉÉ„Éà„Å´„Çà„ÇãÁ©∫ÈñìÁßªÂãï„Å®Áâ©‰ΩìÊìç‰Ωú, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 1A1-M01, 2024</li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂèóÂãï3Ê¨°ÂÖÉ„ÉØ„Ç§„É§ÂãïÂäõ‰ºùÈÅîÊ©üÊßã„Å´„Åä„Åë„Çã‰ºùÈÅîÂäπÁéá„ÅÆËß£Êûê, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 1P1-O09, 2024, <b><font color='red'>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºöËã•ÊâãÂÑ™ÁßÄË¨õÊºî„Éï„Çß„É≠„ÉºË≥û</font></b></li>
<li>Êæ§Âè£ ÊòáÂêæ, Èà¥Êú® Â§©È¶¨, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÂãáÂ¥é È¢ØÂ§™, ÂêâÊùë Èßø‰πã‰ªã, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂäõÂº∑„Åï„Å®Âãï‰ΩúÁØÑÂõ≤„Çí‰∏°Á´ã„Åô„Çã„ÉØ„Ç§„É§ÈßÜÂãïÂûãË∫´‰ΩìÊã°Âºµ„Ç¶„Çß„Ç¢„É©„Éñ„É´„É≠„Éú„ÉÉ„Éà Vlimb „ÅÆË®≠Ë®àÊ≥ï, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 1P2-E06, 2024</li>
<li>ÂãáÂ¥é È¢ØÂ§™, Èà¥Êú® Â§©È¶¨, ÂêâÊùë Èßø‰πã‰ªã, Êæ§Âè£ ÊòáÂêæ, ‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ßÂá∫Âäõ„ÉØ„Ç§„É§Â∑ª„ÅçÂèñ„ÇäÊ©ü„Å®Â§ßÂæÑ„Çø„Ç§„É§„ÇíÊúâ„Åô„Çã„ÉØ„Ç§„É§ÈßÜÂãïÁ©∫‰∏≠ÁßªÂãï„É≠„Éú„ÉÉ„Éà„ÅÆÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 1P1-N09, 2024</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, ‰∏âÊú® Á´†ÂØõ, Ê∑±Â±± ÂíåÊµ©, ‰ΩêÂéü ‰æëÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÊüîËªü„É©„ÉÜ„Ç£„ÇπÊßãÈÄ†„ÇíÊ¥ªÁî®„Åó„Åü„ÉØ„Ç§„É§ÈßÜÂãï‰∫∫Â∑•Á≠ãËÇâ„Å®Á≠ãÈ™®Ê†º‰∏äËÖïÊßãÈÄ†„ÅÆÊßãÊàê, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I01, 2024</li>
<li>‰ΩêÂéü ‰æëÂ§™, ‰∏âÊú® Á´†ÂØõ, ÊùéÊûó ÂòâÂÖÉ, ÂêâÊùë Èßø‰πã‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Èù≠Â∏Ø„ÇíÂÇô„Åà„ÅüËÇ©Ë§áÂêà‰Ωì„ÅÆÁ≠ãÈ™®Ê†º„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„É¢„Éá„É´„ÅÆÊßãÊàêÊ≥ï„Å®Âà∂Âæ°, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I02, 2024</li>
<li>‰∏âÊú® Á´†ÂØõ, ‰ΩêÂéü ‰æëÂ§™, ÂêâÊùë Èßø‰πã‰ªã, ÊùéÊûó ÂòâÂÖÉ, ÂãáÂ¥é È¢ØÂ§™, Ê∑±Â±± ÂíåÊµ©, Èï∑Ë∞∑Â∑ù Â≥ª, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Èñ¢ÁØÄÊ∂≤ÂÜÖÂåÖÊ©üËÉΩ„Å®Èñ¢ÁØÄÂèóÂÆπÂô®Ê©üËÉΩ„ÇíÂÇô„Åà„Åü‰∫∫‰ΩìÊ®°ÂÄ£„É≠„Éú„ÉÉ„Éà„ÅÆÈñ¢ÁØÄÂåÖÊßãÊàêÊ≥ï, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 2P1-I03, 2024</li>
<li>ÊùéÊûó ÂòâÂÖÉ, ‰ΩêÂéü ‰æëÂ§™, Êæ§Âè£ ÊòáÂêæ, Ê∑±Â±± ÂíåÊµ©, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Ç¢„Éº„ÉÅÁä∂ÊßãÈÄ†Êùê„ÇíÁî®„ÅÑ„ÅüËÜ®Âºµ„Çí‰º¥„ÅÜÂ§âÂΩ¢„ÅÆË®≠Ë®à„Å®„ÉØ„Ç§„É§Â∑ªÂèñÂºè‰∫∫Â∑•Á≠ãËÇâ„Å∏„ÅÆÈÅ©Áî®, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 2P1-K10, 2024</li>
<li>ÂúíÁî∞ ÁæéÈÉ∑, Âîê ÂÆâÂçó, Áü≥Áî∞ ÂØõÂíå, Âπ≥Â≤° ÊãìÁúü, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â∞èÂ≥∂ ÈÇ¶Áîü, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Áõ∏ÂØæ„É≠„ÉÉ„Éâ‰ΩçÁΩÆÂßøÂã¢„Å´ÁùÄÁõÆ„Åó„ÅüÊ≠£‰∫åÂçÅÈù¢‰Ωì„ÉÜ„É≥„Çª„Ç∞„É™„ÉÜ„Ç£„É≠„Éú„ÉÉ„Éà„ÅÆËª¢„Åå„ÇäÈÅãÂãïÂà∂Âæ°ÊñπÁ≠ñ„ÅÆÂ≠¶ÁøíÁç≤Âæó, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'24 (<b>ROBOMECH24J</b>)</i>, 2P1-M10, 2024</li>
<li>Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â°öÊú¨ Áõ¥‰∫∫, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÁîüÊ¥ªÊîØÊè¥„É≠„Éú„ÉÉ„Éà„ÅÆÁèæÂ†¥Áü•Ë≠ò„Å´Âü∫„Å•„Åè„Ç™„É≥„É©„Ç§„É≥Âãï‰Ωú„Éó„É≠„Ç∞„É©„É†Â±ïÈñã, in <i>Á¨¨38Âõû‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºöÂÖ®ÂõΩÂ§ß‰ºö (<b>JSAI24J</b>)</i>, 4E1-GS-8-04, 2024</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Âü∫Áõ§„É¢„Éá„É´„Å®Âè§ÂÖ∏„Éó„É©„É≥„Éã„É≥„Ç∞„ÇíÁî®„ÅÑ„Åü„É¨„Ç∑„ÉîË®òËø∞„Åã„Çâ„ÅÆÂÆü‰∏ñÁïåË™øÁêÜË®àÁîªË™çË≠òÂÆüË°å„É≠„Éú„ÉÉ„Éà„Ç∑„Çπ„ÉÜ„É†, in <i>Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨30ÂõûÂπ¥Ê¨°Â§ß‰ºö (<b>NLP24J</b>)</i>, E1-3, 2024</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂØæË±°Áâ©Áä∂ÊÖã‰∏≠ÂøÉ„ÅÆË™øÁêÜË°åÂãïË®òËø∞„Å´Âü∫„Å•„Åè„É¨„Ç∑„Éî„Åã„Çâ„ÅÆÂçµÊñôÁêÜ„ÅÆÂÆü‰∏ñÁïåË™øÁêÜÂÆüË°å„É≠„Éú„ÉÉ„Éà„Ç∑„Çπ„ÉÜ„É†, in <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 3G2-08, 2023, <b><font color='red'>ÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li>Ê∑±Â±± ÂíåÊµ©, ÊùéÊûó ÂòâÂÖÉ, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â∞éÈõªÊÄß„Éï„Ç£„É©„É°„É≥„Éà„Å´„Çà„ÇãË°®ÁöÆÈ™®Ê†º‰∏Ä‰Ωì„É≠„Éú„ÉÉ„Éà„Éè„É≥„Éâ„ÅÆÊé•Ëß¶ÁÇπÊé®ÂÆö„Å´Èñ¢„Åô„ÇãÁ†îÁ©∂, in <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 2E3-08, 2023</li>
<li>‰∏âÊú® Á´†ÂØõ, ‰ΩêÂéü ‰æëÂ§™, Ê∑±Â±± ÂíåÊµ©, ÊùéÊûó ÂòâÂÖÉ, Èï∑Ë∞∑Â∑ù Â≥ª, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫∫„ÅÆÈñ¢ÁØÄÊΩ§ÊªëÊ©üËÉΩ„ÇíÊ®°„Åó„Åü‰∫∫‰ΩìÊ®°ÂÄ£„É≠„Éú„ÉÉ„Éà„ÅÆÊ∂≤‰ΩìÊª≤Âá∫ËªüÈ™®Ê©üÊßã„ÅÆÊßãÊàêÊ≥ï, in <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 2E3-07, 2023, <b><font color='red'>ÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li>ÊπØÁî∞ ‰∏ÄÊàê, Âîê ÂÆâÂçó, Â∞èÂ≥∂ ÈÇ¶Áîü, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠âË∫´Â§ß„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆÂÖ®Ë∫´ÈÅãÂãï„Å´„Åä„Åë„Çã„Ç®„Éç„É´„ÇÆ„ÉºÂäπÁéá„Å´ÁùÄÁõÆ„Åó„ÅüÈñ¢ÁØÄÈÅãÂãïÂçîË™øÊÄß„ÅÆËß£Êûê, in <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 3H2-06, 2023</li>
<li>Èáë Ê∑≥ÊöÅ, ÈáëÊ≤¢ Áõ¥ÊôÉ, Èï∑Ë∞∑Â∑ù Â≥ª, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÁîüÊ¥ªÊîØÊè¥„É≠„Éú„ÉÉ„Éà„ÇíÁî®„ÅÑ„ÅüË¶ñË¶ö„Å®ÂäõË¶ö„Å´Âü∫„Å•„ÅèÈ†≠È´™„Éñ„É©„ÉÉ„Ç∑„É≥„Ç∞Âãï‰ΩúÁîüÊàê„Å´Èñ¢„Åô„ÇãÁ†îÁ©∂, in <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 3F1-08, 2023</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùæÂ∂ã ÈÅî‰πü<br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´1, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1K3-01, 2023<br> <a href=https://speakerdeck.com/haraduka/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru1-ji-cun-noji-pan-moderuwoshi-robotutoniying-yong-surufang-fa target='_blank'>[Slide]</a></li>
<li>ÊùæÂ∂ã ÈÅî‰πü, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî® - „ÉÅ„É•„Éº„Éà„É™„Ç¢„É´2, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1K3-02, 2023<br> <a href=https://speakerdeck.com/tmats/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru2-shi-robotutoyong-noji-pan-moderuwozuo-tutehuo-yong-surufang-fa target='_blank'>[Slide]</a></li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ë™øÁêÜ„É≠„Éú„ÉÉ„Éà„ÅÆ„Åü„ÇÅ„ÅÆÂü∫Áõ§„É¢„Éá„É´Âà©Áî®„Å´„Çà„Çã„É¨„Ç∑„ÉîË®òËø∞„Åã„Çâ„ÅÆÂçµÊñôÁêÜ„ÅÆÈ£üÊùêÁä∂ÊÖãÂ§âÂåñË™çË≠ò„Å®Âãï‰Ωú„Ç∑„Éº„Ç±„É≥„ÇπÁîüÊàê, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1K3-03, 2023</li>
<li>Âëâ Áü•Âã≥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Áü≥Áî∞ ÂØõÂíå, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÆüÊôÇÈñìÁâ©‰ΩìËøΩË∑°„ÇíÁî®„ÅÑ„ÅüË¶ñË¶öÁöÑÂ§âÂåñ„Å´„É≠„Éê„Çπ„Éà„Å™„É≠„Éú„ÉÉ„Éà„ÅÆVisuomotorÊñπÁ≠ñÁç≤Âæó„Ç∑„Çπ„ÉÜ„É†, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1K3-07, 2023</li>
<li>Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Áü¢ÈáéÂÄâ ‰ºäÁπî, Èáë Ê∑≥ÊöÅ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„Å´„Çà„Çã„Çø„Çπ„ÇØÂÆüË°åÁÆ°ÁêÜÂô®ÁîüÊàêÊ≥ï„Å®RoboCup JapanOpen @Home League GPSR„Çø„Çπ„ÇØ„Å∏„ÅÆÂøúÁî®, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1K4-05, 2023, <b><font color='red'>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÁ¨¨5ÂõûÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li>Â°öÊú¨ Áõ¥‰∫∫, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â∏ÇÂÄâ ÊÑõÂ≠ê, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ßË¶èÊ®°Ë¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å®„Éá„Éº„Çø„Éô„Éº„Çπ„ÇíÁî®„ÅÑ„Åü„É≠„Éú„ÉÉ„Éà„ÅÆË®òÊÜ∂ËìÑÁ©ç„Å®„É¶„Éº„Ç∂„Éº„Å∏„ÅÆÂÖ±Êúâ, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1K4-07, 2023</li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ê§ÖÂ≠êÂûãÈùûÂØæÁß∞‰∏âËÑöÁßªÂãï„É≠„Éú„ÉÉ„Éà„ÅÆË∫´‰ΩìË®≠Ë®à„Å®Ê≠©ÂÆπÁîüÊàê, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 2D1-04, 2023</li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„ÉØ„Ç§„É§Âπ≤Ê∏âÈßÜÂãï„Ç¢„Éº„É†„Å´„Çà„ÇãÈ´òÈÄüÊâìÊíÉÂãï‰ΩúÂÆüÁèæ, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 3E4-02, 2023</li>
<li>ÂãáÂ¥é È¢ØÂ§™, Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„ÉØ„Ç§„É§ÈßÜÂãïÂûã3Ê¨°ÂÖÉÁ©∫‰∏≠ÁßªÂãïË£ÖÁΩÆ„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„Å´„Çà„ÇãÊ§úË®é, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1D2-01, 2023</li>
<li>Â∞èÂ°ö ÈôΩÂ∏å, Ë∂ô Êº†Â±Ö, Ë•øÂ∞æ ÂçìÁ¥î, Âîê ÂÆâÂçó, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÆüÊ©üÊ§úË®º„Å´Âü∫„Å•„ÅèÊôÇÈñìÈÅÖ„Çå„Å´ÁùÄÁõÆ„Åó„Åü„Éû„É´„ÉÅ„É≠„Éº„ÇøÈöúÂÆ≥Áâ©ÂõûÈÅø„ÅÆ„Åü„ÇÅ„ÅÆÊ±éÁî®ÁöÑ„Å™Â≠¶ÁøíÊñπÁ≠ñ„ÅÆÊßãÁØâ, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 2H3-05, 2023</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§öÁõÆÁöÑ„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÊúÄÈÅ©Âåñ„Å®„É¢„Éá„É´‰∫àÊ∏¨Âà∂Âæ°„Å´„Çà„ÇãÊãÆÊäó„ÉØ„Ç§„É§ÈßÜÂãïËÑö„ÅÆÁ≠ãÈÖçÁΩÆÁîüÊàê, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 3I3-07, 2023</li>
<li>‰∏âÊú® Á´†ÂØõ, ‰ΩêÂéü ‰æëÂ§™, Ê∑±Â±± ÂíåÊµ©, ÂêâÊùë Èßø‰πã‰ªã, ÊùéÊûó ÂòâÂÖÉ, Èï∑Ë∞∑Â∑ù Â≥ª, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫∫Èñì„ÅÆÈñ¢ÁØÄÂèØÂãïÂüü„ÇíÊ∫Ä„Åü„ÅôÊ®°Êì¨Èù≠Â∏ØÊßãÊàêÊ≥ï„ÅÆÂü∫Á§éÁöÑÊ§úË®é, in <i>Á¨¨41ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ23J</b>)</i>, 1B3-03, 2023</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁúüÂ£Å ‰Ωë, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§öÁõÆÁöÑ„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÊúÄÈÅ©Âåñ„Å´Âü∫„Å•„Åè‰ΩúÊ•≠ÊîØÊè¥„É¢„Ç∏„É•„É©„Éº„É≠„Éú„ÉÉ„ÉàË®≠Ë®à, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1P1-G13, 2023</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Âà∂Á¥Ñ‰ªò„ÅçÊ®°ÂÄ£Â≠¶Áøí„Å´„Çà„Çã„É≠„Éú„ÉÉ„Éà„ÅÆËÖπËÖîÈè°ÊâãË°ì„ÅÆÂü∫Êú¨ÊäÄËÉΩË®ìÁ∑¥, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 2P2-B22, 2023</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, Èà¥Êú® Â§©È¶¨, ÊùøÊù± Ê≠£Á•ê, ÂãáÂ¥é È¢ØÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ËÑö„Å®Â∞ªÂ∞æ„ÇíÊúâ„Åô„Çã„Ç´„É≥„Ç¨„É´„Éº„É≠„Éú„ÉÉ„Éà„ÅÆÊßãÊàêÊ≥ï„Å®Ë∑≥Ë∫çÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1A1-E19, 2023, <b><font color='red'>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºöËã•ÊâãÂÑ™ÁßÄË¨õÊºî„Éï„Çß„É≠„ÉºË≥û</font></b></li>
<li>Ê∑±Â±± ÂíåÊµ©, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫îÊåá„ÇíÊúâ„Åô„ÇãË°®ÁöÆÈ™®Ê†º‰∏Ä‰ΩìÂûã„É≠„Éú„ÉÉ„Éà„Éè„É≥„Éâ„ÅÆË£Ω‰Ωú, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1A1-F23, 2023</li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Object size based fingertip workspace processing for acceleration of grasp pose generation, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1A1-F24, 2023</li>
<li>ÂãáÂ¥é È¢ØÂ§™, ‰∏âÊú® Á´†ÂØõ, ÊùøÊù± Ê≠£Á•ê, ÂêâÊùë Èßø‰πã‰ªã, Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Áí∞Â¢É„ÇíÂà©Áî®„Åó„ÅüË∫´‰ΩìËÉΩÂäõÊã°ÂºµË°åÂãï„ÅÆ„Åü„ÇÅ„ÅÆÂèØÂãï„Ç´„É©„Éì„Éä„ÉØ„Ç§„É§„É¢„Ç∏„É•„Éº„É´„ÅÆË®≠Ë®à„Å®Âãï‰ΩúÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1A1-I11, 2023</li>
<li>Â∏ÇÂÄâ ÊÑõÂ≠ê, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„É≠„Éú„ÉÉ„Éà„ÅÆ„ÅäÊï£Ê≠©‰ΩìÈ®ìÊó•Ë®ò - Ë®òËø∞ÂÜÖÂÆπ„ÅÆÈÅï„ÅÑ„Å´„Çà„ÇãË™≠ËÄÖ„ÅÆÊÑüÊÉ≥ÊØîËºÉ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1A2-C26, 2023</li>
<li>Èà¥Êú® Â§©È¶¨, ÊùøÊù± Ê≠£Á•ê, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>3Ê¨°ÂÖÉÂèóÂãï„ÉØ„Ç§„É§Êï¥ÂàóË£ÖÁΩÆ„ÅÆË£Ω‰Ωú„Å®7Ëá™Áî±Â∫¶„Éû„Éã„É•„Éî„É¨„Éº„Çø„Å∏„ÅÆÈÅ©Áî®, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1A1-H16, 2023</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Áü≥Áî∞ ÂØõÂíå, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂèçÂæ©Ëá™Âãï„Éá„Éº„ÇøÂèéÈõÜ„ÇíÁî®„ÅÑ„ÅüÊ®°ÂÄ£Â≠¶Áøí„Å´„Çà„ÇãÁí∞Â¢ÉË®≠ÂÇôÊìç‰Ωú„Çø„Çπ„ÇØ„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1P1-D05, 2023</li>
<li>Â§ßÊó•Êñπ ÊÖ∂Ê®π, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â±±Âè£ Áõ¥‰πü, Â°öÊú¨ Áõ¥‰∫∫, Áü¢ÈáéÂÄâ ‰ºäÁπî, ÂåóÂ∑ù ÊôãÂêæ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ßË¶èÊ®°Ë¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å®„ÉÅ„É£„ÉÉ„Éà„Ç§„É≥„Çø„Éï„Çß„Éº„Çπ„ÇíÁî®„ÅÑ„ÅüÁîüÊ¥ªÁí∞Â¢É„ÅÆÂàÜÈ°û„Å®„É≠„Éú„ÉÉ„Éà„Çø„Çπ„ÇØ„Éû„ÉÉ„Éî„É≥„Ç∞„Ç∑„Çπ„ÉÜ„É†, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 1P1-D06, 2023</li>
<li>Â∞èÂ°ö ÈôΩÂ∏å, Ë∂ô Êº†Â±Ö, Ë•øÂ∞æ ÂçìÁ¥î, Âîê ÂÆâÂçó, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Ê±éÁî®ÁöÑ„Å™„Éû„É´„ÉÅ„É≠„Éº„Çø„Å´ÈÅ©ÂøúÂèØËÉΩ„Å™Â≠¶ÁøíÊñπÁ≠ñ„Å´„Çà„ÇãÈöúÂÆ≥Áâ©ÂõûÈÅøÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 2A2-D10, 2023, <b><font color='red'>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÁ¨¨2ÂõûËã•ÊâãË¨õÊºîË≥û</font></b></li>
<li>‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùøÊù± Ê≠£Á•ê, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>ËÑ±ÁùÄÂèØËÉΩ„Å™„ÉØ„Ç§„É§„É¢„Ç∏„É•„Éº„É´„ÇíÁî®„ÅÑ„ÅüÁí∞Â¢ÉÁâ©Ëá™Âú®Êìç‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 2P1-C25, 2023</li>
<li>ÊùéÊûó ÂòâÂÖÉ, Ê∑±Â±± ÂíåÊµ©, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>„ÉØ„Ç§„É§Â∑ªÂèñÂºèÁ≠ãËÖ±Ë§áÂêà‰ΩìÈßÜÂãï„ÅÆË£Ω‰Ωú„Å®‰∫åÊ¨°ÂÖÉÁöÑ„É≠„Éú„ÉÉ„ÉàÊßãÊàê„Å´„Åä„Åë„ÇãÊ§úË®º, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'23 (<b>ROBOMECH23J</b>)</i>, 2P2-D19, 2023</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Êó•Â∏∏ÁîüÊ¥ªÊîØÊè¥„É≠„Éú„ÉÉ„Éà„Å´Âêë„Åë„ÅüÂ§ßË¶èÊ®°Ë¶ñË¶ö-Ë®ÄË™û„É¢„Éá„É´„Å®ÈÄ≤ÂåñÁöÑË®àÁÆó„Å´Âü∫„Å•„ÅèÁä∂ÊÖãË™çË≠ò, in <i>Á¨¨37Âõû‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºöÂÖ®ÂõΩÂ§ß‰ºö (<b>JSAI23J</b>)</i>, 3G1-OS-24a-04, 2023</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ßË¶èÊ®°Âü∫Áõ§„É¢„Éá„É´Âà©Áî®„Å´„Çà„ÇãÊñôÁêÜ„É¨„Ç∑„ÉîË®òËø∞„Åã„Çâ„ÅÆÈ£üÊùêÁä∂ÊÖãÂ§âÂåñ„ÇíËÄÉÊÖÆ„Åó„ÅüË™øÁêÜË™çË≠òË®àÁîªË°åÂãï„É≠„Éú„ÉÉ„Éà„Ç∑„Çπ„ÉÜ„É†, in <i>Á¨¨37Âõû‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºöÂÖ®ÂõΩÂ§ß‰ºö (<b>JSAI23J</b>)</i>, 3G1-OS-24a-02, 2023</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰ΩéÂâõÊÄß„É≠„Éú„ÉÉ„Éà„ÅÆË∫´‰ΩìÂ§âÂåñ„ÇíËÄÉÊÖÆ„Åó„ÅüËá™ÂæãÁöÑË¶ñË¶ö„Çµ„Éº„ÉúÂ≠¶Áøí, in <i>Á¨¨23ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI22J</b>)</i>, 3P2-H07, 2022</li>
<li>Ê•†Â±± Â§ßÊ®π, ÁúüÂ£Å ‰Ωë, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Éí„Éà„Éª„É≠„Éú„ÉÉ„Éà„ÇíÈÅãÊê¨ÂèØËÉΩ„Å™„É¢„Éì„É™„ÉÜ„Ç£„ÅÆ„Éê„É©„É≥„ÇπÂà∂Âæ°, in <i>Á¨¨23ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI22J</b>)</i>, 1A2-D02, 2022</li>
<li>ÊùéÊûó ÂòâÂÖÉ, Ê∑±Â±± ÂíåÊµ©, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„ÉØ„Ç§„É§Â∑ªÂèñÂºèÁ≠ãËÖ±Ë§áÂêà‰ΩìÈßÜÂãï„Å´„Çà„Çã„É≠„Éú„ÉÉ„ÉàÊßãÊàê„ÅÆÂü∫Á§éÁöÑÊ§úË®é, in <i>Á¨¨23ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI22J</b>)</i>, 1P3-E09, 2022</li>
<li>Èáë Ê∑≥ÊöÅ, ÂåóÂ∑ù ÊôãÂêæ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>RGB ÁîªÂÉè„Å´„Çà„ÇãÈ´™„ÅÆ‰π±ÈõëÈ†òÂüüË™çË≠ò„Å®ÂúßÂäõ„Çª„É≥„Çµ„Çí‰ªò„Åë„ÅüÊ´õ„Å´„Çà„ÇãÈ†≠ÁöÆÊé•Ëß¶Ë™çË≠ò„ÇíÁî®„ÅÑ„Åü„É≠„Éú„ÉÉ„ÉàÊï¥È´™„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ†îÁ©∂, in <i>Á¨¨23ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI22J</b>)</i>, 3A2-B08, 2022</li>
<li>‰∏âÊú® Á´†ÂØõ, ÊùøÊù± Ê≠£Á•ê, Ê∞∏Êùæ Á•êÂº•, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Âπ≥Â≤° Áõ¥Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ëª∏ÈßÜÂãï, ËÖ±ÈßÜÂãï, Âè∞ËªäÂûã, Êó¢Ë£ΩÂìÅ„ÇíÂê´„ÇÄÂ§öÊßò„Å™„É≠„Éú„ÉÉ„Éà„ÇíÊâ±„ÅÜ„Åü„ÇÅ„ÅÆ„Éè„Éº„Éâ„Ç¶„Çß„Ç¢ÊäΩË±°Âåñ„Éá„Éê„Ç§„ÇπÂà∂Âæ°„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÈñãÁô∫, in <i>Á¨¨23ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI22J</b>)</i>, 3A2-E16, 2022</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∏ÄËà¨ÂåñÂ§öÊÑüË¶öÁõ∏Èñ¢„É¢„Éá„É´Â≠¶Áøí„Å´Âü∫„Å•„ÅèË∫´‰ΩìÂõ≥Âºè„ÅÆÁç≤Âæó„Å®Ë™çË≠òÂà∂Âæ°, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 1F1-03, 2022</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Éë„É©„É¨„É´„ÉØ„Ç§„É§ÈßÜÂãï‰∏ÄÊú¨ËÑöË∑≥Ë∫ç„É≠„Éú„ÉÉ„ÉàRAMIEL„ÅÆÂº∑ÂåñÂ≠¶Áøí„Å´Âü∫„Å•„ÅèÈÄ£Á∂öË∑≥Ë∫çÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 2F3-05, 2022</li>
<li>ÁúüÂ£Å ‰Ωë, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê∞∏Êùæ Á•êÂº•, ÂÆâÊñé Êô∫Á¥Ä, ËèÖ‰∫ï Êñá‰ªÅ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Çª„É´„Éï„É≠„ÉÉ„ÇØÊ∏õÈÄüÊ©üÊßã„Å®ÂÜóÈï∑„Çª„É≥„Çµ„ÇíÂÇô„Åà„Åü„Çµ„Éº„Éú„É¢„Ç∏„É•„Éº„É´„ÅÆË®≠Ë®àÈñãÁô∫„Å®Â§öÈñ¢ÁØÄ„Ç¢„Éº„É†„Å´„Åä„Åë„ÇãÂøúÁî®, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 2K1-06, 2022</li>
<li>ÂãáÂ¥é È¢ØÂ§™, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÆ∂Â∫≠Áî®3D„Éó„É™„É≥„Çø„ÅßËá™‰ΩúÂèØËÉΩ„Å™Â§ßÂûã„Éô„Ç¢„É™„É≥„Ç∞„Éª„Çµ„Ç§„ÇØ„É≠„Ç§„ÉâÊ∏õÈÄüÊ©ü„Çµ„Éº„Éú„É¢„Ç∏„É•„Éº„É´„ÅÆÈñãÁô∫, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 2K1-07, 2022</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Áü≥Áî∞ ÂØõÂíå, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„É≠„Éú„ÉÉ„Éà„ÅÆÂèçÂæ© pick-and-place Ëá™Âãï„Éá„Éº„ÇøÂèéÈõÜ„Å´„Çà„ÇãOne-Shot ÊïôÁ§∫ÊääÊåÅÂãï‰Ωú„Çπ„Ç≠„É´Â≠¶Áøí„Ç∑„Çπ„ÉÜ„É†, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 3F1-03, 2022</li>
<li>Èà¥Êú® Â§©È¶¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê∑±Â±± ÂíåÊµ©, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÁÑ°Ê∏õÈÄü„ÉØ„Ç§„É§Âπ≤Ê∏âÈßÜÂãï„ÇíÁî®„ÅÑ„ÅüËªΩÈáè„Éª„Éê„ÉÉ„ÇØ„Éâ„É©„Ç§„Éê„Éñ„É´„Å™„É≠„Éú„ÉÉ„Éà„Ç¢„Éº„É†„ÅÆÈñãÁô∫, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 3E2-03, 2022</li>
<li>Áü≥Áî∞ ÂØõÂíå, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂàÜÁØÄÂåñÂûãBehavioral Cloning„Å®„É¢„Ç∏„É•„Éº„É´ÊÄß„Å´ÁùÄÁõÆ„Åó„Åü„Åù„ÅÆÊúâÂäπÊù°‰ª∂„ÅÆË™¨Êòé, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 3F2-02, 2022</li>
<li>ÂêâÊùë Èßø‰πã‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>3D„Éó„É™„É≥„Çø„Å®„Çµ„Éº„Éú„É¢„Ç∏„É•„Éº„É´„ÅßË£Ω‰ΩúÂèØËÉΩ„Å™„Ç¢„Éº„É†„Åß‰ΩìÈáç„ÇíÊîØÊåÅ„ÅóÁßªÂãï„Åô„ÇãËªäËº™ÂûãËÖ±ÈßÜÂãï„É≠„Éú„ÉÉ„Éà„ÅÆÈñãÁô∫, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 4E1-07, 2022</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Parametric Bias „ÇíÁî®„ÅÑ„ÅüÈ£üÊùêÁâπÂæ¥„ÇíËÄÉÊÖÆÂèØËÉΩ„Å™Ë™øÁêÜ„É≠„Éú„ÉÉ„Éà„ÅÆÂåÖ‰∏ÅÂàáÊñ≠Êìç‰ΩúÂ≠¶Áøí, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 4I1-06, 2022</li>
<li>Ê∑±Â±± ÂíåÊµ©, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ë°®ÁöÆ„Å®È™®Ê†º„Çí‰∏Ä‰Ωì„Åß3D„Éó„É™„É≥„ÉÜ„Ç£„É≥„Ç∞„Åô„ÇãËÖ±ÈßÜÂãï„ÇΩ„Éï„Éà„É≠„Éú„ÉÉ„Éà„Éè„É≥„Éâ„ÅÆÈñãÁô∫, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 4K2-08, 2022</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Parametric Bias „ÇíÁî®„ÅÑ„ÅüÈ£üÊùêÁâπÂæ¥„ÇíËÄÉÊÖÆÂèØËÉΩ„Å™Ë™øÁêÜ„É≠„Éú„ÉÉ„Éà„ÅÆÂåÖ‰∏ÅÂàáÊñ≠Êìç‰ΩúÂ≠¶Áøí, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 4I1-06, 2022</li>
<li>L. Wu, <b><u>K. Kawaharazuka</u></b>, K. Okada, M. Inaba<br>Taxonomy-aware workspace-based grasp pose generation, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 1J1-04, 2022</li>
<li>‰∏âÊú® Á´†ÂØõ, ÊùøÊù± Ê≠£Á•ê, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùéÊûó ÂòâÂÖÉ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„ÇãÂãï‰ΩúÂë®Êúü„ÅÆÊé¢Á¥¢„Å´Âü∫„Å•„Åè„É≠„Éº„ÉóÊäï„ÅíÊìç‰Ωú„ÅÆÂÆüÁèæ, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 4E1-05, 2022</li>
<li>ÊùéÊûó ÂòâÂÖÉ, ‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ËÖ±ÈßÜÂãï„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„Çã„Çπ„ÉÜ„Ç£„ÉÉ„ÇØÊääÊåÅÁä∂ÊÖã„Å®ÂâõÊÄß„ÅÆÂ§âÂåñ„ÇíÂà©Áî®„Åó„Åü„Éâ„É©„É†„É≠„Éº„É´ÂÆüÁèæ, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 4E1-06, 2022</li>
<li>Êñ∞Âüé ÂÖâÊ®π, Â§ßÊó•Êñπ ÊÖ∂Ê®π, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÁßªÂãï„É≠„Éú„ÉÉ„Éà„ÅÆ„Éï„É≠„Ç¢ÈñìÁßªÂãï„ÅÆ„Åü„ÇÅ„ÅÆ„Éû„É´„ÉÅ„Çª„É≥„Çµ„ÉªIoT„Çπ„Ç§„ÉÉ„ÉÅ„Å´„Çà„Çã„Ç®„É¨„Éô„Éº„ÇøÁä∂ÊÖãË™çË≠ò„ÉªÊìç‰Ωú„Ç∑„Çπ„ÉÜ„É†, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 1D1-05, 2022</li>
<li>Â∞èÂ°ö ÈôΩÂ∏å, Ë∂ô Êº†Â±Ö, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âîê ÂÆâÂçó, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Âº∑ÂåñÂ≠¶Áøí„ÇíÁî®„ÅÑ„ÅüÂãïÁöÑÈöúÂÆ≥Áâ©Áí∞Â¢É‰∏ã„Åß„ÅÆ„Éû„É´„ÉÅ„É≠„Éº„ÇøÈ´òÈÄüÁßªÂãï, in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ22J</b>)</i>, 1G1-02, 2022</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Parametric Bias„ÇíÂê´„ÇÄÊ∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí„Å®Â§öÊßò„Å™ÂÆü„É≠„Éú„ÉÉ„Éà„Å∏„ÅÆÂøúÁî®, in <i>Á¨¨36Âõû‰∫∫Â∑•Áü•ËÉΩÂ≠¶‰ºöÂÖ®ÂõΩÂ§ß‰ºö (<b>JSAI22J</b>)</i>, 2M5-OS-19c-01, 2022</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ‰∏âÊú® Á´†ÂØõ, Âà©ÂÖâ Ê≥∞Âæ≥, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãÁ≠ãÂ¢óÂä†„ÇíËÄÉÊÖÆÂèØËÉΩ„Å™ÈÅ©ÂøúÁöÑË∫´‰ΩìÂõ≥ÂºèÂ≠¶Áøí„Ç∑„Çπ„ÉÜ„É†, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2A2-I10, 2022</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ‰∏âÊú® Á´†ÂØõ, ÊùøÊù± Ê≠£Á•ê, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ê∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí„Å´„Çà„ÇãÂèØÂ§âÂâõÊÄß„Å®Á¥†ÊùêÂ§âÂåñ„ÇíËÄÉÊÖÆ„Åó„ÅüÂãïÁöÑÊüîËªüÂ∏ÉÊìç‰Ωú, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2A1-O05, 2022, <b><font color='red'>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„Éô„Çπ„Éà„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥Ë≥û</font></b></li>
<li>Âà©ÂÖâ Ê≥∞Âæ≥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ‰∏âÊú® Á´†ÂØõ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂØÜÁîªÂÉè„É§„Ç≥„Éì„Ç¢„É≥„ÅÆÊé®ÂÆöÊ≥ïDIJE„Å®„Éì„Ç∏„É•„Ç¢„É´„Çµ„Éº„ÉúÂà∂Âæ°„Å∏„ÅÆÂøúÁî®, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2A2-I09, 2022</li>
<li>Ëã•Êûó ÈöºÂπ≥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Êìç‰ΩúÊïôÁ§∫„Å´Âü∫„Å•„ÅèË£úÂä©ÂøÖË¶ÅÂ∫¶„ÇíËÄÉÊÖÆ„Åó„ÅüÈ£üÂô®È°û„ÅÆÊøØ„Åé„Å®Êì¶„ÇäÂãï‰ΩúÂ≠¶Áøí, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2A1-O06, 2022</li>
<li>ÊùøÊù± Ê≠£Á•ê, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ‰∏âÊú® Á´†ÂØõ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂèåËÖï„É≠„Éú„ÉÉ„Éà„Å´„Çà„Çã„É≠„Éº„ÉóÂõû„ÅóÂãï‰Ωú„ÅÆÁõÆÊ®ôÊâãÂÖàËªåÈÅìÁîüÊàê, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2A1-N08, 2022</li>
<li>Ê∑±Â±± ÂíåÊµ©, Èï∑Ë∞∑Â∑ù Â≥ª, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â±±Âè£ Áõ¥‰πü, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á•ûÁµåÂÜÖÂåÖÊüîËªüË°®ÁöÆ„ÇíÊúâ„ÅóÈÅìÂÖ∑‰ΩøÁî®„ÇíË°å„ÅÜ‰∫îÊåá„Éè„É≥„Éâ„ÅÆÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2A1-K02, 2022</li>
<li>ÊùéÊûó ÂòâÂÖÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Ê•†Â±± Â§ßÊ®π, ‰∏âÊú® Á´†ÂØõ, Êñ∞Âüé ÂÖâÊ®π, ÊùøÊù± Ê≠£Á•ê, Èà¥Êú® Â§©È¶¨, Â∞èÊ§éÂ∞æ ‰æëÂ§ö, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÅ¥Èù¢ÂäõË¶ö„ÇíÊúâ„Åô„Çã„É≠„Éú„ÉÉ„Éà„Éï„ÉÉ„Éà„Å´„Çà„ÇãÊ§ÖÂ≠êÁùÄÂ∫ßÁä∂ÊÖã„Å´„Åä„Åë„ÇãÂõûËª¢Âãï‰ΩúÂà∂Âæ°, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 1P1-T07, 2022</li>
<li>ÊùéÊûó ÂòâÂÖÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Ê•†Â±± Â§ßÊ®π, ‰∏âÊú® Á´†ÂØõ, Êñ∞Âüé ÂÖâÊ®π, ÊùøÊù± Ê≠£Á•ê, Èà¥Êú® Â§©È¶¨, Â∞èÊ§éÂ∞æ ‰æëÂ§ö, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫∫‰Ωì„ÅÆË∂≥Ë£èÂ§ñÂë®Á∏ÅÊé•Ëß¶ÂúßÂàÜÂ∏ÉË®àÊ∏¨Ë£ÖÁΩÆ„ÇíÁî®„ÅÑ„Åü„É≠„Éú„ÉÉ„ÉàËÑö„Å´„Çà„ÇãÊ®°ÂÄ£Ë°åÂãï„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 1P1-T08, 2022</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Parametric Bias„ÇíÁî®„ÅÑ„ÅüË™øÁêÜ„É≠„Éú„ÉÉ„Éà„ÅÆÂåÖ‰∏ÅÂàáÊñ≠Êìç‰Ωú„Å´„Åä„Åë„ÇãÈ£üÊùêÁâπÂæ¥Â≠¶Áøí, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 1A1-T11, 2022</li>
<li>Èà¥Êú® Â§©È¶¨, Âà©ÂÖâ Ê≥∞Âæ≥, Ê∞∏Êùæ Á•êÂº•, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ‰∏âÊú® Á´†ÂØõ, ÊùéÊûó ÂòâÂÖÉ, ÊùøÊù± Ê≠£Á•ê, Â∞èÂ≥∂ ÈÇ¶Áîü, Âû£ÂÜÖ Ê¥ãÂπ≥, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>„Éë„É©„É¨„É´„ÉØ„Ç§„É§Âûã‰∏ÄÊú¨ËÑöË∑≥Ë∫ç„É≠„Éú„ÉÉ„ÉàRAMIEL„ÅÆË®≠Ë®à„Å®Ë∑≥Ë∫çÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2P1-L10, 2022, <b><font color='red'>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„Éô„Çπ„Éà„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥Ë≥û</font></b></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÈÄêÊ¨°ÁöÑ„Å™ÊääÊåÅÁä∂ÊÖãÂ§âÂåñ„ÇíËÄÉÊÖÆ„Åó„ÅüÈÅ©ÂøúÁöÑÈÅìÂÖ∑ÂÖàÁ´ØÊìç‰ΩúÂ≠¶Áøí, in <i>Á¨¨22ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI21J</b>)</i>, 1D2-04, 2021</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Êñ∞Âüé ÂÖâÊ®π, Ê≤≥Êùë Ê¥ã‰∏ÄÈÉé, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á¢∫ÁéáÁöÑÊ∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí„Å´„Çà„ÇãÂàÜÊï£ÊúÄÂ∞èÂåñ„ÇíÂê´„ÇÄÁí∞Â¢ÉÈÅ©ÂøúÂûãÂà∂Âæ° - Âè∞ËªäÂûã„É≠„Éú„ÉÉ„Éà„Å∏„ÅÆÈÅ©Áî® -, in <i>Á¨¨22ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI21J</b>)</i>, 1H3-02, 2021, <b><font color='red'>ÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li>‰∏âÊú® Á´†ÂØõ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊùøÊù± Ê≠£Á•ê, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Âè∞ËªäÂûãÁ≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„ÇãÂ∏ÉÊìç‰Ωú„ÇíÂê´„Çì„Å†‰∏ÄÈÄ£„ÅÆ„ÉÜ„Éº„Éñ„É´„Çª„ÉÉ„ÉÜ„Ç£„É≥„Ç∞Âãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Á¨¨22ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI21J</b>)</i>, 1D2-03, 2021</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê≤≥Êùë Ê¥ã‰∏ÄÈÉé, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Parametric Bias„ÇíÁî®„ÅÑ„ÅüÂãï‰Ωú„Çπ„Çø„Ç§„É´„ÇíÂà∂Á¥ÑÂèØËÉΩ„Å™Ê®°ÂÄ£Â≠¶Áøí, in <i>Á¨¨39ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ21J</b>)</i>, 1I3-01, 2021</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ë•øÊµ¶ Â≠¶, Â§ßÊùë Êüö‰ªã, Âè§Ë≥Ä ÊÇ†Áü¢, Âà©ÂÖâ Ê≥∞Âæ≥, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Ê©üËÉΩÁöÑ„ÉªÁ©∫ÈñìÁöÑÊé•Á∂ö„ÇíÂà©Áî®„Åó„ÅüÂÜóÈï∑„Å™„Çª„É≥„Çµ„Éª„Ç¢„ÇØ„ÉÅ„É•„Ç®„Éº„Çø„ÅÆËá™ÂãïÂàÜÂâ≤: Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆÁ≠ãÂàÜÂâ≤„Å∏„ÅÆÈÅ©Áî®, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 1A1-D06, 2021</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Ë•øÊµ¶ Â≠¶, Âè§Ë≥Ä ÊÇ†Áü¢, Â§ßÊùë Êüö‰ªã, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÁ†¥Êñ≠„ÇíË£úÂÑü„Åô„ÇãÂÜóÈï∑ÊÄß„ÇíÊúÄÂ§ßÈôêÊ¥ªÁî®„Åó„ÅüÁ≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆË®≠Ë®àÊúÄÈÅ©Âåñ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 2P3-H04, 2021</li>
<li>Âè§Ë≥Ä ÊÇ†Áü¢, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Ë•øÊµ¶ Â≠¶, Â§ßÊùë Êüö‰ªã, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆËÇ©Ë§áÂêà‰Ωì„Å´„Åä„Åë„ÇãÂÜóÈï∑ÊÄß„ÇíÊ¥ª„Åã„Åó„ÅüÂßøÂã¢ÁîüÊàê„Å®Áâ©‰ΩìÊìç‰Ωú„ÇíÁõÆÁöÑ„Å®„Åó„ÅüËá™Â∑±Ë∫´‰ΩìÂÉè„ÅÆÂÆüÊ©üÂ≠¶Áøí, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 1A1-D07, 2021</li>
<li>Ëã•Êûó ÈöºÂπ≥, ÂåóÂ∑ù ÊôãÂêæ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÂÆ§Â≤° Ë≤¥‰πã, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ë¶ñË¶öÊÉÖÂ†±„Å´Âü∫„Å•„ÅèÈ£üÂô®È°û„ÅÆÊääÊåÅ„ÅÆÂÜóÈï∑ÊÄß„ÇíËÄÉÊÖÆ„Åó„ÅüËá™Â∑±ÊïôÂ∏´„ÅÇ„ÇäÊääÊåÅÂ≠¶Áøí, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 1A1-F09, 2021</li>
<li>Â§ßÊùë Êüö‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê∞∏Êùæ Á•êÂº•, Âè§Ë≥Ä ÊÇ†Áü¢, Ë•øÊµ¶ Â≠¶, Âà©ÂÖâ Ê≥∞Âæ≥, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„Çã‰∫∫‰ΩìÊ®°ÂÄ£‰∏°ËÄ≥ËÅ¥„ÇíÁî®„ÅÑ„ÅüË¶ñÈáéÂ§ñÁí∞Â¢ÉË™çË≠òË°åÂãï, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 2A1-I15, 2021</li>
<li>Ë•øÊµ¶ Â≠¶, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Êé•Ëß¶Áä∂ÊÖã„ÇíÂê´„ÇÄË∫´‰Ωì„É¢„Éá„É´„Å®Âº∑ÂåñÂ≠¶Áøí„ÇíÁî®„ÅÑ„ÅüÁ≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„ÇãÁí∞Â¢ÉÊé•Ëß¶Ë°åÂãï, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 2A1-I16, 2021</li>
<li>Âà©ÂÖâ Ê≥∞Âæ≥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ë•øÊµ¶ Â≠¶, Âè§Ë≥Ä ÊÇ†Áü¢, Â§ßÊùë Êüö‰ªã, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„ÉâËÖïÈÉ®„ÅÆÁ≠ã„ÉªÈñ¢ÁØÄÂÜóÈï∑ÊÄß„ÇíÊ¥ªÁî®„Åó„Åü„Çø„Çπ„ÇØÁ©∫Èñì„Å´„Åä„Åë„ÇãÂà∂Âæ°, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'21 (<b>ROBOMECH21J</b>)</i>, 2P2-G15, 2021</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â∞èÂ∑ù Âæπ, ÈçãÂ∂å ÂéöÂ§™<br>„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆË™§Â∑ÆÈÄÜ‰ºùÊí≠„Å´„Çà„ÇãÈÅìÂÖ∑ÂΩ¢Áä∂ÊúÄÈÅ©Âåñ, in <i>Á¨¨21ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI20J</b>)</i>, 3D3-05, 2020, <b><font color='red'>ÂÑ™ÁßÄË¨õÊºîË≥û</font></b></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âπ≥Â≤° Áõ¥Ê®π, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Ê∏©Â∫¶„É¢„Éá„É´„Éë„É©„É°„Éº„Çø„ÅÆ„Ç™„É≥„É©„Ç§„É≥Â≠¶Áøí„ÇíÁî®„ÅÑ„Åü„É¢„Éº„Çø„Ç≥„Ç¢Ê∏©Â∫¶Êé®ÂÆö„Å®Âà∂Âæ°: Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å∏„ÅÆÈÅ©Áî®, in <i>Á¨¨21ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI20J</b>)</i>, 2F3-14, 2020</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âè§Ë≥Ä ÊÇ†Áü¢, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>ÊãÆÊäóÁ≠ãÊäëÂà∂Âà∂Âæ°„Å®ÊãÆÊäóÁ≠ã‰∫àË¶ã‰º∏Èï∑Âà∂Âæ°„Å´„Çà„ÇãÂÜóÈï∑„Å™Á≠ã„ÇíÊúâ„Åô„ÇãÁ≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆÊúÄÂ§ßÈñ¢ÁØÄÈÄüÂ∫¶„ÇíÁ™ÅÁ†¥„Åô„ÇãÂãï‰ΩúÊà¶Áï•, in <i>Á¨¨21ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI20J</b>)</i>, 2D2-08, 2020</li>
<li>Â§ßÊùë Êüö‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê∞∏Êùæ Á•êÂº•, Âè§Ë≥Ä ÊÇ†Áü¢, Ë•øÊµ¶ Â≠¶, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫∫‰ΩìÂ§ñËÄ≥Ê©üÊßã„ÇíÊ®°„Åó„Åü„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆ‰∏°ËÄ≥Èñì„Çπ„Éö„ÇØ„Éà„É´Â∑ÆÂ≠¶Áøí„Å´Âü∫„Å•„ÅèÁ©∫ÈñìÈü≥Ê∫êÊñπÂêëÊé®ÂÆö„Ç∑„Çπ„ÉÜ„É†, in <i>Á¨¨21ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI20J</b>)</i>, 1C3-17, 2020</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Parametric Bias„ÇíÂê´„ÇÄÂÜçÂ∏∞Âûã„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíÁî®„ÅÑ„ÅüÊüîËªü„Éè„É≥„Éâ„ÅÆÁâ©‰ΩìË™çË≠ò„ÉªÂãïÁöÑÊé•Ëß¶Âà∂Âæ°/Ê§úÁü•/„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥, in <i>Á¨¨38ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ20J</b>)</i>, 2A1-05, 2020</li>
<li>È¨ºÂ°ö ÁõõÂÆá, Ë•øÊµ¶ Â≠¶, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈÉΩÁØâ Êï¨, Âà©ÂÖâ Ê≥∞Âæ≥, Â§ßÊùë Êüö‰ªã, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Èù¢Áä∂È™®Ê†ºÈñìÊßãÈÄ†„ÇíÂà©Áî®„ÅóÂ∫É„ÅÑÂèØÂãïÂüü„Å´„Åä„ÅÑ„Å¶„É¢„Éº„É°„É≥„Éà„Ç¢„Éº„É†„ÇíÁ¢∫‰øù„ÅóÈ´òÂá∫Âäõ„Åß„ÅÆÁí∞Â¢ÉÊé•Ëß¶Âãï‰Ωú„ÅåÂèØËÉΩ„Å™Á≠ãÈ™®Ê†ºËÑö„ÅÆÈñãÁô∫, in <i>Á¨¨38ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ20J</b>)</i>, 2G2-08, 2020</li>
<li>Âà©ÂÖâ Ê≥∞Âæ≥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, Ë•øÊµ¶ Â≠¶, Âè§Ë≥Ä ÊÇ†Áü¢, Â§ßÊùë Êüö‰ªã, ÂÜ®Áî∞ Âππ, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Motor Directional TuningÁèæË±°„Å´Âü∫„Å•„ÅèÁ≠ãÂºµÂäõÂà∂Âæ°„Å´„Çà„ÇãÁ≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆ‰∏äËÇ¢Âãï‰Ωú, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'20 (<b>ROBOMECH20J</b>)</i>, 1P1-G05, 2020</li>
<li>Â§ßÊùë Êüö‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ê∞∏Êùæ Á•êÂº•, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, Âè§Ë≥Ä ÊÇ†Áü¢, Ë•øÊµ¶ Â≠¶, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Â§ñËÄ≥ÊßãÈÄ†„ÇíÊúâ„ÅóÈü≥ÈüøÂá¶ÁêÜ„ÇíË°å„ÅÜ‰∫∫‰ΩìÊ®°ÂÄ£„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆËÄ≥Ê©üÊßã„ÅÆË®≠Ë®àÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'20 (<b>ROBOMECH20J</b>)</i>, 1A1-E12, 2020</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Musculoskeletal AutoEncoder: Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆÁä∂ÊÖãÊé®ÂÆö„ÉªÂà∂Âæ°„Éª„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„ÇíÁµ±‰∏ÄÁöÑ„Å´Êâ±„ÅÜÁ≠ãÈ™®Ê†º„Çª„É≥„ÇµÈñì„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆ„Ç™„É≥„É©„Ç§„É≥Áç≤ÂæóÊâãÊ≥ï, in <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 3B3-06, 2019, <b><font color='red'>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÁ¨¨35ÂõûÁ†îÁ©∂Â•®Âä±Ë≥û</font></b></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â∞èÂ∑ù Âæπ, Áî∞Êùë Ê∑≥Â§™ÈÉé, ÈçãÂ∂å ÂéöÂ§™<br>Ê∑±Â±§Â≠¶Áøí„ÇíÁî®„ÅÑ„ÅüÈñ¢ÁØÄ„Éà„É´„ÇØÂÖ•Âäõ„Å´„Çà„ÇãÂãïÁöÑ„Å™ÊüîËªüÁâ©‰ΩìÊìç‰Ωú, in <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 1A2-06, 2019, <b><font color='red'>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÁ¨¨35ÂõûÁ†îÁ©∂Â•®Âä±Ë≥û</font></b></li>
<li>‰∏≠Â≥∂ ÊÖé‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊµÖÈáé ÊÇ†Á¥Ä, Âû£ÂÜÖ Ê¥ãÂπ≥, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Ëá™Â∑±‰øÆÂæ©ÂºµÂäõ‰ºùÈÅî„É¢„Ç∏„É•„Éº„É´„ÇíÂÇô„Åà„ÇãËÖ±ÈßÜÂãïËÑö„É≠„Éú„ÉÉ„Éà„ÅÆÈñãÁô∫, in <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 1K3-01, 2019</li>
<li>Ë•øÊµ¶ Â≠¶, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãÁí∞Â¢ÉÁâ©‰Ωì„Å´Âøú„Åò„ÅüÈÅ©ÂøúÁöÑÂâõÊÄß„É¨„É≥„Ç∏ÈÅ∏Êäû„Å®„Åù„ÅÆÂèØÂ§âÂâõÊÄßÂà∂Âæ°Êà¶Áï•„ÅÆÁç≤Âæó, in <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 1K3-06, 2019</li>
<li>ÊµÖÈáé ÊÇ†Á¥Ä, ÈÉΩÁØâ Êï¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, È¨ºÂ°ö ÁõõÂÆá, Âè§Ë≥Ä ÊÇ†Áü¢, Â§ßÊùë Êüö‰ªã, Ê∞∏Êùæ Á•êÂº•, ÁúüÂ£Å ‰Ωë, Ëó§‰∫ï Á∂∫È¶ô, Êñ∞Âüé ÂÖâÊ®π, ‰∏≠Â≥∂ ÊÖé‰ªã, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>ËÖ±ÈßÜÂãï„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãË™çË≠òÂà§Êñ≠Êìç‰ΩúÁµ±Âêà„Å´Âü∫„Å•„ÅèËá™ÂãïËªäÈÅãËª¢„ÅÆÂÆüË®ºÂÆüÈ®ì, in <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 3L2-06, 2019</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, ÈÉΩÁØâ Êï¨, È¨ºÂ°ö ÁõõÂÆá, Ê∞∏Êùæ Á•êÂº•, Êñ∞Âüé ÂÖâÊ®π, ÁúüÂ£Å ‰Ωë, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Â≠¶ÁøíÂà∂Âæ°Ê®°Á¥¢„ÅÆ„Åü„ÇÅ„ÅÆ„É¢„Ç∏„É•„É©„ÉºÂûãÁ≠ãÈ™®Ê†º„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„ÅÆË®≠Ë®àÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 2P1-C06, 2019</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈÉΩÁØâ Êï¨, ÁâßÈáé Â∞ÜÂêæ, È¨ºÂ°ö ÁõõÂÆá, Êñ∞Âüé ÂÖâÊ®π, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„Çã„Çø„Çπ„ÇØÁâπÂåñ„Åó„ÅüÂãïÁöÑËá™Â∑±Ë∫´‰ΩìÂà∂Âæ°„ÅÆÁç≤Âæó - Ëá™ÂãïÈÅãËª¢„Å´„Åä„Åë„Çã„Éö„ÉÄ„É´Êìç‰Ωú„Å∏„ÅÆÂøúÁî® -, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 1A1-L08, 2019</li>
<li>ÁúüÂ£Å ‰Ωë, ÁôΩ‰∫ï ÊãìÁ£®, Ê∞∏Êùæ Ë£ïÂº•, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ËèÖ‰∫ï Êñá‰ªÅ, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Áî®ÈÄîÈÅ©ÂøúÂûã„É≠„Éú„ÉÉ„Éà„ÅÆ„Åü„ÇÅ„ÅÆ„ÄÅÈßÜÂãïÊôÇ‰∫åÊÆµÂèØÂ§âÊ∏õÈÄüÈùûÈßÜÂãïÊôÇ„É≠„ÉÉ„ÇØÊ©üÊßã„ÇíÊåÅ„Å§Èñ¢ÁØÄ„É¢„Ç∏„É•„Éº„É´„ÅÆË®≠Ë®àÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 2A2-F08, 2019</li>
<li>ÈÉΩÁØâ Êï¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁúüÂ£Å ‰Ωë, È¨ºÂ°ö ÁõõÂÆá, ÁâßÈáé Â∞ÜÂêæ, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂèØÂãïÁúºÁêÉ„Å®Ëá™Â∑±Ë∫´‰Ωì„ÇíÁî®„ÅÑ„ÅüË∑ùÈõ¢Ë™çË≠òÊ©üËÉΩ„ÅÆÁç≤Âæó, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 1A1-M10, 2019</li>
<li>Â§ßÊùë Êüö‰ªã, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, È¨ºÂ°ö ÁõõÂÆá, Êñ∞Âüé ÂÖâÊ®π, ÈÉΩÁØâ Êï¨, Âè§Ë≥Ä ÊÇ†Áü¢, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãÊôÇÁ≥ªÂàóËÅ¥Ë¶öÊÉÖÂ†±„ÇíÁî®„ÅÑ„ÅüÊâìÈü≥Ë™çË≠ò„Å´Âü∫„Å•„ÅèÂãï‰ΩúÁç≤Âæó, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K03, 2019</li>
<li>Âè§Ë≥Ä ÊÇ†Áü¢, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, È¨ºÂ°ö ÁõõÂÆá, ÁúüÂ£Å ‰Ωë, ÈÉΩÁØâ Êï¨, Â§ßÊùë Êüö‰ªã, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆ„ÉÄ„Ç§„Éä„Éü„ÉÉ„ÇØÂãï‰Ωú„Å´„Åä„Åë„ÇãÁ≠ã„ÅÆÊãÆÊäóÈñ¢‰øÇ„Å®ÊâãÂÖàËªåÈÅì„ÅÆ‰øÆÊ≠£, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K02, 2019</li>
<li>Êñ∞Âüé ÂÖâÊ®π, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÊµÖÈáé ÊÇ†Á¥Ä, ‰∏≠Â≥∂ ÊÖé‰ªã, ÁâßÈáé Â∞ÜÂêæ, È¨ºÂ°ö ÁõõÂÆá, ÈÉΩÁØâ Êï¨, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>„Ç≥„Ç¢„Éª„Ç∑„Çß„É´ÊßãÈÄ†„ÇíÊúâ„Åô„Çã6Ëª∏ÂäõË®àÊ∏¨„É¢„Ç∏„É•„Éº„É´„Çí„Å§„ÅæÂÖà„ÉªË∏µ„Å´ÊåÅ„Å§Ë∂≥ÈÉ®„É¶„Éã„ÉÉ„Éà„ÇíÁî®„ÅÑ„ÅüÁ≠âË∫´Â§ßÁ≠ãÈ™®Ê†ºËÖ±ÈßÜÂãï„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„Çã„Éö„ÉÄ„É´Ë∏è„Åø„ÉªÂæ©Â∏∞Âãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 1A1-K01, 2019</li>
<li>È¨ºÂ°ö ÁõõÂÆá, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Êñ∞Âüé ÂÖâÊ®π, ÈÉΩÁØâ Êï¨, ‰∏≠Â≥∂ ÊÖé‰ªã, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãÈù¢Áä∂ÁâΩÂºïÊßãÈÄ†„ÇíÊúâ„Åô„ÇãÈñ¢ÁØÄ„ÅÆÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'19 (<b>ROBOMECH19J</b>)</i>, 1A1-J02, 2019</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÈÉΩÁØâ Êï¨, ÁâßÈáé Â∞ÜÂêæ, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†ºÊßãÈÄ†„Å´„Åä„Åë„ÇãÈï∑ÊúüÁöÑËá™Â∑±Ë∫´‰ΩìÂÉèÁç≤Âæó„Å®ÂèØÂ§âÂâõÊÄßÂà∂Âæ°„ÅÆÂÆüÁèæ, in <i>Á¨¨36ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ18J</b>)</i>, 1J2-02, 2018</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁúüÂ£Å ‰Ωë, ÁâßÈáé Â∞ÜÂêæ, ÈÉΩÁØâ Êï¨, Ê∞∏Êùæ Á•êÂº•, ÊµÖÈáé ÊÇ†Á¥Ä, ÁôΩ‰∫ï ÊãìÁ£®, ËèÖ‰∫ï Êñá‰ªÅ, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Áí∞Â¢ÉÊé•Ëß¶„Çí‰º¥„ÅÜÂ≠¶ÁøíÂûãÂà∂Âæ°Á†îÁ©∂„ÅÆ„Åü„ÇÅ„ÅÆÁ≠ãÈ™®Ê†ºÂûãÂÄíÁ´ã‰∫åËº™„É≠„Éú„ÉÉ„Éà„ÅÆÈñãÁô∫, in <i>Á¨¨36ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ18J</b>)</i>, 1P2-02, 2018</li>
<li>ÈÉΩÁØâ Êï¨, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, È¨ºÂ°ö ÁõõÂÆá, ÁúüÂ£Å ‰Ωë, ÁâßÈáé Â∞ÜÂêæ, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Çà„ÇãËá™ÂãïËªäÈÅãËª¢Âãï‰Ωú„ÅÆÂÆüÁèæ„Å´Âêë„Åë„Åü„Éö„ÉÄ„É´Êìç‰ΩúÊà¶Áï•, in <i>Á¨¨36ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ18J</b>)</i>, 2P1-05, 2018</li>
<li>È¨ºÂ°ö ÁõõÂÆá, ÁúüÂ£Å ‰Ωë, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãËÑöÂÖ®‰Ωì„ÅÆÁ≠ã„Å´Âü∫„Å•„ÅèÁ≠ãÂºµÂäõ ZMP „ÇíÁî®„ÅÑ„ÅüÂπ≥Ë°°Âãï‰Ωú, in <i>Á¨¨36ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ18J</b>)</i>, 1J2-05, 2018</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Èô≥ Áõ∏ÁæΩ, Ëó§‰∫ï Á∂∫È¶ô, Â∑ùÊùë Â∞ÜÁü¢, ÁúüÂ£Å ‰Ωë, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Êì¨‰ººÁêÉÈñ¢ÁØÄ„É¢„Ç∏„É•„Éº„É´„Å´„Çà„ÇäÂÜóÈï∑„Å™ÈùûÁ∑öÂΩ¢ÂºæÊÄßË¶ÅÁ¥†„ÇíÂà∂Âæ°ÂèØËÉΩ„Å™Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆ‰∏äËÇ¢Ë®≠Ë®à, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G09, 2018</li>
<li>ÁâßÈáé Â∞ÜÂêæ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Ëó§‰∫ï Á∂∫È¶ô, Â∑ùÊùë Â∞ÜÁü¢, ÁúüÂ£Å ‰Ωë, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>ÁµÑ„ÅøÂêà„Çè„ÅõÂàáÂâä„Å∞„Å≠„Å´„Çà„ÇãÂ∫ÉÂèØÂãïÂüüÈñ¢ÁØÄÊØçÊåáÈñ¢ÁØÄ„Å®ÂèØÂ§âÂâõÊÄßÊåáÈñ¢ÁØÄ„Çí„ÇÇ„Å§‰∫∫‰ΩìÊ®°ÂÄ£Âûã‰∫îÊåá„Éè„É≥„Éâ„ÅÆÈñãÁô∫, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'18 (<b>ROBOMECH18J</b>)</i>, 1P1-H16, 2018</li>
<li>ÁúüÂ£Å ‰Ωë, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Â∑ùÊùë Â∞ÜÁü¢, Ëó§‰∫ï Á∂∫È¶ô, È¨ºÂ°ö ÁõõÂÆá, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãÂèØÂãïÁúºÁêÉ„ÅÆÈñãÁô∫„Å®Ëªä‰∏°Ë¶ãÂõû„ÅóÁô∫ÈÄ≤Âãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G11, 2018</li>
<li>ÊµÖÈáé ÊÇ†Á¥Ä, Â∑ùÊùë Â∞ÜÁü¢, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Ëó§‰∫ï Á∂∫È¶ô, ÁúüÂ£Å ‰Ωë, È¨ºÂ°ö ÁõõÂÆá, Â≤°Áî∞ ÊÖß, Â∑ùÂ¥é ÂÆèÊ≤ª, Á®≤Ëëâ ÈõÖÂπ∏<br>‰∫∫‰ΩìÊ®°ÂÄ£Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãÁ≠ãÂºµÂäõ„ÇíÁî®„ÅÑ„ÅüÈñ¢ÁØÄÁ©∫Èñì„Ç≥„É≥„Éà„É≠„Éº„É©„Å´„Çà„ÇãËªä‰∏°„Éö„ÉÄ„É´Êìç‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'18 (<b>ROBOMECH18J</b>)</i>, 2A2-G07, 2018</li>
<li>Ëó§‰∫ïÁ∂∫È¶ô, ‰∏≠Â≥∂ÊÖé‰ªã, Â∑ùÊùëÂ∞ÜÁü¢, <b><u>Ê≤≥ÂéüÂ°öÂÅ•‰∫∫</u></b>, ÁâßÈáéÂ∞ÜÂêæ, ÊµÖÈáéÊÇ†Á¥Ä, Â≤°Áî∞ÊÖß, Á®≤ËëâÈõÖÂπ∏<br>‰∫∫‰Ωì„ÅÆÈñ¢ÁØÄÂåÖÊßãÈÄ†„Å´Á§∫ÂîÜ„ÇíÂæó„ÅüÊüîËªü„Åß‰º∏Á∏ÆÂ§âÂΩ¢ÂèØËÉΩ„Å™ËÜúÊßãÈÄ†„ÇíÂÇô„Åà„ÅüÈñãÊîæÂûãÁêÉÈñ¢ÁØÄ„ÅÆÈñãÁô∫, in <i>Á¨¨18ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI17J</b>)</i>, 3B4-02, 2017</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Â∑ùÊùë Â∞ÜÁü¢, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å´„Åä„Åë„ÇãË¶ñË¶ö„ÇíÂà©Áî®„Åó„ÅüÈñ¢ÁØÄ-Á≠ãÁ©∫Èñì„Éû„ÉÉ„Éó„ÅÆÈÄêÊ¨°ÁöÑÂÜçÂ≠¶Áøí, in <i>Á¨¨35ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ17J</b>)</i>, 2L1-01, 2017</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÁâßÈáé Â∞ÜÂêæ, Â∑ùÊùë Â∞ÜÁü¢, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>È™®ÊßãÈÄ†‰∏Ä‰ΩìÂ∞èÂûãÁ≠ã„É¢„Ç∏„É•„Éº„É´„Å´„Çà„ÇäÊßãÊàê„Åï„Çå„ÅüÊ©àÈ™®Â∞∫È™®ÊßãÈÄ†„ÇíÊúâ„Åô„ÇãÂâçËÖïÈÉ®„ÅÆË®≠Ë®à, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'17 (<b>ROBOMECH17J</b>)</i>, 1A1-O11, 2017</li>
<li>ÁâßÈáé Â∞ÜÂêæ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â∑ùÊùë Â∞ÜÁü¢, ÊµÖÈáé ÊÇ†Á¥Ä, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆ„Åü„ÇÅ„ÅÆÂàáÂâä„Å∞„Å≠„Å´„Çà„ÇãÊüîËªüÈñ¢ÁØÄ„ÇíÂÇô„Åà„Åü‰∫îÊåá„Éè„É≥„Éâ„ÅÆÈñãÁô∫„Å®Ëá™Â∑±Ë∫´‰ΩìË≤†Ëç∑‰øùÊåÅÂãï‰Ωú„ÅÆÂÆüÁèæ, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'17 (<b>ROBOMECH17J</b>)</i>, 2P1-B08, 2017, <b><font color='red'>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºöËã•ÊâãÂÑ™ÁßÄË¨õÊºî„Éï„Çß„É≠„ÉºË≥û</font></b></li>
</ol>
<h3> Invited Talks, Books, etc.</h3>
<ol>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„É≠„Éú„ÉÉ„ÉàÂü∫Áõ§„É¢„Éá„É´Á†îÁ©∂„ÅÆÁèæÁä∂„Å®‰ªäÂæå, ÊãõÂæÖË¨õÊºî, in <i>ÊÉÖÂ†±Âá¶ÁêÜÂ≠¶‰ºöÈÄ£Á∂ö„Çª„Éü„Éä„Éº</i>, 2025.9.25<br> <a href=https://www.ipsj.or.jp/event/seminar/2025/program06.html target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„É≠„Éú„ÉÉ„ÉàÂü∫Áõ§„É¢„Éá„É´Á†îÁ©∂„ÅÆÊúÄÂâçÁ∑ö, ÊãõÂæÖË¨õÊºî, in <i>MIRU2025„ÉÅ„É•„Éº„Éà„É™„Ç¢„É´</i>, 2025.7.29<br> <a href=https://cvim.ipsj.or.jp/MIRU2025/tutorial.html target='_blank'>[Website]</a> <a href=https://speakerdeck.com/haraduka/miru2025-tiyutoriarujiang-yan-robotutoji-pan-moderunozui-qian-xian target='_blank'>[Slide]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπÂõõËÑö„É≠„Éú„ÉÉ„ÉàMEVIUS„Å®„Åù„ÅÆÁô∫Â±ï, ÊãõÂæÖË¨õÊºî, in <i>ROBOMECH2025„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„Éó Ê©üÊ¢∞Â≠¶Áøí„Å®‰∫∫Âûã„ÉªÂ§öËÑö„ÉªÂ§öÈñ¢ÁØÄ„É≠„Éú„ÉÉ„ÉàÔΩûÁ†îÁ©∂ÔºÜ„Éì„Ç∏„Éç„Çπ„Éà„É¨„É≥„ÉâÊúÄÂâçÁ∑öÔΩû</i>, 2025.6.4<br> <a href=https://rt-net.jp/robomech2025ws/ target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Âü∫Áõ§„É¢„Éá„É´„Å®„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„ÅÆËûçÂêà, ÊãõÂæÖË¨õÊºî, in <i>Êù±ÂåóÂ§ßÂ≠¶ „Çø„ÉïÔΩ•„Çµ„Ç§„Éê„Éº„Éï„Ç£„Ç∏„Ç´„É´AIÁ†îÁ©∂„Çª„É≥„Çø„Éº„Ç∑„É≥„Éù„Ç∏„Ç¶„É†2025</i>, 2025.6.3<br> <a href=http://tcpai.tohoku.ac.jp/sympo2025/ target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„Éï„Ç£„Ç∏„Ç´„É´AI„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ†îÁ©∂ÈñãÁô∫ÔΩûË∫´‰ΩìÊÄß„Å´Âü∫„Å•„ÅèÁü•ËÉΩ„ÅÆÁ†îÁ©∂ÔΩû, „Éë„Éç„É™„Çπ„Éà, in <i>JSAI2025‰ºÅÁîª„Çª„ÉÉ„Ç∑„Éß„É≥</i>, 2025.5.28<br> <a href=https://www.jst.go.jp/crds/sympo/JSAI2025_physicalai/index.html target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>ÁîüÊàêAI„ÅÆ„É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÂøúÁî®, „Çª„Éü„Éä„ÉºË¨õÂ∏´, in <i>IEICEÂÖàÁ´Ø„Çª„Éü„Éä„Éº</i>, 2025.5.1<br> <a href=https://www.ieice.org/jpn_r/activities/advanced_seminar.html target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids for Human-like Embodied Intelligence, Short Talk and Panelist, in <i>2025 International Conference on Embodied Intelligence (EI)</i>, 2025.4.2<br> <a href=https://embodied-intelligence.org/embodied-intelligence-conference25/ target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>ÁßëÂ≠¶ÊäÄË°ìÊú™Êù•Êà¶Áï•„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„ÉóÂ†±ÂëäÊõ∏„Äå„Éï„Ç£„Ç∏„Ç´„É´AI„Ç∑„Çπ„ÉÜ„É†„Äç, „Éë„Éç„É™„Çπ„Éà, in <i>JST CRDS Á†îÁ©∂ÈñãÁô∫Êà¶Áï•„Çª„É≥„Çø„Éº</i>, 2025.3.28<br> <a href=https://www.jst.go.jp/crds/report/CRDS-FY2024-WR-07.html target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Âü∫Áõ§„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî®, ÊãõÂæÖË¨õÊºî, in <i>„Éë„Çø„Éº„É≥Ë™çË≠ò„Éª„É°„Éá„Ç£„Ç¢ÁêÜËß£Á†îÁ©∂‰ºö (PRMU)</i>, 2025.3.18<br> <a href=https://ken.ieice.org/ken/paper/20250318ac9c/ target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å®Âü∫Áõ§„É¢„Éá„É´, Ë©±È°åÊèê‰æõ, in <i>LLM-jp ÂÆüÁí∞Â¢É„Ç§„É≥„Çø„É©„ÇØ„Ç∑„Éß„É≥WG</i>, 2025.2.14</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„É≠„Éú„ÉÉ„Éà„Å´„Åä„Åë„ÇãData-centric AI, in <i>Á¨¨13Âõû Data-Centric AIÂãâÂº∑‰ºö -Data-centric AIÂÖ•ÈñÄ ËëóËÄÖLTÂ§ß‰ºö-</i>, 2025.2.12<br> <a href=https://dcai-jp.connpass.com/event/342802/ target='_blank'>[Website]</a></li>
<li>ÁâáÂ≤° Ë£ïÈõÑ (Áõ£‰øÆ), ÈΩãËó§ÈÇ¶Á´†, Ê∏ÖÈáéËàú, Â∞èÊûóÊªâÊ≤≥, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, ÂÆÆÊæ§ ‰∏Ä‰πã, Èà¥Êú® ÈÅîÂìâ<br>Data-centric AIÂÖ•ÈñÄ, in <i>ÊäÄË°ìË©ïË´ñÁ§æ</i>, 2025.01.08<br> <a href=https://gihyo.jp/book/2025/978-4-297-14663-4 target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>The Point of Tendon-driven Musculoskeletal Humanoids, Invited Talk, in <i>VANJ (Vietnamese Academic Network in Japan) Conference</i>, 2024.12.07<br> <a href=https://conf.vanj.jp/2024/speakers/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>History and Future of Tendon-driven Musculoskeletal Humanoids, in <i>TAI AHR #03 - AI in Hardware and Robotics</i>, 2024.12.06<br> <a href=https://lu.ma/ppgh4amz target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>History and Future of Tendon-driven Musculoskeletal Humanoids, Plenary Talk, in <i>2024 IEEE International Conference on Humanoid Robots (Humanoids)</i>, 2024.11.23<br> <a href=https://2024.ieee-humanoids.org/plenaries/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Building Intelligent Robots: From Musculoskeletal Humanoids to Foundation Models, in <i>Seminar at KIT, Karlsruhe</i>, 2024.11.20</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>IROS/ICRA„ÅÆ„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„ÉóÈñãÂÇ¨„ÅÆÁµåÈ®ì„Å®Â±ïÊúõ ~ Cooking Robotics Workshop@ICRA 2024„Çí‰∏ªÂÇ¨„Åó„Å¶ ~, in <i>Á¨¨42ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö Â≠¶Ë°ì„É©„É≥„ÉÅ„Éß„É≥„Çª„Éü„Éä„Éº</i>, 2024.9.5<br> <a href=https://speakerdeck.com/haraduka/rsj2024xue-shu-rantiyonsemina-ruo-shou-zhong-jian-niyoruguo-ji-hua-ridasitupunixiang-kete-zi-liao-he-yuan-zhong target='_blank'>[Slide]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at DLR, Oberpfaffenhofen</i>, 2024.7.31</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at TUM, Munich</i>, 2024.7.30</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at Max Planck Institute, Tubingen</i>, 2024.7.29</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Seminar at EPFL, Lausanne</i>, 2024.7.5</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>CRL Seminar at ETH Zurich</i>, 2024.6.28</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Musculoskeletal Humanoids, Wire-driven Robots, and Beyond, in <i>Postdoc Seminar at IIT, Genova</i>, 2024.6.20</li>
<li><b><u>Kento Kawaharazuka</u></b><br>Robotic Imitation Learning for Biomedical Applications, in <i>Symposium on Robotics in Biomedical Applications</i>, 2024.6.17<br> <a href=https://sites.google.com/view/srbm/home target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>LLM„ÉªVLM„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî®‰æã„Å®„Åù„ÅÆÂàÜÈ°û, Ë¨õÂ∏´, in <i>Á¨¨152Âõû„É≠„Éú„ÉÉ„ÉàÂ∑•Â≠¶„Çª„Éü„Éä„Éº„Äå„É≠„Éú„ÉÉ„Éà„ÅÆ„Åü„ÇÅ„ÅÆLLM„ÉªVLM Âà©Ê¥ªÁî®„Äç</i>, 2024.5.23<br> <a href=https://www.rsj.or.jp/event/seminar/news/2024/s152.html target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Âü∫Áõ§„É¢„Éá„É´„ÇíÁî®„ÅÑ„Åü„É≠„Éú„ÉÉ„Éà„ÅÆÂãï‰ΩúË®àÁîª„Å®Âà∂Âæ°, ÊãõÂæÖË¨õÊºî, in <i>ROS Japan UG #55 PlannerÁâπÈõÜÔºÅ</i>, 2024.5.21<br> <a href=https://rosjp.connpass.com/event/313794/ target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>What is Necessary to Cook Curry with a Robot?, Workshop on "Cooking Robotics: Perception and motion planning", in <i>2024 IEEE International Conference on Robotics and Automation (ICRA)</i>, 2024.5.17<br> <a href=https://sites.google.com/view/icra2024cookingrobotics/home target='_blank'>[Website]</a></li>
<li><b><u>Kento Kawaharazuka</u></b><br>Tendon-driven Musculoskeletal Humanoids and Beyond, Workshop on "From Layers to Limbs! Exploring the Interface of 3D Printing and Bio-Inspired Musculoskeletal Robotics", in <i>2024 IEEE International Conference on Soft Robotics (RoboSoft)</i>, 2024.4.14<br> <a href=https://printed-musculoskeletal-robots.ethz.ch/ target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>„É≠„Éú„ÉÉ„ÉàÁ†îÁ©∂„Å´„Åä„Åë„ÇãLLM„ÅÆÂÆü‰∏ñÁïåÂøúÁî®, ÊãõÂæÖË¨õÊºî, in <i>NLP2024‰ΩµË®≠„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„Éó„ÄåÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÅÆÂÆü‰∏ñÁïåÂøúÁî®„Äç</i>, 2024.3.15<br> <a href=https://sites.google.com/grp.riken.jp/langrobonlp2024 target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Á≠ãÈ™®Ê†º„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Å®Ë∫´‰ΩìÂõ≥ÂºèÂ≠¶Áøí, ÊãõÂæÖË¨õÊºî, in <i>Á¨¨19ÂõûË∫´‰ΩìÊÄßË™çÁü•ÁßëÂ≠¶„Å®ÂÆü‰∏ñÁïåÂøúÁî®„Å´Èñ¢„Åô„ÇãËã•ÊâãÁ†îÁ©∂‰ºö(ECSRA)</i>, 2023.10.29<br> <a href=https://sites.google.com/site/ecsrawebsite/%E8%BA%AB%E4%BD%93%E6%80%A7%E8%AA%8D%E7%9F%A5%E7%A7%91%E5%AD%A6%E3%81%A8%E5%AE%9F%E4%B8%96%E7%95%8C%E5%BF%9C%E7%94%A8%E3%81%AB%E9%96%A2%E3%81%99%E3%82%8B%E8%8B%A5%E6%89%8B%E7%A0%94%E7%A9%B6%E4%BC%9A-ecsra target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„ÉàÂøúÁî®‰æã, ÊãõÂæÖË¨õÊºî, in <i>Á¨¨5ÂõûLLMÂãâÂº∑‰ºö(LLM-jp)</i>, 2023.10.18<br> <a href=https://llm-jp.nii.ac.jp/llm/2023/10/18/meeting-5.html target='_blank'>[Website]</a></li>
<li><b><u>K. Kawaharazuka</u></b><br>Learning-based manipulation and grasping with flexible arms and hands, Workshop on "Learning Meets Model-based Methods for Manipulation and Grasping", in <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2023.10.5<br> <a href=https://sites.google.com/view/learning-meets-models-iros2023/speakers?authuser=0 target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÅÆÂÆü„É≠„Éú„ÉÉ„Éà„Çø„Çπ„ÇØÂøúÁî®, ÊãõÂæÖ„Çª„ÉÉ„Ç∑„Éß„É≥, in <i>NLPËã•Êâã„ÅÆ‰ºö Á¨¨18Âõû„Ç∑„É≥„Éù„Ç∏„Ç¶„É† (YANS2023)</i>, 2023.8.31<br> <a href=https://yans.anlp.jp/entry/yans2023invitesession target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>ËÑ±ÂäõÂèØËÉΩ„Å™„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÅÆË∫´‰Ωì„Å®Âà∂Âæ°, „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö2023„Ç∑„É≥„Éù„Ç∏„Ç¶„É†„Äå"„ÅÑ„ÅÑ„Åã„Åí„Çì"„ÇíÁßëÂ≠¶„Åó„Å¶Êú™Êù•„ÇíÂâµ„Çã„ÇΩ„Éï„Éà„É≠„Éú„ÉÉ„ÉàÂ≠¶4„Äç, in <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö</i>, 2023.6.28<br> <a href=https://softrobot.jp/events/2023/06161205082540/ target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Ë∫´‰ΩìÂõ≥Âºè„ÅÆËá™ÂæãÁç≤ÂæóÊ©üËÉΩ„ÇíÊúâ„Åô„ÇãÁü•ËÉΩ„É≠„Éú„ÉÉ„Éà„Ç∑„Çπ„ÉÜ„É†„Å®„Çµ„Ç§„Ç®„É≥„ÇπÈñãÊãì, Ëã•ÊâãÁ†îÁ©∂ËÄÖ„ÅåÊèè„Åè2050Âπ¥„ÅÆAI„É≠„Éú„ÉÉ„Éà„Éì„Ç∏„Éß„É≥ („Ç™„Éº„Éó„É≥„Éï„Ç©„Éº„É©„É†: „É†„Éº„É≥„Ç∑„Éß„ÉÉ„ÉàÂûãÁ†îÁ©∂„ÅßÁõÆÊåá„ÅôAI„É≠„Éú„ÉÉ„Éà), in <i>Á¨¨40ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö</i>, 2022.9.9<br> <a href=https://ac.rsj-web.org/2022/openforum.html#OF5 target='_blank'>[Website]</a></li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Ë∫´‰ΩìÂõ≥Âºè„ÅÆÈÄêÊ¨°Â≠¶ÁøíÊ©üËÉΩ„ÇíÊúâ„Åô„ÇãÁü•ËÉΩ„É≠„Éú„ÉÉ„Éà„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ†îÁ©∂, in <i>ÂçöÂ£´Ë´ñÊñá</i>, <b><font color='red'>Á†îÁ©∂ÁßëÈï∑Ë≥û</font></b>, 2022.3.24</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Ê∑±Â±§‰∫àÊ∏¨„É¢„Éá„É´Â≠¶Áøí„Å´„Çà„Çã„É≠„Éú„ÉÉ„Éà„ÅÆÊôÇÈñìÁöÑ„ÉªÁ©∫ÈñìÁöÑÊüîËªüÊÄßÊîªÁï•, „Ç≠„Éº„Éé„Éº„ÉàË¨õÊºî (OS: Á¢∫Áéá„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Å®„Éá„Éº„ÇøÂ∑•Â≠¶„É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÔΩûË™çË≠ò„ÉªË°åÂãïÂ≠¶Áøí„ÉªË®òÂè∑ÂâµÁô∫ÔΩû), in <i>Á¨¨39ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö</i>, 2021.9.6</li>
</ol>
        <!-- publication_replace_by_python -->

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Awards (Publication) </h2>
        </div>

<ol>
<li>S. Kim, N. Kanazawa, S. Hasegawa, <b><u>K. Kawaharazuka</u></b>, K. Okada<br>Best Student Paper Finalist, <i>2025 IEEE/SICE International Symposium on System Integration (<b>SII2025</b>)</i>, 2025.1.24</li>
<li>‰∫ï‰∏ä ‰ø°Â§öÈÉé, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Èà¥Êú® Â§©È¶¨, ÂãáÂ¥é È¢ØÂ§™, ÊùéÊûó ÂòâÂÖÉ, ‰ΩêÂéü ‰æëÂ§™, Â≤°Áî∞ ÊÖß<br>ÂÑ™ÁßÄË¨õÊºîË≥û, <i>Á¨¨25ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI24J</b>)</i>, 2024.12.20</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, ÈáëÊ≤¢ Áõ¥ÊôÉ, Â°öÊú¨ Áõ¥‰∫∫, Â≤°Áî∞ ÊÖß<br>ÂÑ™ÁßÄË¨õÊºîË≥û, <i>Á¨¨25ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI24J</b>)</i>, 2024.12.20</li>
<li>S. Inoue, <b><u>K. Kawaharazuka</u></b>, T. Suzuki, S. Yuzaki, Y. Ribayashi, Y. Sahara, K. Okada<br>Mike Stillman Award, <i>2024 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2024</b>)</i>, 2024.11.24</li>
<li><b><u>K. Kawaharazuka</u></b>, Y. Obinata, N. Kanazawa, N. Tsukamoto, K. Okada<br>Excellent Practice Award, <i>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2024</b>)</i>, (<b>Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects</b>), 2024.10.14</li>
<li>Open X-Embodiment Collaboration<br>Finalists of Best Paper Award in Robot Manipulation, <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, 2024.5.16</li>
<li>Open X-Embodiment Collaboration<br>Best Conference Paper Award, <i>2024 IEEE International Conference on Robotics and Automation (<b>ICRA2024</b>)</i>, 2024.5.16</li>
<li>ÈáëÊ≤¢ Áõ¥ÊôÉ, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â§ßÊó•Êñπ ÊÖ∂Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÑ™ÁßÄË¨õÊºîË≥û, <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 2023.12.16</li>
<li>‰∏âÊú® Á´†ÂØõ, ‰ΩêÂéü ‰æëÂ§™, Ê∑±Â±± ÂíåÊµ©, ÊùéÊûó ÂòâÂÖÉ, Èï∑Ë∞∑Â∑ù Â≥ª, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÑ™ÁßÄË¨õÊºîË≥û, <i>Á¨¨24ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI23J</b>)</i>, 2023.12.15</li>
<li>‰∏âÊú® Á´†ÂØõ, ÊùøÊù± Ê≠£Á•ê, Ê∞∏Êùæ Á•êÂº•, <b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Âà©ÂÖâ Ê≥∞Âæ≥, Âπ≥Â≤° Áõ¥Ê®π, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>Á¨¨3ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ÂÑ™ÁßÄÁ†îÁ©∂„ÉªÊäÄË°ìË≥û, <i>Á¨¨28Âõû„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Ç∑„É≥„Éù„Ç∏„Ç¢ (<b>ROBOSYM23J</b>)</i>, 2023.9.13</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„Éô„Çπ„Éà„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥Ë≥û, <i>Êó•Êú¨Ê©üÊ¢∞Â≠¶‰ºö„É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„Éª„É°„Ç´„Éà„É≠„Éã„ÇØ„ÇπË¨õÊºî‰ºö'22 (<b>ROBOMECH22J</b>)</i>, 2023.6.29</li>
<li><b><u>K. Kawaharazuka</u></b>, A. Miki, M. Bando, T. Suzuki, Y. Ribayashi, Y. Toshimitsu, Y. Nagamatsu, K. Okada, M. Inaba<br>Best Interactive Paper Award Finalist, <i>2022 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2022</b>)</i>, 2022.11.30</li>
<li><b><u>K. Kawaharazuka</u></b><br>SICE International Young Authors Award (SIYA-IROS2022), <i>IEEE Robotics and Automation Letters (<b>RAL</b>)</i>, 2022.10.26</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Á†îÁ©∂ÁßëÈï∑Ë≥û, <i>ÂçöÂ£´Ë´ñÊñá</i>, 2022.3.24</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Êñ∞Âüé ÂÖâÊ®π, Ê≤≥Êùë Ê¥ã‰∏ÄÈÉé, Â≤°Áî∞ ÊÖß, Á®≤Ëëâ ÈõÖÂπ∏<br>ÂÑ™ÁßÄË¨õÊºîË≥û, <i>Á¨¨22ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI21J</b>)</i>, 2021.12.24</li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Finalists of Mike Stilman Paper Award, <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, 2021.7.21</li>
<li>M. Onitsuka, M. Nishiura, <b><u>K. Kawaharazuka</u></b>, K. Tsuzuki, Y. Toshimitsu, Y. Omura, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>Best Oral Paper Award, <i>2020 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2020</b>)</i>, 2021.7.21</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b>, Â∞èÂ∑ù Âæπ, ÈçãÂ∂å ÂéöÂ§™<br>ÂÑ™ÁßÄË¨õÊºîË≥û, <i>Á¨¨21ÂõûSICE„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„ÉÜ„Ç∞„É¨„Éº„Ç∑„Éß„É≥ÈÉ®ÈñÄË¨õÊºî‰ºö (<b>SI20J</b>)</i>, 2020.12.25</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÁ¨¨35ÂõûÁ†îÁ©∂Â•®Âä±Ë≥û, <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 2020.10.9</li>
<li><b><u>Ê≤≥ÂéüÂ°ö ÂÅ•‰∫∫</u></b><br>Êó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÁ¨¨35ÂõûÁ†îÁ©∂Â•®Âä±Ë≥û, <i>Á¨¨37ÂõûÊó•Êú¨„É≠„Éú„ÉÉ„ÉàÂ≠¶‰ºöÂ≠¶Ë°ìË¨õÊºî‰ºö (<b>RSJ19J</b>)</i>, 2020.10.9</li>
<li><b><u>K. Kawaharazuka</u></b><br>Company of Biologists Early Career Researcher Grant (500 GBP), <i>9th International Symposium on Adaptive Motion of Animals and Machines (<b>AMAM2019</b>)</i>, 2019.8.20</li>
<li>S. Makino, <b><u>K. Kawaharazuka</u></b>, M. Kawamura, A. Fujii, T. Makabe, M. Onitsuka, Y. Asano, K. Okada, K. Kawasaki, M. Inaba<br>IROS ICROS Best Application Paper Award 2018 Finalists, <i>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2018</b>)</i>, 2018.10.2</li>
<li><b><u>K. Kawaharazuka</u></b><br>IEEE RAS Japan Joint Chapter Young Award (2017), <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS2017</b>)</i>, 2017.9.24</li>
<li>Y. Asano, T. Kozuki, S. Ookubo, M. Kawamura, S. Nakashima, T. Katayama, Y. Iori, H. Toshinori, <b><u>K. Kawaharazuka</u></b>, S. Makino, Y. Kakiuchi, K. Okada, M. Inaba<br>Best Interactive Paper Award Finalist, <i>2016 IEEE-RAS International Conference on Humanoid Robots (<b>HUMANOIDS2016</b>)</i>, 2016.11.17</li>
</ol>
          <!-- award_replace_by_python -->

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Awards and Experiences (Others) </h2>
        </div>
        <ol>
          <li>First Place (GPSR task in DSPL), RoboCup@Home JapanOpen2022, 2023.3.6 - 2023.3.9</li>
          <li>First Prize (state-based category), <a href="https://uzh-rpg.github.io/icra2022-dodgedrone/" target='_blank'>ICRA 2022 DodgeDrone Challenge</a>, 2022.5.26</li>
          <li>Part-time Enginner at <a href="https://www.preferred-networks.jp/en/" target='_blank'>Preferred Networks</a>, 2018.10 - 2020.3</li>
          <li>Internship at <a href="https://www.preferred-networks.jp/en/" target='_blank'>Preferred Networks</a>, 2018.8 - 2018.9</li>
          <li>Oral Presentation Award (Second Prize), <a href="http://deeplearning.jp/deeplearningday2018/" target='_blank'>Deep Learning Day 2018</a>, 2018.1.20</li>
          <li>Code Thanks Festival 2017, 2017.12.2</li>
          <li>Jaxa Award (Second Prize), <a href="http://moonhack.jp.klab.com/" target='_blank'>Moon Hack Hackathon 2017</a>, 2017.11.11 - 2017.11.12</li>
          <li>Final Round of Code Festival 2016, 2016.11.26 - 2016.11.27</li>
          <li>2nd RUNNER-UP and ABU ROBOCON AWARD, <a href="http://aburobocon.net/" target='_blank'>ABU Robot Contest 2016</a>, Clean Energy Recharging the World, 2016.8.21</li>
          <li>First Prize <a href="https://official-robocon.com/history/gakusei/about/history/twentyfive/" target='_blank'>NHK Student Robot Contest 2016</a>, Clean Energy Recharging the World, 2016.7.10</li>
          <li>Outstanding Performance Award, Internship at <a href="http://www.worksap.com/" target='_blank'>Works Applications Co., Ltd.</a>, 2016.3.4 - 2016.3.31</li>
          <li>Internship at <a href="http://www.futurestandard.co.jp/about/" target='_blank'>Future Standard Co., Ltd.</a>, 2016.1 - 2016.4</li>
          <li>Third Prize (Senior Division), <a href="http://www.lsse.kyutech.ac.jp/~sociorobo/ja/tomato-robot2015" target='_blank'>Tomato Robot Challenge</a>, 2015.12.18 - 2015.12.20</li>
          <li>Final Round of CODE RUNNER 2015, 2015.12.12</li>
          <li>Final Round of Code Festival 2015, 2015.11.14 - 2015.11.15</li>
          <li>Internship at <a href="https://www.hioki.com/en/" target='_blank'>HIOKI E.E. CORPORATION</a>, 2015.8.17 - 2015.8.28</li>
          <li>Technical Award, <a href="https://official-robocon.com/history/gakusei/about/history/twenty-fourth/" target='_blank'>NHK Student Robot Contest 2015</a>, ROBOMINTON:BADMINTON ROBO GAME (Pit Member), 2015.6.7</li>
          <li>Dowango Award (11/372), <a href="https://icpc.iisf.or.jp/2015-tsukuba/domestic/?lang=en" target='_blank'>ICPC Domestic Preliminary Contest</a>, 2015.6.26</li>
          <li>Final Round of <a href="http://www.ipsj.or.jp/event/samuraicoding/2014-15/index.html" target='_blank'>SamurAI Coding 2014-2015</a>, 2015.3.18</li>
          <li>Final Round of CODE RUNNER 2014, 30, November, 2014</li>
          <li>Technical Award, <a href="http://f3rcontest.web.fc2.com/index.html" target='_blank'>Freshman's Robot Contest 2013 (F^3RC)</a>, 2013.9.29</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Grants-in-Aid and Scholarship </h2>
        </div>
        <ol>
          <li> <b>CRONOS (ÂàÜÊãÖ)</b>, ÁßëÂ≠¶ÊäÄË°ìÊåØËààÊ©üÊßã (JST), 2024.10 - 2030.3 </li>
          <li> <b>ÂâµÁô∫ÁöÑÁ†îÁ©∂ÊîØÊè¥‰∫ãÊ•≠ (‰ª£Ë°®)</b>, ÁßëÂ≠¶ÊäÄË°ìÊåØËààÊ©üÊßã (JST), 2024.10 - 2032.3 </li>
          <li> <b>Âü∫Áõ§Á†îÁ©∂B (‰ª£Ë°®)</b>, Êó•Êú¨Â≠¶Ë°ìÊåØËàà‰ºö (JSPS), 2023.4 - 2027.3 </li>
          <li> <b>ÊåëÊà¶ÁöÑËêåËäΩ (‰ª£Ë°®)</b>, Êó•Êú¨Â≠¶Ë°ìÊåØËàà‰ºö (JSPS), 2023.4 - 2026.3 </li>
          <li> <b>ACT-XÂä†ÈÄü„Éï„Çß„Éº„Ç∫ (‰ª£Ë°®)</b>, ÁßëÂ≠¶ÊäÄË°ìÊåØËààÊ©üÊßã (JST), 2023.4 - 2024.3 </li>
          <li> <b>Á†îÁ©∂Ê¥ªÂãï„Çπ„Çø„Éº„ÉàÊîØÊè¥ (‰ª£Ë°®)</b>, Êó•Êú¨Â≠¶Ë°ìÊåØËàà‰ºö (JSPS), 2022.4 - 2024.3 </li>
          <li> <b>ACT-X (‰ª£Ë°®)</b>, ÁßëÂ≠¶ÊäÄË°ìÊåØËààÊ©üÊßã (JST), 2020.12 - 2023.3 </li>
          <li> <b>ÁâπÂà•Á†îÁ©∂Âì° (DC1)</b>, Êó•Êú¨Â≠¶Ë°ìÊåØËàà‰ºö (JSPS), 2019.4 ‚Äì 2022.3 </li>
          <li> <b>„Éà„É®„Çø„Éª„Éâ„ÉØ„É≥„Ç¥È´òÂ∫¶‰∫∫Â∑•Áü•ËÉΩ‰∫∫ÊùêÂ•®Â≠¶Èáë</b>, 2021.4 - 2022.3 </li>
          <li> <b>„Éà„É®„Çø„Éª„Éâ„ÉØ„É≥„Ç¥È´òÂ∫¶‰∫∫Â∑•Áü•ËÉΩ‰∫∫ÊùêÂ•®Â≠¶Èáë</b>, 2020.4 - 2021.3 </li>
          <li> <b>Ëã•ÊâãÁ†îÁ©∂ËÄÖÊµ∑Â§ñÊåëÊà¶„Éó„É≠„Ç∞„É©„É†</b>, Êó•Êú¨Â≠¶Ë°ìÊåØËàà‰ºö (JSPS), 2020.4 ‚Äì 2020.8 (Covid-19„Å´„Çà„ÇäËæûÈÄÄ) </li>
          <li> <b>„Éà„É®„Çø„Éª„Éâ„ÉØ„É≥„Ç¥È´òÂ∫¶‰∫∫Â∑•Áü•ËÉΩ‰∫∫ÊùêÂ•®Â≠¶Èáë</b>, 2018.4 - 2019.3 </li>
          <li> <b>„Éà„É®„Çø„Éª„Éâ„ÉØ„É≥„Ç¥È´òÂ∫¶‰∫∫Â∑•Áü•ËÉΩ‰∫∫ÊùêÂ•®Â≠¶Èáë</b>, 2017.4 - 2018.3 </li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Media </h2>
        </div>
        <ol>
          <li><a href="https://karapaia.com/archives/525837.html" target='_blank'>„Åì„ÅÑ„Å§„ÄÅÈÄü„ÅÑ„ÅûÔºÅÊù±‰∫¨Â§ßÂ≠¶„ÅåÈñãÁô∫„Åó„ÅüÂ£ÅÁôª„Çä„É≠„Éú„ÉÉ„Éà„Åå‰∏ñÁïåÊúÄÈÄüË®òÈå≤„ÇíÊõ¥Êñ∞ÔºÅ</a>, „Ç´„É©„Éë„Ç§„Ç¢, 2025.07.18</li>
          <li><a href="https://newatlas.com/robotics/jsk-kleiyn-quadruped-waist-climb/" target='_blank'>Robodog chimneys better than you, ready to send a V5</a>, New Atlas, 2025.07.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-reachy-mini" target='_blank'>Reachy Mini Brings the Cute: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.07.11</li>
          <li><a href="https://interestingengineering.com/innovation/kleiyn-chimney-climbing-robot-dog" target='_blank'>Watch world‚Äôs fastest chimney-climbing robot dog scale 50 times faster than rivals</a>, Interesting Engineering, 2025.07.14</li>
          <li><a href="https://newswitch.jp/p/46244" target='_blank'>Êù±Â§ß„ÅåÈñãÁô∫„ÄÅ„Éü„Çπ„ÉüÈÄöË≤©„ÅßÈÉ®ÂìÅË™øÈÅî„Åß„Åç„Çã„Äå4ËÑö„É≠„Éú„ÉÉ„Éà„Äç„ÅÆÂà©ÁÇπ</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2025.07.06</li>
          <li><a href="https://spectrum.ieee.org/video-friday-hopping-robot-insect" target='_blank'>Tiny Robot Bug Hops and Jumps: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.04.11</li>
          <li><a href="https://jp.meviy.misumi-ec.com/info/ja/news/48510/" target='_blank'>Á¨¨10Âõû„ÄÄË®≠Ë®à„ÉªË£ΩÈÄ†„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥Â±ïÔºàDMSÂêçÂè§Â±ãÔºâ2025</a>, meviy, 2025.03.25</li>
          <li><a href="https://xtech.nikkei.com/atcl/nxt/column/18/03118/00005/" target='_blank'>ËÑöÂºè„É≠„Éú„ÅÆÊ≠©Ë°åÈ®íÈü≥ÂïèÈ°å„ÄÅ„ÇΩ„Éã„Éº„ÅåÁã¨Ëá™Âº∑ÂåñÂ≠¶Áøí„ÅßaiboÈùô„Åã„Å´</a>, Êó•Áµå„ÇØ„É≠„Çπ„ÉÜ„ÉÉ„ÇØ, 2025.03.21</li>
          <li><a href="https://techxplore.com/news/2025-03-sony-aibo-dog-quietly-elaborate.html" target='_blank'>Sony's aibo dog could soon walk quietly and perform elaborate dance routines</a>, Tech Xplore, 2025.03.04</li>
          <li><a href="https://spectrum.ieee.org/video-friday-good-over-all-terrains" target='_blank'>Good Over All Terrains: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.02.28</li>
          <li><a href="https://spectrum.ieee.org/video-friday-aibo-foster-parents" target='_blank'>Aibo Foster Parents: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.31</li>
          <li><a href="https://spectrum.ieee.org/video-friday-agile-upgrade" target='_blank'>Agile Upgrade: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-hottest-on-the-ice" target='_blank'>Hottest on the Ice: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2025.01.24</li>
          <li><a href="https://prtimes.jp/main/html/rd/p/000000060.000069918.html" target='_blank'>„Ç¢„Éº„É´„ÉÜ„Ç£„ÅåÊåë„ÇÄ„ÄÅÂõΩÁî£4Ë∂≥Ê≠©Ë°å„É≠„Éú„ÉÉ„Éà„ÅÆÊú™Êù•</a>, PR TIMES, 2024.12.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-multiple-magicbots" target='_blank'>Multiple MagicBots: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.12.06</li>
          <li><a href="https://www.yomiuri.co.jp/science/20241120-OYT1T50012/" target='_blank'>„ÄåÈ†≠ËÑ≥„ÄçÊâã„Å´ÂÖ•„Çå„ÄåÂ∏∏Ë≠ò„ÄçÂÇô„Åà„Åü„Åã„Å´Ë¶ã„Åà„Çã„É≠„Éú„ÉÉ„Éà‚Ä¶ÁßÅ„Åü„Å°„ÅÆ„Éë„Éº„Éà„Éä„Éº„Åã„ÄÅÂÄ´ÁêÜË¶≥„Å™„ÅçÂç±Èô∫„Å™Â≠òÂú®„Åã</a>, Ë™≠Â£≤Êñ∞ËÅû, 2024.11.20</li>
          <li><a href="https://newswitch.jp/p/43682" target='_blank'>„É≠„Éú„ÉÉ„Éà„Å´ÊåáÁ§∫„ÉªÊÑèÂõ≥„Å©„ÅÜ‰ºù„Åà„ÇãÔºü‚Ä¶„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„ÇπÊúÄÈÅ©Âåñ„Å∏Êñ∞ÊâãÊ≥ïÊé¢„Çã</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2024.11.24</li>
          <li><a href="https://spectrum.ieee.org/video-friday-quadruped-ladder-climbing" target='_blank'>Quadruped Ladder Climbing: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.10.04</li>
          <li><a href="https://interestingengineering.com/innovation/mini-muscle-power-new-robotic-forearm" target='_blank'>Game-changing mini-muscle motors power new robotic forearm like humans</a>, Interesting Engineering, 2024.09.02</li>
          <li><a href="https://www.dw.com/en/a-robot-at-the-wheel/video-69903705" target='_blank'>A robot at the wheel</a>, Deutsche Welle, 2024.08.31</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robots-table-tennis" target='_blank'>Robots Solving Table Tennis: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.30</li>
          <li><a href="https://spectrum.ieee.org/video-friday-disney-robot-dance" target='_blank'>Disney Robot Dance: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.23</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robot-dog-jump" target='_blank'>Silly Robot Dog Jump: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.08.16</li>
          <li><a href="https://newswitch.jp/p/42280" target='_blank'>„ÄåÂ∏∏Ë≠ò„Äç„Äå„Éá„Éº„Çø„Äç‰Ωø„ÅÑÂàá„Çå‚Ä¶Âü∫Áõ§„É¢„Éá„É´„ÉªLLM„ÄÅ„É≠„Éú„ÉÉ„Éà„Å´ÂøúÁî®</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2024.07.19</li>
          <li><a href="https://www.gizmodo.jp/2024/06/musashi-humanoid-driving.html" target='_blank'>‰∫∫Âûã„É≠„Éú„ÅØÈÅãËª¢„ÇÇ„Åì„Å™„Åô„ÄÇ„ÇØ„É´„Éû„Åæ„Åã„Åõ„ÅÆËá™ÂãïÈÅãËª¢„Çà„Çä„ÇÇÂÆâÂøÉÊÑü„Ç¢„ÉÉ„Éó</a>, GIZMODO JAPAN, 2024.06.18</li>
          <li><a href="https://www.newscientist.com/article/2435826-watch-a-humanoid-robot-driving-a-car-extremely-slowly/" target='_blank'>Watch a humanoid robot driving a car extremely slowly</a>, New Scientist, 2024.06.17</li>
          <li><a href="https://newatlas.com/robotics/musashi-humanoid-autonomous-driving/" target='_blank'>Video: Humanoid chauffeur put in the driving seat for robotaxi future</a>, New Atlas, 2024.06.13</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robots-with-knives" target='_blank'>Robots With Knives: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.05.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-racer-heavy" target='_blank'>RACER Heavy: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.26</li>
          <li><a href="https://abema.tv/video/episode/89-106_s1_p2428" target='_blank'>„Äé„Åô„Åö„ÇÅ„ÅÆÊà∏Á∑†„Çä„ÄèÊ§ÖÂ≠ê„Çí„É≠„Éú„ÉÉ„Éà„Å´</a>, ABEMA„ÄêÈÄ±ÂàäBUZZÂãïÁîª„ÄëSNS„ÅßË©±È°å„ÅÆÂãïÁîª„Çí„Éî„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó!, 2024.04.20</li>
          <li><a href="https://spectrum.ieee.org/video-friday-spacehopper" target='_blank'>SpaceHopper: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.19</li>
          <li><a href="https://www.itmedia.co.jp/aiplus/articles/2404/17/news048.html" target='_blank'>„Äå„Åô„Åö„ÇÅ„ÅÆÊà∏Á∑†„Åæ„Çä„Äç„Å´ÁôªÂ†¥„ÅÆ‚Äú3Êú¨ËÑö„ÅÆÊ§ÖÂ≠ê‚Äù„ÇíÂÜçÁèæ„Åó„Åü„É≠„Éú„ÉÉ„Éà„ÄÄÊù±Â§ß„ÅåÈñãÁô∫„ÄÄÊ≠©Ë°å„ÅóÂÄí„Çå„Å¶„ÇÇËµ∑„Åç‰∏ä„Åå„Çã</a>, ITmedia AI+, 2024.04.17</li>
          <li><a href="https://spectrum.ieee.org/video-friday-robot-dog-can-t-fall" target='_blank'>Robot Dog Can't Fall: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.04.12</li>
          <li><a href="https://spectrum.ieee.org/video-friday-co-expression" target='_blank'>Co-Expression: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.29</li>
          <li><a href="https://spectrum.ieee.org/video-friday-many-quadrupeds" target='_blank'>Many Quadrupeds: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.15</li>
          <li><a href="https://spectrum.ieee.org/video-friday-human-to-humanoid" target='_blank'>Human to Humanoid: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2024.03.08</li>
          <li><a href="https://spectrum.ieee.org/video-friday-tap-finger-move-mountain" target='_blank'>Tap Finger, Move Mountain: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2023.12.01</li>
          <li><a href="https://newswitch.jp/p/39450" target='_blank'>AI„Éª„É≠„Éú„ÇÇËø∑„ÅÜ‚Ä¶‚ÄúÊàë„ÅåÂÆ∂„ÅÆÂÜ∑ËîµÂ∫´ÂïèÈ°å‚Äù„ÅåËß£„Åë„Åü„ÇâÂÄ§ÂçÉÈáë„Å™ÁêÜÁî±</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2023.12.01</li>
          <li><a href="https://newswitch.jp/p/39285" target='_blank'>ÁîüÊ¥ªÊîØÊè¥„É≠„Éú„ÉÉ„Éà„ÄÅÔº°Ôº©„ÅßÂ§âÈù©„Åó„ÅüÁèæÂú®Âú∞„Å®Â±ïÊúõ</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2023.11.30</li>
          <li><a href="https://spectrum.ieee.org/video-friday-punch-out" target='_blank'>Punch-Out: Your weekly selection of awesome robot videos</a>, IEEE Spectrum Video Friday, 2023.11.24</li>
          <li><a href="https://newswitch.jp/p/38378" target='_blank'>ËÖπËÖîÈè°ÊâãË°ì„ÅÆË®ìÁ∑¥ÊâãÊäÄ„Çí„É≠„Éú„ÉÉ„Éà„Å´„ÄÅÊù±Â§ß„ÅåÂà∂Á¥Ñ‰ªò„ÅçÊ®°ÂÄ£Â≠¶ÁøíÈñãÁô∫</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2023.09.06</li>
          <li><a href="https://www.asahi.com/articles/ASLCJ3412LCJOBJB002.html" target='_blank'>‰∫∫Âûã„É≠„Éú„ÉÉ„Éà„Äå„É†„Çµ„Ç∑„Äç„ÄÅËªä„ÇÇÈÅãËª¢„Åß„Åç„Çã„Çà„ÄÄÊù±Â§ß„ÅåÊä´Èú≤</a>, ÊúùÊó•Êñ∞ËÅû, 2018.11.16</li>
          <li><a href="https://newswitch.jp/p/13673" target='_blank'>Êù±Â§ß„ÅÆ„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„ÄåËÖ±ÊÇüÈÉé„Äç„ÄÅËªä„ÅÆÈÅãËª¢„Å´ÊàêÂäü</a>, Êó•ÂàäÂ∑•Ê•≠Êñ∞ËÅû, 2018.07.13</li>
          <li><a href="https://www.nikkei.com/article/DGXMZO25019580U7A221C1TJM000/" target='_blank'>Êù±Â§ß„ÄÅÊó•Êú¨‰∫∫„ÅÆÁ≠ãÈ™®Ê†ºÂÜçÁèæ„Åó„Åü„É≠„Éú„ÉÉ„ÉàÈñãÁô∫</a>, Êó•Êú¨ÁµåÊ∏àÊñ∞ËÅû, 2017.12.24</li>
          <li><a href="https://www.todaishimbun.org/seisakuten20161118/" target='_blank'>ÂàùÊó•„Åã„Çâ300‰∫∫Êù•Â†¥ÔºÅ„ÅÑ„ÅæË©±È°å„ÅÆ„ÄåÊù±‰∫¨Â§ßÂ≠¶Âà∂‰ΩúÂ±ï„ÄéFAKE FUTURE„Äè„Äç„Åß„ÅØ„Å©„Çì„Å™‰ΩìÈ®ì„Åå„Åß„Åç„Çã„ÅÆ„ÅãÔºü</a>, Êù±Â§ßÊñ∞ËÅû„Ç™„É≥„É©„Ç§„É≥, 2016.11.18</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> Academic Activities </h2>
        </div>
        <ol>
          <li>Organizer, <a href="https://sites.google.com/g.ecc.u-tokyo.ac.jp/iros2025-ws-roboticdesign/" target='_blank'>Workshop on Foundation Models for Robotic Design</a>, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025), 2025</li>
          <li>Organizer, <a href="TODO" target='_blank'>Workshop on Open Hardware in the Era of Robot Learning</a>, Conference on Robot Learning (CoRL2025), 2025</li>
          <li>Associate Editor, 2025 IEEE-RAS International Conference on Humanoid Robots (Humanoids2025), 2025</li>
          <li>Associate Editor, 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025), 2025</li>
          <li>Associate Editor, 2025 IEEE International Conference on Robotics and Automation (ICRA2025), 2025</li>
          <li>Associate Editor, 2024 IEEE-RAS International Conference on Humanoid Robots (Humanoids2024), 2024</li>
          <li>Organizer, Organized Session on Real-World Robot Applications of Foundation Models, The 42nd Annual Conference of the Robotics Society of Japan (RSJ2024), 2024</li>
          <li>Organizer, <a href="https://sites.google.com/view/icra2024cookingrobotics/home" target='_blank'>Workshop on Cooking Robotics: Perception and motion planning</a>, IEEE International Conference on Robotics and Automation (ICRA2024), 2024</li>
          <li>Associate Editor, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024), 2024</li>
          <li>Section Editor, Special Section on Cognitive Development and Symbol Emergence, Advanced Robotics, 2024</li>
          <li>Guest Editor, <a href="https://www.rsj.or.jp/content/files/pub/ar/CFP/CFP_38_17.pdf" target='_blank'>Special Issue on Real-World Robot Applications of the Foundation Models</a>, Advanced Robotics, 2024</li>
          <li>Organizer, <a href="https://sites.google.com/grp.riken.jp/langrobonlp2024" target='_blank'>Workshop on Real-World Applications of Large Language Models</a>, The 30th Annual Meeting of the Association of Natural Language Processing (NLP2024), 2024</li>
          <li>Associate Editor, 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids2023), 2023</li>
          <li>Organizer, <a href="https://sites.google.com/view/robotics-foundation-models/organized-session-on-rsj2023?authuser=0" target='_blank'>Organized Session on Real-World Robot Applications of Foundation Models</a>, The 41st Annual Conference of the Robotics Society of Japan (RSJ2023), 2023</li>
          <li>Associate Editor, 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids2022), 2022</li>
        </ol>

        <div class="text-white bg-primary border-primary mt-3 ps-3">
          <h2> CV </h2>
        </div>
        <a href="static/kawaharazuka-cv.pdf">Download</a>
      </main>
    </div>
  </body>
</html>
